{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspired/based on https://github.com/rayidghani/magicloops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pipeline_v2 as pipeline\n",
    "import importlib\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(pipeline)\n",
    "\n",
    "data = pd.read_csv('projects_2012_2013.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data exploration...\n",
      "\n",
      "Number of rows: 124976\n",
      "\n",
      "Columns and types of data:\n",
      "projectid                                  object\n",
      "teacher_acctid                             object\n",
      "schoolid                                   object\n",
      "school_ncesid                             float64\n",
      "school_latitude                           float64\n",
      "school_longitude                          float64\n",
      "school_city                                object\n",
      "school_state                               object\n",
      "school_metro                               object\n",
      "school_district                            object\n",
      "school_county                              object\n",
      "school_charter                             object\n",
      "school_magnet                              object\n",
      "teacher_prefix                             object\n",
      "primary_focus_subject                      object\n",
      "primary_focus_area                         object\n",
      "secondary_focus_subject                    object\n",
      "secondary_focus_area                       object\n",
      "resource_type                              object\n",
      "poverty_level                              object\n",
      "grade_level                                object\n",
      "total_price_including_optional_support    float64\n",
      "students_reached                          float64\n",
      "eligible_double_your_impact_match          object\n",
      "date_posted                                object\n",
      "datefullyfunded                            object\n",
      "dtype: object\n",
      "\n",
      "\n",
      "Statistics for selected variables:\n",
      "count    124976.000000\n",
      "mean        654.011811\n",
      "std        1098.015854\n",
      "min          92.000000\n",
      "25%         345.810000\n",
      "50%         510.500000\n",
      "75%         752.960000\n",
      "max      164382.840000\n",
      "Name: total_price_including_optional_support, dtype: float64\n",
      "Number of outliers (>4 standard dev):521\n",
      "\n",
      "\n",
      "count    124917.000000\n",
      "mean         95.445760\n",
      "std         163.481912\n",
      "min           1.000000\n",
      "25%          23.000000\n",
      "50%          30.000000\n",
      "75%         100.000000\n",
      "max       12143.000000\n",
      "Name: students_reached, dtype: float64\n",
      "Number of outliers (>4 standard dev):2063\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Correlation between ['total_price_including_optional_support', 'students_reached']\n",
      "0.17662743502916253\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "importlib.reload(pipeline)\n",
    "\n",
    "stats_for_variables = [\n",
    "  'total_price_including_optional_support',\n",
    "  'students_reached'\n",
    "]\n",
    "\n",
    "variables_for_correlation = [\n",
    "  'total_price_including_optional_support',\n",
    "  'students_reached'\n",
    "]\n",
    "\n",
    "pipeline.explore_data(data, stats_for_variables, variables_for_correlation)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can clearly see in the histograms that DebtRadio MontlyIncome have very big outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre processing data...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(pipeline)\n",
    "\n",
    "columns_to_process = [\n",
    "  'total_price_including_optional_support',\n",
    "  'students_reached'\n",
    "]\n",
    "\n",
    "data = pipeline.pre_process_data(data, columns_to_process)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create binary features and select predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['projectid',\n",
       " 'teacher_acctid',\n",
       " 'schoolid',\n",
       " 'school_ncesid',\n",
       " 'school_latitude',\n",
       " 'school_longitude',\n",
       " 'school_city',\n",
       " 'school_district',\n",
       " 'school_county',\n",
       " 'teacher_prefix',\n",
       " 'secondary_focus_subject',\n",
       " 'secondary_focus_area',\n",
       " 'total_price_including_optional_support',\n",
       " 'students_reached',\n",
       " 'date_posted',\n",
       " 'datefullyfunded',\n",
       " 'school_state_AK',\n",
       " 'school_state_AL',\n",
       " 'school_state_AR',\n",
       " 'school_state_AZ',\n",
       " 'school_state_CA',\n",
       " 'school_state_CO',\n",
       " 'school_state_CT',\n",
       " 'school_state_DC',\n",
       " 'school_state_DE',\n",
       " 'school_state_FL',\n",
       " 'school_state_GA',\n",
       " 'school_state_HI',\n",
       " 'school_state_IA',\n",
       " 'school_state_ID',\n",
       " 'school_state_IL',\n",
       " 'school_state_IN',\n",
       " 'school_state_KS',\n",
       " 'school_state_KY',\n",
       " 'school_state_LA',\n",
       " 'school_state_MA',\n",
       " 'school_state_MD',\n",
       " 'school_state_ME',\n",
       " 'school_state_MI',\n",
       " 'school_state_MN',\n",
       " 'school_state_MO',\n",
       " 'school_state_MS',\n",
       " 'school_state_MT',\n",
       " 'school_state_NC',\n",
       " 'school_state_ND',\n",
       " 'school_state_NE',\n",
       " 'school_state_NH',\n",
       " 'school_state_NJ',\n",
       " 'school_state_NM',\n",
       " 'school_state_NV',\n",
       " 'school_state_NY',\n",
       " 'school_state_OH',\n",
       " 'school_state_OK',\n",
       " 'school_state_OR',\n",
       " 'school_state_PA',\n",
       " 'school_state_RI',\n",
       " 'school_state_SC',\n",
       " 'school_state_SD',\n",
       " 'school_state_TN',\n",
       " 'school_state_TX',\n",
       " 'school_state_UT',\n",
       " 'school_state_VA',\n",
       " 'school_state_VT',\n",
       " 'school_state_WA',\n",
       " 'school_state_WI',\n",
       " 'school_state_WV',\n",
       " 'school_state_WY',\n",
       " 'school_state_nan',\n",
       " 'school_metro_rural',\n",
       " 'school_metro_suburban',\n",
       " 'school_metro_urban',\n",
       " 'school_metro_nan',\n",
       " 'school_charter_f',\n",
       " 'school_charter_t',\n",
       " 'school_charter_nan',\n",
       " 'school_magnet_f',\n",
       " 'school_magnet_t',\n",
       " 'school_magnet_nan',\n",
       " 'primary_focus_subject_Applied Sciences',\n",
       " 'primary_focus_subject_Character Education',\n",
       " 'primary_focus_subject_Civics & Government',\n",
       " 'primary_focus_subject_College & Career Prep',\n",
       " 'primary_focus_subject_Community Service',\n",
       " 'primary_focus_subject_ESL',\n",
       " 'primary_focus_subject_Early Development',\n",
       " 'primary_focus_subject_Economics',\n",
       " 'primary_focus_subject_Environmental Science',\n",
       " 'primary_focus_subject_Extracurricular',\n",
       " 'primary_focus_subject_Foreign Languages',\n",
       " 'primary_focus_subject_Gym & Fitness',\n",
       " 'primary_focus_subject_Health & Life Science',\n",
       " 'primary_focus_subject_Health & Wellness',\n",
       " 'primary_focus_subject_History & Geography',\n",
       " 'primary_focus_subject_Literacy',\n",
       " 'primary_focus_subject_Literature & Writing',\n",
       " 'primary_focus_subject_Mathematics',\n",
       " 'primary_focus_subject_Music',\n",
       " 'primary_focus_subject_Nutrition',\n",
       " 'primary_focus_subject_Other',\n",
       " 'primary_focus_subject_Parent Involvement',\n",
       " 'primary_focus_subject_Performing Arts',\n",
       " 'primary_focus_subject_Social Sciences',\n",
       " 'primary_focus_subject_Special Needs',\n",
       " 'primary_focus_subject_Sports',\n",
       " 'primary_focus_subject_Visual Arts',\n",
       " 'primary_focus_subject_nan',\n",
       " 'primary_focus_area_Applied Learning',\n",
       " 'primary_focus_area_Health & Sports',\n",
       " 'primary_focus_area_History & Civics',\n",
       " 'primary_focus_area_Literacy & Language',\n",
       " 'primary_focus_area_Math & Science',\n",
       " 'primary_focus_area_Music & The Arts',\n",
       " 'primary_focus_area_Special Needs',\n",
       " 'primary_focus_area_nan',\n",
       " 'resource_type_Books',\n",
       " 'resource_type_Other',\n",
       " 'resource_type_Supplies',\n",
       " 'resource_type_Technology',\n",
       " 'resource_type_Trips',\n",
       " 'resource_type_Visitors',\n",
       " 'resource_type_nan',\n",
       " 'poverty_level_high poverty',\n",
       " 'poverty_level_highest poverty',\n",
       " 'poverty_level_low poverty',\n",
       " 'poverty_level_moderate poverty',\n",
       " 'poverty_level_nan',\n",
       " 'grade_level_Grades 3-5',\n",
       " 'grade_level_Grades 6-8',\n",
       " 'grade_level_Grades 9-12',\n",
       " 'grade_level_Grades PreK-2',\n",
       " 'grade_level_nan',\n",
       " 'eligible_double_your_impact_match_f',\n",
       " 'eligible_double_your_impact_match_t',\n",
       " 'eligible_double_your_impact_match_nan',\n",
       " 'datefullyfunded_formated',\n",
       " 'date_posted_formated']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['school_state' 'school_metro' 'school_charter' 'school_magnet'\\n 'primary_focus_subject' 'primary_focus_area' 'resource_type'\\n 'poverty_level' 'grade_level' 'eligible_double_your_impact_match'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-9d87aa67408c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_dummies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcols_to_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/ML-pipeline/pipeline_v2.py\u001b[0m in \u001b[0;36mcreate_dummies\u001b[0;34m(df, cols_to_transform)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcreate_dummies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcols_to_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdummy_na\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcols_to_transform\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/core/reshape/reshape.py\u001b[0m in \u001b[0;36mget_dummies\u001b[0;34m(data, prefix, prefix_sep, dummy_na, columns, sparse, drop_first, dtype)\u001b[0m\n\u001b[1;32m    842\u001b[0m                 include=dtypes_to_encode)\n\u001b[1;32m    843\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 844\u001b[0;31m             \u001b[0mdata_to_encode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    845\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m         \u001b[0;31m# validate prefixes and separator to avoid silently dropping cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2680\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2681\u001b[0m             \u001b[0;31m# either boolean or fancy integer index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2682\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2683\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2684\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_array\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2724\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_take\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2725\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2726\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2727\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_take\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[0;34m(self, obj, axis, is_setter)\u001b[0m\n\u001b[1;32m   1325\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m                     raise KeyError('{mask} not in index'\n\u001b[0;32m-> 1327\u001b[0;31m                                    .format(mask=objarr[mask]))\n\u001b[0m\u001b[1;32m   1328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values_from_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['school_state' 'school_metro' 'school_charter' 'school_magnet'\\n 'primary_focus_subject' 'primary_focus_area' 'resource_type'\\n 'poverty_level' 'grade_level' 'eligible_double_your_impact_match'] not in index\""
     ]
    }
   ],
   "source": [
    "importlib.reload(pipeline)\n",
    "\n",
    "cols_to_transform = [\n",
    "'school_state',\n",
    "'school_metro',\n",
    "'school_charter',\n",
    "'school_magnet',\n",
    "'primary_focus_subject',\n",
    "'primary_focus_area',\n",
    "'resource_type',\n",
    "'poverty_level',\n",
    "'grade_level',\n",
    "'eligible_double_your_impact_match']\n",
    "\n",
    "\n",
    "data = pipeline.create_dummies(data, cols_to_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = ['school_state_AK','school_state_AL','school_state_AR','school_state_AZ','school_state_CA','school_state_CO','school_state_CT','school_state_DC','school_state_DE','school_state_FL','school_state_GA','school_state_HI','school_state_IA','school_state_ID','school_state_IL','school_state_IN','school_state_KS','school_state_KY','school_state_LA','school_state_MA','school_state_MD','school_state_ME','school_state_MI','school_state_MN','school_state_MO','school_state_MS','school_state_MT','school_state_NC','school_state_ND','school_state_NE','school_state_NH','school_state_NJ','school_state_NM','school_state_NV','school_state_NY','school_state_OH','school_state_OK','school_state_OR','school_state_PA','school_state_RI','school_state_SC','school_state_SD','school_state_TN','school_state_TX','school_state_UT','school_state_VA','school_state_VT','school_state_WA','school_state_WI','school_state_WV','school_state_WY','school_state_nan','school_metro_rural','school_metro_suburban','school_metro_urban','school_metro_nan','school_charter_f','school_charter_t','school_charter_nan','school_magnet_f','school_magnet_t','school_magnet_nan','primary_focus_subject_Applied Sciences','primary_focus_subject_Character Education','primary_focus_subject_Civics & Government','primary_focus_subject_College & Career Prep','primary_focus_subject_Community Service','primary_focus_subject_ESL','primary_focus_subject_Early Development','primary_focus_subject_Economics','primary_focus_subject_Environmental Science','primary_focus_subject_Extracurricular','primary_focus_subject_Foreign Languages','primary_focus_subject_Gym & Fitness','primary_focus_subject_Health & Life Science','primary_focus_subject_Health & Wellness','primary_focus_subject_History & Geography','primary_focus_subject_Literacy','primary_focus_subject_Literature & Writing','primary_focus_subject_Mathematics','primary_focus_subject_Music','primary_focus_subject_Nutrition','primary_focus_subject_Other','primary_focus_subject_Parent Involvement','primary_focus_subject_Performing Arts','primary_focus_subject_Social Sciences','primary_focus_subject_Special Needs','primary_focus_subject_Sports','primary_focus_subject_Visual Arts','primary_focus_subject_nan','primary_focus_area_Applied Learning','primary_focus_area_Health & Sports','primary_focus_area_History & Civics','primary_focus_area_Literacy & Language','primary_focus_area_Math & Science','primary_focus_area_Music & The Arts','primary_focus_area_Special Needs','primary_focus_area_nan','resource_type_Books','resource_type_Other','resource_type_Supplies','resource_type_Technology','resource_type_Trips','resource_type_Visitors','resource_type_nan','poverty_level_high poverty','poverty_level_highest poverty','poverty_level_low poverty','poverty_level_moderate poverty','poverty_level_nan','grade_level_Grades 3-5','grade_level_Grades 6-8','grade_level_Grades 9-12','grade_level_Grades PreK-2','grade_level_nan','eligible_double_your_impact_match_f','eligible_double_your_impact_match_t','eligible_double_your_impact_match_nan']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create binary variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(pipeline)\n",
    "\n",
    "# The task is to predict if a project onprint(sklearn.__version__) donorschoose will not get fully funded within 60 days of posting.\n",
    "\n",
    "# Change dates to date format\n",
    "data['datefullyfunded_formated'] = pd.to_datetime(data['datefullyfunded'])\n",
    "data['date_posted_formated'] = pd.to_datetime(data['date_posted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(pipeline)\n",
    "\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "#Calculate difference between two dates\n",
    "data['time_to_fund'] = data['datefullyfunded_formated'].sub(data['date_posted_formated'], axis=0)\n",
    "got an unexpected keyword argument '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(pipeline)\n",
    "\n",
    "data['time_to_fund'] = pd.to_numeric(data['time_to_fund'] / np.timedelta64(1, 'D'))\n",
    "data['not_funded_in_60'] = np.where(data['time_to_fund']>60, 1, 0)\n",
    "\n",
    "\n",
    "* Get label (1/4) This problem asks you to predict the project not funded in 60 days, so you should label 1 for the projects not funded in 60 days.\n",
    "\n",
    "outcome ='not_funded_in_60'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['date_posted_formated'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(pipeline)\n",
    "\n",
    "start_time = str(data['date_posted_formated'].describe()['first']).split(\" \")[0]\n",
    "end_time = str(data['date_posted_formated'].describe()['last']).split(\" \")[0]\n",
    "prediction_window = 6\n",
    "date_column='date_posted_formated'\n",
    "\n",
    "\n",
    "sets = pipeline.create_temp_validation_train_and_testing_sets(data, \n",
    "                                                                   selected_features,\n",
    "                                                                   outcome,\n",
    "                                                                   start_time,\n",
    "                                                                   end_time,\n",
    "                                                                   prediction_window,\n",
    "                                                                   date_column)\n",
    "x_train_1 = sets[0]\n",
    "x_test_1 = sets[1]\n",
    "y_train_1 = sets[2]\n",
    "y_test_1 = sets[3]\n",
    "\n",
    "x_train_2 = sets[4]\n",
    "x_test_2 = sets[5]\n",
    "y_train_2 = sets[6]\n",
    "y_test_2 = sets[7]\n",
    "\n",
    "x_train_3 = sets[8]\n",
    "x_test_3 = sets[9]\n",
    "y_train_3 = sets[10]\n",
    "y_test_3 = sets[11]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Clasifiers and parameters generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(pipeline)\n",
    "\n",
    "#We define the specific models we want to run\n",
    "\n",
    "#Not running BA and KNN because t\n",
    "\n",
    "* Get label (1/4) This problem asks you to predict the project not funded in 60 days, so you should label 1 for the projects not funded in 60 days.\n",
    "hey are taking ages\n",
    "models_to_run=['LR','DT','LR','AB','RF','SVM']#,'BA','KNN']\n",
    "\n",
    "#Get all posible models and their different sets of parameters\n",
    "models, parameters_grid = pipeline.get_models_and_parameters()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loop over models and different training/test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With first train set (biggest one):\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'x_train_1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-bcd9e96d29fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"With first train set (biggest one):\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterate_over_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels_to_run\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'x_train_1' is not defined"
     ]
    }
   ],
   "source": [
    "importlib.reload(pipeline)\n",
    "\n",
    "print(\"With first train set (biggest one):\")\n",
    "pipeline.iterate_over_models(models_to_run, models, parameters_grid, x_train_1, x_test_1, y_train_1, y_test_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"With second train set:\")\n",
    "pipeline.iterate_over_models(models_to_run, models, parameters_grid, x_train_2, x_test_2, y_train_2, y_test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With third train set (smalles one):\n",
      "Running LR...\n",
      "Running DT...\n",
      "Running LR...\n",
      "Running AB...\n",
      "Running RF...\n",
      "Running SVM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/felipe/.local/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>model</th>\n",
       "      <th>parameters</th>\n",
       "      <th>p_at_1</th>\n",
       "      <th>r_at_1</th>\n",
       "      <th>p_at_2</th>\n",
       "      <th>r_at_2</th>\n",
       "      <th>p_at_5</th>\n",
       "      <th>r_at_5</th>\n",
       "      <th>p_at_10</th>\n",
       "      <th>r_at_10</th>\n",
       "      <th>p_at_20</th>\n",
       "      <th>r_at_20</th>\n",
       "      <th>p_at_30</th>\n",
       "      <th>r_at_30</th>\n",
       "      <th>p_at_50</th>\n",
       "      <th>r_at_50</th>\n",
       "      <th>auc-roc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>{'C': 0.001, 'penalty': 'l1'}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013917</td>\n",
       "      <td>0.694881</td>\n",
       "      <td>0.019352</td>\n",
       "      <td>0.877989</td>\n",
       "      <td>0.061146</td>\n",
       "      <td>0.833401</td>\n",
       "      <td>0.116081</td>\n",
       "      <td>0.815211</td>\n",
       "      <td>0.227095</td>\n",
       "      <td>0.800939</td>\n",
       "      <td>0.334679</td>\n",
       "      <td>0.782331</td>\n",
       "      <td>0.544850</td>\n",
       "      <td>0.592306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>{'C': 0.001, 'penalty': 'l2'}</td>\n",
       "      <td>0.872211</td>\n",
       "      <td>0.012139</td>\n",
       "      <td>0.880892</td>\n",
       "      <td>0.024532</td>\n",
       "      <td>0.875963</td>\n",
       "      <td>0.061005</td>\n",
       "      <td>0.857925</td>\n",
       "      <td>0.119497</td>\n",
       "      <td>0.832489</td>\n",
       "      <td>0.231908</td>\n",
       "      <td>0.819247</td>\n",
       "      <td>0.342329</td>\n",
       "      <td>0.788553</td>\n",
       "      <td>0.549183</td>\n",
       "      <td>0.618635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'l1'}</td>\n",
       "      <td>0.864097</td>\n",
       "      <td>0.012026</td>\n",
       "      <td>0.866700</td>\n",
       "      <td>0.024137</td>\n",
       "      <td>0.872112</td>\n",
       "      <td>0.060737</td>\n",
       "      <td>0.858533</td>\n",
       "      <td>0.119582</td>\n",
       "      <td>0.837606</td>\n",
       "      <td>0.233334</td>\n",
       "      <td>0.823368</td>\n",
       "      <td>0.344051</td>\n",
       "      <td>0.791573</td>\n",
       "      <td>0.551287</td>\n",
       "      <td>0.624384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'l2'}</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.012280</td>\n",
       "      <td>0.872783</td>\n",
       "      <td>0.024306</td>\n",
       "      <td>0.871301</td>\n",
       "      <td>0.060680</td>\n",
       "      <td>0.859141</td>\n",
       "      <td>0.119666</td>\n",
       "      <td>0.838316</td>\n",
       "      <td>0.233531</td>\n",
       "      <td>0.823706</td>\n",
       "      <td>0.344192</td>\n",
       "      <td>0.791999</td>\n",
       "      <td>0.551583</td>\n",
       "      <td>0.625046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>{'C': 1, 'penalty': 'l1'}</td>\n",
       "      <td>0.834686</td>\n",
       "      <td>0.011617</td>\n",
       "      <td>0.855043</td>\n",
       "      <td>0.023812</td>\n",
       "      <td>0.869274</td>\n",
       "      <td>0.060539</td>\n",
       "      <td>0.858330</td>\n",
       "      <td>0.119553</td>\n",
       "      <td>0.838164</td>\n",
       "      <td>0.233489</td>\n",
       "      <td>0.823368</td>\n",
       "      <td>0.344051</td>\n",
       "      <td>0.791695</td>\n",
       "      <td>0.551371</td>\n",
       "      <td>0.624894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>{'C': 1, 'penalty': 'l2'}</td>\n",
       "      <td>0.839757</td>\n",
       "      <td>0.011687</td>\n",
       "      <td>0.856057</td>\n",
       "      <td>0.023840</td>\n",
       "      <td>0.868869</td>\n",
       "      <td>0.060511</td>\n",
       "      <td>0.857925</td>\n",
       "      <td>0.119497</td>\n",
       "      <td>0.837809</td>\n",
       "      <td>0.233390</td>\n",
       "      <td>0.823402</td>\n",
       "      <td>0.344065</td>\n",
       "      <td>0.791289</td>\n",
       "      <td>0.551089</td>\n",
       "      <td>0.624866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>{'C': 10, 'penalty': 'l1'}</td>\n",
       "      <td>0.830629</td>\n",
       "      <td>0.011560</td>\n",
       "      <td>0.854536</td>\n",
       "      <td>0.023798</td>\n",
       "      <td>0.869072</td>\n",
       "      <td>0.060525</td>\n",
       "      <td>0.858026</td>\n",
       "      <td>0.119511</td>\n",
       "      <td>0.838062</td>\n",
       "      <td>0.233461</td>\n",
       "      <td>0.823335</td>\n",
       "      <td>0.344037</td>\n",
       "      <td>0.791451</td>\n",
       "      <td>0.551202</td>\n",
       "      <td>0.624867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>{'C': 10, 'penalty': 'l2'}</td>\n",
       "      <td>0.833671</td>\n",
       "      <td>0.011602</td>\n",
       "      <td>0.855043</td>\n",
       "      <td>0.023812</td>\n",
       "      <td>0.868869</td>\n",
       "      <td>0.060511</td>\n",
       "      <td>0.857722</td>\n",
       "      <td>0.119469</td>\n",
       "      <td>0.837961</td>\n",
       "      <td>0.233433</td>\n",
       "      <td>0.823368</td>\n",
       "      <td>0.344051</td>\n",
       "      <td>0.791411</td>\n",
       "      <td>0.551174</td>\n",
       "      <td>0.624857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 1, 'min_sam...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013917</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.027849</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.069643</td>\n",
       "      <td>0.711796</td>\n",
       "      <td>0.099143</td>\n",
       "      <td>0.701409</td>\n",
       "      <td>0.195393</td>\n",
       "      <td>0.800939</td>\n",
       "      <td>0.334679</td>\n",
       "      <td>0.880566</td>\n",
       "      <td>0.613265</td>\n",
       "      <td>0.550781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 1, 'min_sam...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013917</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.027849</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.069643</td>\n",
       "      <td>0.711796</td>\n",
       "      <td>0.099143</td>\n",
       "      <td>0.701409</td>\n",
       "      <td>0.195393</td>\n",
       "      <td>0.800939</td>\n",
       "      <td>0.334679</td>\n",
       "      <td>0.880566</td>\n",
       "      <td>0.613265</td>\n",
       "      <td>0.550781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'min_sam...</td>\n",
       "      <td>0.887424</td>\n",
       "      <td>0.012351</td>\n",
       "      <td>0.811455</td>\n",
       "      <td>0.022598</td>\n",
       "      <td>0.837657</td>\n",
       "      <td>0.058337</td>\n",
       "      <td>0.787191</td>\n",
       "      <td>0.109645</td>\n",
       "      <td>0.799301</td>\n",
       "      <td>0.222663</td>\n",
       "      <td>0.769524</td>\n",
       "      <td>0.321552</td>\n",
       "      <td>0.783993</td>\n",
       "      <td>0.546008</td>\n",
       "      <td>0.610375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'min_sam...</td>\n",
       "      <td>0.887424</td>\n",
       "      <td>0.012351</td>\n",
       "      <td>0.811455</td>\n",
       "      <td>0.022598</td>\n",
       "      <td>0.837657</td>\n",
       "      <td>0.058337</td>\n",
       "      <td>0.787191</td>\n",
       "      <td>0.109645</td>\n",
       "      <td>0.799301</td>\n",
       "      <td>0.222663</td>\n",
       "      <td>0.769524</td>\n",
       "      <td>0.321552</td>\n",
       "      <td>0.783993</td>\n",
       "      <td>0.546008</td>\n",
       "      <td>0.610375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 10, 'min_sa...</td>\n",
       "      <td>0.781947</td>\n",
       "      <td>0.010883</td>\n",
       "      <td>0.871769</td>\n",
       "      <td>0.024278</td>\n",
       "      <td>0.877989</td>\n",
       "      <td>0.061146</td>\n",
       "      <td>0.847994</td>\n",
       "      <td>0.118114</td>\n",
       "      <td>0.830563</td>\n",
       "      <td>0.231372</td>\n",
       "      <td>0.823808</td>\n",
       "      <td>0.344235</td>\n",
       "      <td>0.792546</td>\n",
       "      <td>0.551964</td>\n",
       "      <td>0.626015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 10, 'min_sa...</td>\n",
       "      <td>0.790061</td>\n",
       "      <td>0.010996</td>\n",
       "      <td>0.872276</td>\n",
       "      <td>0.024292</td>\n",
       "      <td>0.875557</td>\n",
       "      <td>0.060976</td>\n",
       "      <td>0.847791</td>\n",
       "      <td>0.118085</td>\n",
       "      <td>0.829905</td>\n",
       "      <td>0.231188</td>\n",
       "      <td>0.823639</td>\n",
       "      <td>0.344164</td>\n",
       "      <td>0.792323</td>\n",
       "      <td>0.551809</td>\n",
       "      <td>0.625719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 50, 'min_sa...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013917</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.027849</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.069643</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.139286</td>\n",
       "      <td>0.761603</td>\n",
       "      <td>0.212161</td>\n",
       "      <td>0.841069</td>\n",
       "      <td>0.351447</td>\n",
       "      <td>0.869277</td>\n",
       "      <td>0.605403</td>\n",
       "      <td>0.745723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 50, 'min_sa...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013917</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.027849</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.069643</td>\n",
       "      <td>0.910113</td>\n",
       "      <td>0.126766</td>\n",
       "      <td>0.784607</td>\n",
       "      <td>0.218570</td>\n",
       "      <td>0.856405</td>\n",
       "      <td>0.357856</td>\n",
       "      <td>0.863319</td>\n",
       "      <td>0.601253</td>\n",
       "      <td>0.734040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 100, 'min_s...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013917</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.027849</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.069643</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.139286</td>\n",
       "      <td>0.744224</td>\n",
       "      <td>0.207320</td>\n",
       "      <td>0.829483</td>\n",
       "      <td>0.346606</td>\n",
       "      <td>0.874040</td>\n",
       "      <td>0.608720</td>\n",
       "      <td>0.748978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 100, 'min_s...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013917</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.027849</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.069643</td>\n",
       "      <td>0.962910</td>\n",
       "      <td>0.134120</td>\n",
       "      <td>0.769102</td>\n",
       "      <td>0.214250</td>\n",
       "      <td>0.846068</td>\n",
       "      <td>0.353536</td>\n",
       "      <td>0.865224</td>\n",
       "      <td>0.602580</td>\n",
       "      <td>0.736847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 1, 'min_...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013917</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.027849</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.069643</td>\n",
       "      <td>0.711796</td>\n",
       "      <td>0.099143</td>\n",
       "      <td>0.701409</td>\n",
       "      <td>0.195393</td>\n",
       "      <td>0.800939</td>\n",
       "      <td>0.334679</td>\n",
       "      <td>0.880566</td>\n",
       "      <td>0.613265</td>\n",
       "      <td>0.550781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 1, 'min_...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013917</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.027849</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.069643</td>\n",
       "      <td>0.711796</td>\n",
       "      <td>0.099143</td>\n",
       "      <td>0.701409</td>\n",
       "      <td>0.195393</td>\n",
       "      <td>0.800939</td>\n",
       "      <td>0.334679</td>\n",
       "      <td>0.880566</td>\n",
       "      <td>0.613265</td>\n",
       "      <td>0.550781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'min_...</td>\n",
       "      <td>0.834686</td>\n",
       "      <td>0.011617</td>\n",
       "      <td>0.783578</td>\n",
       "      <td>0.021822</td>\n",
       "      <td>0.878192</td>\n",
       "      <td>0.061160</td>\n",
       "      <td>0.807458</td>\n",
       "      <td>0.112468</td>\n",
       "      <td>0.810752</td>\n",
       "      <td>0.225853</td>\n",
       "      <td>0.767261</td>\n",
       "      <td>0.320606</td>\n",
       "      <td>0.782027</td>\n",
       "      <td>0.544638</td>\n",
       "      <td>0.609640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'min_...</td>\n",
       "      <td>0.834686</td>\n",
       "      <td>0.011617</td>\n",
       "      <td>0.782565</td>\n",
       "      <td>0.021793</td>\n",
       "      <td>0.878395</td>\n",
       "      <td>0.061174</td>\n",
       "      <td>0.807560</td>\n",
       "      <td>0.112482</td>\n",
       "      <td>0.810651</td>\n",
       "      <td>0.225825</td>\n",
       "      <td>0.767295</td>\n",
       "      <td>0.320620</td>\n",
       "      <td>0.781987</td>\n",
       "      <td>0.544610</td>\n",
       "      <td>0.609648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 10, 'min...</td>\n",
       "      <td>0.758621</td>\n",
       "      <td>0.010558</td>\n",
       "      <td>0.879372</td>\n",
       "      <td>0.024489</td>\n",
       "      <td>0.884070</td>\n",
       "      <td>0.061569</td>\n",
       "      <td>0.858127</td>\n",
       "      <td>0.119525</td>\n",
       "      <td>0.842623</td>\n",
       "      <td>0.234731</td>\n",
       "      <td>0.823166</td>\n",
       "      <td>0.343967</td>\n",
       "      <td>0.794917</td>\n",
       "      <td>0.553616</td>\n",
       "      <td>0.625778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 10, 'min...</td>\n",
       "      <td>0.755578</td>\n",
       "      <td>0.010516</td>\n",
       "      <td>0.877851</td>\n",
       "      <td>0.024447</td>\n",
       "      <td>0.883462</td>\n",
       "      <td>0.061527</td>\n",
       "      <td>0.857823</td>\n",
       "      <td>0.119483</td>\n",
       "      <td>0.842673</td>\n",
       "      <td>0.234745</td>\n",
       "      <td>0.822828</td>\n",
       "      <td>0.343825</td>\n",
       "      <td>0.794795</td>\n",
       "      <td>0.553531</td>\n",
       "      <td>0.625747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 50, 'min...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013917</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.027849</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.069643</td>\n",
       "      <td>0.976794</td>\n",
       "      <td>0.136054</td>\n",
       "      <td>0.768950</td>\n",
       "      <td>0.214208</td>\n",
       "      <td>0.845967</td>\n",
       "      <td>0.353494</td>\n",
       "      <td>0.867777</td>\n",
       "      <td>0.604359</td>\n",
       "      <td>0.742237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 50, 'min...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013917</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.027849</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.069643</td>\n",
       "      <td>0.900385</td>\n",
       "      <td>0.125411</td>\n",
       "      <td>0.790231</td>\n",
       "      <td>0.220136</td>\n",
       "      <td>0.860154</td>\n",
       "      <td>0.359422</td>\n",
       "      <td>0.870067</td>\n",
       "      <td>0.605954</td>\n",
       "      <td>0.733306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 100, 'mi...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013917</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.027849</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.069643</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.139286</td>\n",
       "      <td>0.747669</td>\n",
       "      <td>0.208280</td>\n",
       "      <td>0.831779</td>\n",
       "      <td>0.347566</td>\n",
       "      <td>0.875621</td>\n",
       "      <td>0.609821</td>\n",
       "      <td>0.749111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 100, 'mi...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013917</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.027849</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.069643</td>\n",
       "      <td>0.969193</td>\n",
       "      <td>0.134995</td>\n",
       "      <td>0.770774</td>\n",
       "      <td>0.214716</td>\n",
       "      <td>0.847183</td>\n",
       "      <td>0.354002</td>\n",
       "      <td>0.866825</td>\n",
       "      <td>0.603695</td>\n",
       "      <td>0.739574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>{'C': 0.001, 'penalty': 'l1'}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013917</td>\n",
       "      <td>0.694881</td>\n",
       "      <td>0.019352</td>\n",
       "      <td>0.877989</td>\n",
       "      <td>0.061146</td>\n",
       "      <td>0.833401</td>\n",
       "      <td>0.116081</td>\n",
       "      <td>0.815211</td>\n",
       "      <td>0.227095</td>\n",
       "      <td>0.800939</td>\n",
       "      <td>0.334679</td>\n",
       "      <td>0.782331</td>\n",
       "      <td>0.544850</td>\n",
       "      <td>0.592306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>{'C': 0.001, 'penalty': 'l2'}</td>\n",
       "      <td>0.872211</td>\n",
       "      <td>0.012139</td>\n",
       "      <td>0.880892</td>\n",
       "      <td>0.024532</td>\n",
       "      <td>0.875963</td>\n",
       "      <td>0.061005</td>\n",
       "      <td>0.857925</td>\n",
       "      <td>0.119497</td>\n",
       "      <td>0.832489</td>\n",
       "      <td>0.231908</td>\n",
       "      <td>0.819247</td>\n",
       "      <td>0.342329</td>\n",
       "      <td>0.788553</td>\n",
       "      <td>0.549183</td>\n",
       "      <td>0.618635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>{'C': 1, 'penalty': 'l2'}</td>\n",
       "      <td>0.839757</td>\n",
       "      <td>0.011687</td>\n",
       "      <td>0.856057</td>\n",
       "      <td>0.023840</td>\n",
       "      <td>0.868869</td>\n",
       "      <td>0.060511</td>\n",
       "      <td>0.857925</td>\n",
       "      <td>0.119497</td>\n",
       "      <td>0.837809</td>\n",
       "      <td>0.233390</td>\n",
       "      <td>0.823402</td>\n",
       "      <td>0.344065</td>\n",
       "      <td>0.791289</td>\n",
       "      <td>0.551089</td>\n",
       "      <td>0.624866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>{'C': 10, 'penalty': 'l1'}</td>\n",
       "      <td>0.830629</td>\n",
       "      <td>0.011560</td>\n",
       "      <td>0.854536</td>\n",
       "      <td>0.023798</td>\n",
       "      <td>0.869072</td>\n",
       "      <td>0.060525</td>\n",
       "      <td>0.858026</td>\n",
       "      <td>0.119511</td>\n",
       "      <td>0.838012</td>\n",
       "      <td>0.233447</td>\n",
       "      <td>0.823301</td>\n",
       "      <td>0.344023</td>\n",
       "      <td>0.791431</td>\n",
       "      <td>0.551188</td>\n",
       "      <td>0.624868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>{'C': 10, 'penalty': 'l2'}</td>\n",
       "      <td>0.833671</td>\n",
       "      <td>0.011602</td>\n",
       "      <td>0.855043</td>\n",
       "      <td>0.023812</td>\n",
       "      <td>0.868869</td>\n",
       "      <td>0.060511</td>\n",
       "      <td>0.857722</td>\n",
       "      <td>0.119469</td>\n",
       "      <td>0.837961</td>\n",
       "      <td>0.233433</td>\n",
       "      <td>0.823368</td>\n",
       "      <td>0.344051</td>\n",
       "      <td>0.791411</td>\n",
       "      <td>0.551174</td>\n",
       "      <td>0.624857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>AB</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'algorithm': 'SAMME', 'n_estimators': 1}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013917</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.027849</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.069643</td>\n",
       "      <td>0.711796</td>\n",
       "      <td>0.099143</td>\n",
       "      <td>0.701409</td>\n",
       "      <td>0.195393</td>\n",
       "      <td>0.800939</td>\n",
       "      <td>0.334679</td>\n",
       "      <td>0.880566</td>\n",
       "      <td>0.613265</td>\n",
       "      <td>0.550781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>AB</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'algorithm': 'SAMME', 'n_estimators': 10}</td>\n",
       "      <td>0.808316</td>\n",
       "      <td>0.011250</td>\n",
       "      <td>0.874303</td>\n",
       "      <td>0.024348</td>\n",
       "      <td>0.897244</td>\n",
       "      <td>0.062487</td>\n",
       "      <td>0.826915</td>\n",
       "      <td>0.115178</td>\n",
       "      <td>0.817896</td>\n",
       "      <td>0.227843</td>\n",
       "      <td>0.793812</td>\n",
       "      <td>0.331701</td>\n",
       "      <td>0.797937</td>\n",
       "      <td>0.555719</td>\n",
       "      <td>0.603653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>AB</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'algorithm': 'SAMME', 'n_estimators': 100}</td>\n",
       "      <td>0.826572</td>\n",
       "      <td>0.011504</td>\n",
       "      <td>0.842879</td>\n",
       "      <td>0.023473</td>\n",
       "      <td>0.866234</td>\n",
       "      <td>0.060327</td>\n",
       "      <td>0.847385</td>\n",
       "      <td>0.118029</td>\n",
       "      <td>0.820582</td>\n",
       "      <td>0.228591</td>\n",
       "      <td>0.791177</td>\n",
       "      <td>0.330600</td>\n",
       "      <td>0.784783</td>\n",
       "      <td>0.546558</td>\n",
       "      <td>0.606189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>AB</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'algorithm': 'SAMME.R', 'n_estimators': 1}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013917</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.027849</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.069643</td>\n",
       "      <td>0.711796</td>\n",
       "      <td>0.099143</td>\n",
       "      <td>0.701409</td>\n",
       "      <td>0.195393</td>\n",
       "      <td>0.800939</td>\n",
       "      <td>0.334679</td>\n",
       "      <td>0.880566</td>\n",
       "      <td>0.613265</td>\n",
       "      <td>0.550781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>AB</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'algorithm': 'SAMME.R', 'n_estimators': 10}</td>\n",
       "      <td>0.824544</td>\n",
       "      <td>0.011475</td>\n",
       "      <td>0.829194</td>\n",
       "      <td>0.023092</td>\n",
       "      <td>0.847588</td>\n",
       "      <td>0.059029</td>\n",
       "      <td>0.835124</td>\n",
       "      <td>0.116321</td>\n",
       "      <td>0.825750</td>\n",
       "      <td>0.230031</td>\n",
       "      <td>0.812492</td>\n",
       "      <td>0.339506</td>\n",
       "      <td>0.803976</td>\n",
       "      <td>0.559925</td>\n",
       "      <td>0.612352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>AB</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'algorithm': 'SAMME.R', 'n_estimators': 100}</td>\n",
       "      <td>0.831643</td>\n",
       "      <td>0.011574</td>\n",
       "      <td>0.855550</td>\n",
       "      <td>0.023826</td>\n",
       "      <td>0.870288</td>\n",
       "      <td>0.060609</td>\n",
       "      <td>0.859141</td>\n",
       "      <td>0.119666</td>\n",
       "      <td>0.838265</td>\n",
       "      <td>0.233517</td>\n",
       "      <td>0.823706</td>\n",
       "      <td>0.344192</td>\n",
       "      <td>0.792080</td>\n",
       "      <td>0.551639</td>\n",
       "      <td>0.624863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 'sqrt', 'min_...</td>\n",
       "      <td>0.892495</td>\n",
       "      <td>0.012421</td>\n",
       "      <td>0.884440</td>\n",
       "      <td>0.024631</td>\n",
       "      <td>0.867653</td>\n",
       "      <td>0.060426</td>\n",
       "      <td>0.857013</td>\n",
       "      <td>0.119370</td>\n",
       "      <td>0.831982</td>\n",
       "      <td>0.231767</td>\n",
       "      <td>0.807898</td>\n",
       "      <td>0.337587</td>\n",
       "      <td>0.782392</td>\n",
       "      <td>0.544893</td>\n",
       "      <td>0.611993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 'sqrt', 'min_...</td>\n",
       "      <td>0.909736</td>\n",
       "      <td>0.012661</td>\n",
       "      <td>0.888495</td>\n",
       "      <td>0.024743</td>\n",
       "      <td>0.884272</td>\n",
       "      <td>0.061583</td>\n",
       "      <td>0.864613</td>\n",
       "      <td>0.120429</td>\n",
       "      <td>0.832286</td>\n",
       "      <td>0.231852</td>\n",
       "      <td>0.820801</td>\n",
       "      <td>0.342979</td>\n",
       "      <td>0.787945</td>\n",
       "      <td>0.548760</td>\n",
       "      <td>0.621082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 'sqrt', 'min_...</td>\n",
       "      <td>0.911765</td>\n",
       "      <td>0.012689</td>\n",
       "      <td>0.895590</td>\n",
       "      <td>0.024941</td>\n",
       "      <td>0.872923</td>\n",
       "      <td>0.060793</td>\n",
       "      <td>0.859242</td>\n",
       "      <td>0.119680</td>\n",
       "      <td>0.828739</td>\n",
       "      <td>0.230864</td>\n",
       "      <td>0.804114</td>\n",
       "      <td>0.336006</td>\n",
       "      <td>0.781541</td>\n",
       "      <td>0.544300</td>\n",
       "      <td>0.610145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 'sqrt', 'min_...</td>\n",
       "      <td>0.905680</td>\n",
       "      <td>0.012605</td>\n",
       "      <td>0.889002</td>\n",
       "      <td>0.024758</td>\n",
       "      <td>0.886299</td>\n",
       "      <td>0.061725</td>\n",
       "      <td>0.864208</td>\n",
       "      <td>0.120372</td>\n",
       "      <td>0.831779</td>\n",
       "      <td>0.231711</td>\n",
       "      <td>0.819112</td>\n",
       "      <td>0.342273</td>\n",
       "      <td>0.787520</td>\n",
       "      <td>0.548464</td>\n",
       "      <td>0.620299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 'log2', 'min_...</td>\n",
       "      <td>0.889452</td>\n",
       "      <td>0.012379</td>\n",
       "      <td>0.878865</td>\n",
       "      <td>0.024475</td>\n",
       "      <td>0.867248</td>\n",
       "      <td>0.060398</td>\n",
       "      <td>0.856810</td>\n",
       "      <td>0.119342</td>\n",
       "      <td>0.830310</td>\n",
       "      <td>0.231301</td>\n",
       "      <td>0.818200</td>\n",
       "      <td>0.341892</td>\n",
       "      <td>0.786324</td>\n",
       "      <td>0.547631</td>\n",
       "      <td>0.616561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 'log2', 'min_...</td>\n",
       "      <td>0.894523</td>\n",
       "      <td>0.012449</td>\n",
       "      <td>0.894577</td>\n",
       "      <td>0.024913</td>\n",
       "      <td>0.883259</td>\n",
       "      <td>0.061513</td>\n",
       "      <td>0.861674</td>\n",
       "      <td>0.120019</td>\n",
       "      <td>0.836137</td>\n",
       "      <td>0.232924</td>\n",
       "      <td>0.822524</td>\n",
       "      <td>0.343698</td>\n",
       "      <td>0.789019</td>\n",
       "      <td>0.549508</td>\n",
       "      <td>0.622608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 'log2', 'min_...</td>\n",
       "      <td>0.895538</td>\n",
       "      <td>0.012463</td>\n",
       "      <td>0.881399</td>\n",
       "      <td>0.024546</td>\n",
       "      <td>0.875557</td>\n",
       "      <td>0.060976</td>\n",
       "      <td>0.855188</td>\n",
       "      <td>0.119116</td>\n",
       "      <td>0.830006</td>\n",
       "      <td>0.231217</td>\n",
       "      <td>0.819112</td>\n",
       "      <td>0.342273</td>\n",
       "      <td>0.787418</td>\n",
       "      <td>0.548393</td>\n",
       "      <td>0.617727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 'log2', 'min_...</td>\n",
       "      <td>0.897566</td>\n",
       "      <td>0.012492</td>\n",
       "      <td>0.891536</td>\n",
       "      <td>0.024828</td>\n",
       "      <td>0.881638</td>\n",
       "      <td>0.061400</td>\n",
       "      <td>0.863498</td>\n",
       "      <td>0.120273</td>\n",
       "      <td>0.836796</td>\n",
       "      <td>0.233108</td>\n",
       "      <td>0.823909</td>\n",
       "      <td>0.344277</td>\n",
       "      <td>0.789810</td>\n",
       "      <td>0.550059</td>\n",
       "      <td>0.623095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 50, 'max_features': 'sqrt', 'min...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013917</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.027849</td>\n",
       "      <td>0.838670</td>\n",
       "      <td>0.058408</td>\n",
       "      <td>0.919335</td>\n",
       "      <td>0.128051</td>\n",
       "      <td>0.925618</td>\n",
       "      <td>0.257851</td>\n",
       "      <td>0.911127</td>\n",
       "      <td>0.380722</td>\n",
       "      <td>0.871770</td>\n",
       "      <td>0.607139</td>\n",
       "      <td>0.764817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 50, 'max_features': 'sqrt', 'min...</td>\n",
       "      <td>0.952333</td>\n",
       "      <td>0.013254</td>\n",
       "      <td>0.954384</td>\n",
       "      <td>0.026578</td>\n",
       "      <td>0.954601</td>\n",
       "      <td>0.066481</td>\n",
       "      <td>0.949027</td>\n",
       "      <td>0.132186</td>\n",
       "      <td>0.933877</td>\n",
       "      <td>0.260152</td>\n",
       "      <td>0.918322</td>\n",
       "      <td>0.383728</td>\n",
       "      <td>0.880627</td>\n",
       "      <td>0.613308</td>\n",
       "      <td>0.779924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 50, 'max_features': 'sqrt', 'min...</td>\n",
       "      <td>0.953347</td>\n",
       "      <td>0.013268</td>\n",
       "      <td>0.945261</td>\n",
       "      <td>0.026324</td>\n",
       "      <td>0.943859</td>\n",
       "      <td>0.065733</td>\n",
       "      <td>0.932509</td>\n",
       "      <td>0.129886</td>\n",
       "      <td>0.911532</td>\n",
       "      <td>0.253927</td>\n",
       "      <td>0.894643</td>\n",
       "      <td>0.373834</td>\n",
       "      <td>0.854219</td>\n",
       "      <td>0.594916</td>\n",
       "      <td>0.733735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 50, 'max_features': 'sqrt', 'min...</td>\n",
       "      <td>0.959432</td>\n",
       "      <td>0.013353</td>\n",
       "      <td>0.955398</td>\n",
       "      <td>0.026607</td>\n",
       "      <td>0.949737</td>\n",
       "      <td>0.066143</td>\n",
       "      <td>0.940717</td>\n",
       "      <td>0.131029</td>\n",
       "      <td>0.919437</td>\n",
       "      <td>0.256129</td>\n",
       "      <td>0.903831</td>\n",
       "      <td>0.377673</td>\n",
       "      <td>0.866602</td>\n",
       "      <td>0.603540</td>\n",
       "      <td>0.754929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 50, 'max_features': 'log2', 'min...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013917</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.027849</td>\n",
       "      <td>0.846777</td>\n",
       "      <td>0.058972</td>\n",
       "      <td>0.923389</td>\n",
       "      <td>0.128615</td>\n",
       "      <td>0.925517</td>\n",
       "      <td>0.257823</td>\n",
       "      <td>0.910147</td>\n",
       "      <td>0.380313</td>\n",
       "      <td>0.870898</td>\n",
       "      <td>0.606532</td>\n",
       "      <td>0.763718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 50, 'max_features': 'log2', 'min...</td>\n",
       "      <td>0.968560</td>\n",
       "      <td>0.013480</td>\n",
       "      <td>0.953371</td>\n",
       "      <td>0.026550</td>\n",
       "      <td>0.952979</td>\n",
       "      <td>0.066368</td>\n",
       "      <td>0.947102</td>\n",
       "      <td>0.131918</td>\n",
       "      <td>0.936056</td>\n",
       "      <td>0.260759</td>\n",
       "      <td>0.920754</td>\n",
       "      <td>0.384745</td>\n",
       "      <td>0.879654</td>\n",
       "      <td>0.612630</td>\n",
       "      <td>0.780529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 50, 'max_features': 'log2', 'min...</td>\n",
       "      <td>0.954361</td>\n",
       "      <td>0.013282</td>\n",
       "      <td>0.953877</td>\n",
       "      <td>0.026564</td>\n",
       "      <td>0.942440</td>\n",
       "      <td>0.065634</td>\n",
       "      <td>0.931901</td>\n",
       "      <td>0.129801</td>\n",
       "      <td>0.911735</td>\n",
       "      <td>0.253984</td>\n",
       "      <td>0.894541</td>\n",
       "      <td>0.373791</td>\n",
       "      <td>0.855191</td>\n",
       "      <td>0.595593</td>\n",
       "      <td>0.734312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 50, 'max_features': 'log2', 'min...</td>\n",
       "      <td>0.958418</td>\n",
       "      <td>0.013339</td>\n",
       "      <td>0.956918</td>\n",
       "      <td>0.026649</td>\n",
       "      <td>0.951155</td>\n",
       "      <td>0.066241</td>\n",
       "      <td>0.940312</td>\n",
       "      <td>0.130972</td>\n",
       "      <td>0.922173</td>\n",
       "      <td>0.256892</td>\n",
       "      <td>0.903223</td>\n",
       "      <td>0.377419</td>\n",
       "      <td>0.867473</td>\n",
       "      <td>0.604147</td>\n",
       "      <td>0.755189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>SVM</td>\n",
       "      <td>LinearSVC(C=10, class_weight=None, dual=True, ...</td>\n",
       "      <td>{'C': 0.001}</td>\n",
       "      <td>0.891481</td>\n",
       "      <td>0.012407</td>\n",
       "      <td>0.892043</td>\n",
       "      <td>0.024842</td>\n",
       "      <td>0.880219</td>\n",
       "      <td>0.061301</td>\n",
       "      <td>0.863296</td>\n",
       "      <td>0.120245</td>\n",
       "      <td>0.839380</td>\n",
       "      <td>0.233828</td>\n",
       "      <td>0.823571</td>\n",
       "      <td>0.344136</td>\n",
       "      <td>0.791999</td>\n",
       "      <td>0.551583</td>\n",
       "      <td>0.625333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>SVM</td>\n",
       "      <td>LinearSVC(C=10, class_weight=None, dual=True, ...</td>\n",
       "      <td>{'C': 0.01}</td>\n",
       "      <td>0.885396</td>\n",
       "      <td>0.012322</td>\n",
       "      <td>0.887988</td>\n",
       "      <td>0.024729</td>\n",
       "      <td>0.876571</td>\n",
       "      <td>0.061047</td>\n",
       "      <td>0.860053</td>\n",
       "      <td>0.119793</td>\n",
       "      <td>0.838670</td>\n",
       "      <td>0.233630</td>\n",
       "      <td>0.824078</td>\n",
       "      <td>0.344348</td>\n",
       "      <td>0.791897</td>\n",
       "      <td>0.551512</td>\n",
       "      <td>0.625729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>SVM</td>\n",
       "      <td>LinearSVC(C=10, class_weight=None, dual=True, ...</td>\n",
       "      <td>{'C': 0.1}</td>\n",
       "      <td>0.880325</td>\n",
       "      <td>0.012252</td>\n",
       "      <td>0.880385</td>\n",
       "      <td>0.024518</td>\n",
       "      <td>0.872720</td>\n",
       "      <td>0.060779</td>\n",
       "      <td>0.858938</td>\n",
       "      <td>0.119638</td>\n",
       "      <td>0.837708</td>\n",
       "      <td>0.233362</td>\n",
       "      <td>0.823639</td>\n",
       "      <td>0.344164</td>\n",
       "      <td>0.792140</td>\n",
       "      <td>0.551682</td>\n",
       "      <td>0.625592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>SVM</td>\n",
       "      <td>LinearSVC(C=10, class_weight=None, dual=True, ...</td>\n",
       "      <td>{'C': 1}</td>\n",
       "      <td>0.884381</td>\n",
       "      <td>0.012308</td>\n",
       "      <td>0.877851</td>\n",
       "      <td>0.024447</td>\n",
       "      <td>0.872112</td>\n",
       "      <td>0.060737</td>\n",
       "      <td>0.859141</td>\n",
       "      <td>0.119666</td>\n",
       "      <td>0.837708</td>\n",
       "      <td>0.233362</td>\n",
       "      <td>0.823706</td>\n",
       "      <td>0.344192</td>\n",
       "      <td>0.791978</td>\n",
       "      <td>0.551569</td>\n",
       "      <td>0.625581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>SVM</td>\n",
       "      <td>LinearSVC(C=10, class_weight=None, dual=True, ...</td>\n",
       "      <td>{'C': 10}</td>\n",
       "      <td>0.884381</td>\n",
       "      <td>0.012308</td>\n",
       "      <td>0.875824</td>\n",
       "      <td>0.024391</td>\n",
       "      <td>0.875557</td>\n",
       "      <td>0.060976</td>\n",
       "      <td>0.857722</td>\n",
       "      <td>0.119469</td>\n",
       "      <td>0.837404</td>\n",
       "      <td>0.233277</td>\n",
       "      <td>0.823672</td>\n",
       "      <td>0.344178</td>\n",
       "      <td>0.791613</td>\n",
       "      <td>0.551315</td>\n",
       "      <td>0.625121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   model_name                                              model  \\\n",
       "0          LR  LogisticRegression(C=10, class_weight=None, du...   \n",
       "1          LR  LogisticRegression(C=10, class_weight=None, du...   \n",
       "2          LR  LogisticRegression(C=10, class_weight=None, du...   \n",
       "3          LR  LogisticRegression(C=10, class_weight=None, du...   \n",
       "4          LR  LogisticRegression(C=10, class_weight=None, du...   \n",
       "5          LR  LogisticRegression(C=10, class_weight=None, du...   \n",
       "6          LR  LogisticRegression(C=10, class_weight=None, du...   \n",
       "7          LR  LogisticRegression(C=10, class_weight=None, du...   \n",
       "8          DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "9          DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "10         DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "11         DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "12         DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "13         DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "14         DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "15         DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "16         DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "17         DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "18         DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "19         DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "20         DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "21         DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "22         DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "23         DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "24         DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "25         DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "26         DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "27         DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "28         LR  LogisticRegression(C=10, class_weight=None, du...   \n",
       "29         LR  LogisticRegression(C=10, class_weight=None, du...   \n",
       "..        ...                                                ...   \n",
       "33         LR  LogisticRegression(C=10, class_weight=None, du...   \n",
       "34         LR  LogisticRegression(C=10, class_weight=None, du...   \n",
       "35         LR  LogisticRegression(C=10, class_weight=None, du...   \n",
       "36         AB  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "37         AB  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "38         AB  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "39         AB  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "40         AB  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "41         AB  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "42         RF  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "43         RF  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "44         RF  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "45         RF  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "46         RF  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "47         RF  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "48         RF  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "49         RF  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "50         RF  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "51         RF  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "52         RF  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "53         RF  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "54         RF  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "55         RF  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "56         RF  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "57         RF  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "58        SVM  LinearSVC(C=10, class_weight=None, dual=True, ...   \n",
       "59        SVM  LinearSVC(C=10, class_weight=None, dual=True, ...   \n",
       "60        SVM  LinearSVC(C=10, class_weight=None, dual=True, ...   \n",
       "61        SVM  LinearSVC(C=10, class_weight=None, dual=True, ...   \n",
       "62        SVM  LinearSVC(C=10, class_weight=None, dual=True, ...   \n",
       "\n",
       "                                           parameters    p_at_1    r_at_1  \\\n",
       "0                       {'C': 0.001, 'penalty': 'l1'}  1.000000  0.013917   \n",
       "1                       {'C': 0.001, 'penalty': 'l2'}  0.872211  0.012139   \n",
       "2                         {'C': 0.1, 'penalty': 'l1'}  0.864097  0.012026   \n",
       "3                         {'C': 0.1, 'penalty': 'l2'}  0.882353  0.012280   \n",
       "4                           {'C': 1, 'penalty': 'l1'}  0.834686  0.011617   \n",
       "5                           {'C': 1, 'penalty': 'l2'}  0.839757  0.011687   \n",
       "6                          {'C': 10, 'penalty': 'l1'}  0.830629  0.011560   \n",
       "7                          {'C': 10, 'penalty': 'l2'}  0.833671  0.011602   \n",
       "8   {'criterion': 'gini', 'max_depth': 1, 'min_sam...  1.000000  0.013917   \n",
       "9   {'criterion': 'gini', 'max_depth': 1, 'min_sam...  1.000000  0.013917   \n",
       "10  {'criterion': 'gini', 'max_depth': 5, 'min_sam...  0.887424  0.012351   \n",
       "11  {'criterion': 'gini', 'max_depth': 5, 'min_sam...  0.887424  0.012351   \n",
       "12  {'criterion': 'gini', 'max_depth': 10, 'min_sa...  0.781947  0.010883   \n",
       "13  {'criterion': 'gini', 'max_depth': 10, 'min_sa...  0.790061  0.010996   \n",
       "14  {'criterion': 'gini', 'max_depth': 50, 'min_sa...  1.000000  0.013917   \n",
       "15  {'criterion': 'gini', 'max_depth': 50, 'min_sa...  1.000000  0.013917   \n",
       "16  {'criterion': 'gini', 'max_depth': 100, 'min_s...  1.000000  0.013917   \n",
       "17  {'criterion': 'gini', 'max_depth': 100, 'min_s...  1.000000  0.013917   \n",
       "18  {'criterion': 'entropy', 'max_depth': 1, 'min_...  1.000000  0.013917   \n",
       "19  {'criterion': 'entropy', 'max_depth': 1, 'min_...  1.000000  0.013917   \n",
       "20  {'criterion': 'entropy', 'max_depth': 5, 'min_...  0.834686  0.011617   \n",
       "21  {'criterion': 'entropy', 'max_depth': 5, 'min_...  0.834686  0.011617   \n",
       "22  {'criterion': 'entropy', 'max_depth': 10, 'min...  0.758621  0.010558   \n",
       "23  {'criterion': 'entropy', 'max_depth': 10, 'min...  0.755578  0.010516   \n",
       "24  {'criterion': 'entropy', 'max_depth': 50, 'min...  1.000000  0.013917   \n",
       "25  {'criterion': 'entropy', 'max_depth': 50, 'min...  1.000000  0.013917   \n",
       "26  {'criterion': 'entropy', 'max_depth': 100, 'mi...  1.000000  0.013917   \n",
       "27  {'criterion': 'entropy', 'max_depth': 100, 'mi...  1.000000  0.013917   \n",
       "28                      {'C': 0.001, 'penalty': 'l1'}  1.000000  0.013917   \n",
       "29                      {'C': 0.001, 'penalty': 'l2'}  0.872211  0.012139   \n",
       "..                                                ...       ...       ...   \n",
       "33                          {'C': 1, 'penalty': 'l2'}  0.839757  0.011687   \n",
       "34                         {'C': 10, 'penalty': 'l1'}  0.830629  0.011560   \n",
       "35                         {'C': 10, 'penalty': 'l2'}  0.833671  0.011602   \n",
       "36          {'algorithm': 'SAMME', 'n_estimators': 1}  1.000000  0.013917   \n",
       "37         {'algorithm': 'SAMME', 'n_estimators': 10}  0.808316  0.011250   \n",
       "38        {'algorithm': 'SAMME', 'n_estimators': 100}  0.826572  0.011504   \n",
       "39        {'algorithm': 'SAMME.R', 'n_estimators': 1}  1.000000  0.013917   \n",
       "40       {'algorithm': 'SAMME.R', 'n_estimators': 10}  0.824544  0.011475   \n",
       "41      {'algorithm': 'SAMME.R', 'n_estimators': 100}  0.831643  0.011574   \n",
       "42  {'max_depth': 5, 'max_features': 'sqrt', 'min_...  0.892495  0.012421   \n",
       "43  {'max_depth': 5, 'max_features': 'sqrt', 'min_...  0.909736  0.012661   \n",
       "44  {'max_depth': 5, 'max_features': 'sqrt', 'min_...  0.911765  0.012689   \n",
       "45  {'max_depth': 5, 'max_features': 'sqrt', 'min_...  0.905680  0.012605   \n",
       "46  {'max_depth': 5, 'max_features': 'log2', 'min_...  0.889452  0.012379   \n",
       "47  {'max_depth': 5, 'max_features': 'log2', 'min_...  0.894523  0.012449   \n",
       "48  {'max_depth': 5, 'max_features': 'log2', 'min_...  0.895538  0.012463   \n",
       "49  {'max_depth': 5, 'max_features': 'log2', 'min_...  0.897566  0.012492   \n",
       "50  {'max_depth': 50, 'max_features': 'sqrt', 'min...  1.000000  0.013917   \n",
       "51  {'max_depth': 50, 'max_features': 'sqrt', 'min...  0.952333  0.013254   \n",
       "52  {'max_depth': 50, 'max_features': 'sqrt', 'min...  0.953347  0.013268   \n",
       "53  {'max_depth': 50, 'max_features': 'sqrt', 'min...  0.959432  0.013353   \n",
       "54  {'max_depth': 50, 'max_features': 'log2', 'min...  1.000000  0.013917   \n",
       "55  {'max_depth': 50, 'max_features': 'log2', 'min...  0.968560  0.013480   \n",
       "56  {'max_depth': 50, 'max_features': 'log2', 'min...  0.954361  0.013282   \n",
       "57  {'max_depth': 50, 'max_features': 'log2', 'min...  0.958418  0.013339   \n",
       "58                                       {'C': 0.001}  0.891481  0.012407   \n",
       "59                                        {'C': 0.01}  0.885396  0.012322   \n",
       "60                                         {'C': 0.1}  0.880325  0.012252   \n",
       "61                                           {'C': 1}  0.884381  0.012308   \n",
       "62                                          {'C': 10}  0.884381  0.012308   \n",
       "\n",
       "      p_at_2    r_at_2    p_at_5    r_at_5   p_at_10   r_at_10   p_at_20  \\\n",
       "0   0.694881  0.019352  0.877989  0.061146  0.833401  0.116081  0.815211   \n",
       "1   0.880892  0.024532  0.875963  0.061005  0.857925  0.119497  0.832489   \n",
       "2   0.866700  0.024137  0.872112  0.060737  0.858533  0.119582  0.837606   \n",
       "3   0.872783  0.024306  0.871301  0.060680  0.859141  0.119666  0.838316   \n",
       "4   0.855043  0.023812  0.869274  0.060539  0.858330  0.119553  0.838164   \n",
       "5   0.856057  0.023840  0.868869  0.060511  0.857925  0.119497  0.837809   \n",
       "6   0.854536  0.023798  0.869072  0.060525  0.858026  0.119511  0.838062   \n",
       "7   0.855043  0.023812  0.868869  0.060511  0.857722  0.119469  0.837961   \n",
       "8   1.000000  0.027849  1.000000  0.069643  0.711796  0.099143  0.701409   \n",
       "9   1.000000  0.027849  1.000000  0.069643  0.711796  0.099143  0.701409   \n",
       "10  0.811455  0.022598  0.837657  0.058337  0.787191  0.109645  0.799301   \n",
       "11  0.811455  0.022598  0.837657  0.058337  0.787191  0.109645  0.799301   \n",
       "12  0.871769  0.024278  0.877989  0.061146  0.847994  0.118114  0.830563   \n",
       "13  0.872276  0.024292  0.875557  0.060976  0.847791  0.118085  0.829905   \n",
       "14  1.000000  0.027849  1.000000  0.069643  1.000000  0.139286  0.761603   \n",
       "15  1.000000  0.027849  1.000000  0.069643  0.910113  0.126766  0.784607   \n",
       "16  1.000000  0.027849  1.000000  0.069643  1.000000  0.139286  0.744224   \n",
       "17  1.000000  0.027849  1.000000  0.069643  0.962910  0.134120  0.769102   \n",
       "18  1.000000  0.027849  1.000000  0.069643  0.711796  0.099143  0.701409   \n",
       "19  1.000000  0.027849  1.000000  0.069643  0.711796  0.099143  0.701409   \n",
       "20  0.783578  0.021822  0.878192  0.061160  0.807458  0.112468  0.810752   \n",
       "21  0.782565  0.021793  0.878395  0.061174  0.807560  0.112482  0.810651   \n",
       "22  0.879372  0.024489  0.884070  0.061569  0.858127  0.119525  0.842623   \n",
       "23  0.877851  0.024447  0.883462  0.061527  0.857823  0.119483  0.842673   \n",
       "24  1.000000  0.027849  1.000000  0.069643  0.976794  0.136054  0.768950   \n",
       "25  1.000000  0.027849  1.000000  0.069643  0.900385  0.125411  0.790231   \n",
       "26  1.000000  0.027849  1.000000  0.069643  1.000000  0.139286  0.747669   \n",
       "27  1.000000  0.027849  1.000000  0.069643  0.969193  0.134995  0.770774   \n",
       "28  0.694881  0.019352  0.877989  0.061146  0.833401  0.116081  0.815211   \n",
       "29  0.880892  0.024532  0.875963  0.061005  0.857925  0.119497  0.832489   \n",
       "..       ...       ...       ...       ...       ...       ...       ...   \n",
       "33  0.856057  0.023840  0.868869  0.060511  0.857925  0.119497  0.837809   \n",
       "34  0.854536  0.023798  0.869072  0.060525  0.858026  0.119511  0.838012   \n",
       "35  0.855043  0.023812  0.868869  0.060511  0.857722  0.119469  0.837961   \n",
       "36  1.000000  0.027849  1.000000  0.069643  0.711796  0.099143  0.701409   \n",
       "37  0.874303  0.024348  0.897244  0.062487  0.826915  0.115178  0.817896   \n",
       "38  0.842879  0.023473  0.866234  0.060327  0.847385  0.118029  0.820582   \n",
       "39  1.000000  0.027849  1.000000  0.069643  0.711796  0.099143  0.701409   \n",
       "40  0.829194  0.023092  0.847588  0.059029  0.835124  0.116321  0.825750   \n",
       "41  0.855550  0.023826  0.870288  0.060609  0.859141  0.119666  0.838265   \n",
       "42  0.884440  0.024631  0.867653  0.060426  0.857013  0.119370  0.831982   \n",
       "43  0.888495  0.024743  0.884272  0.061583  0.864613  0.120429  0.832286   \n",
       "44  0.895590  0.024941  0.872923  0.060793  0.859242  0.119680  0.828739   \n",
       "45  0.889002  0.024758  0.886299  0.061725  0.864208  0.120372  0.831779   \n",
       "46  0.878865  0.024475  0.867248  0.060398  0.856810  0.119342  0.830310   \n",
       "47  0.894577  0.024913  0.883259  0.061513  0.861674  0.120019  0.836137   \n",
       "48  0.881399  0.024546  0.875557  0.060976  0.855188  0.119116  0.830006   \n",
       "49  0.891536  0.024828  0.881638  0.061400  0.863498  0.120273  0.836796   \n",
       "50  1.000000  0.027849  0.838670  0.058408  0.919335  0.128051  0.925618   \n",
       "51  0.954384  0.026578  0.954601  0.066481  0.949027  0.132186  0.933877   \n",
       "52  0.945261  0.026324  0.943859  0.065733  0.932509  0.129886  0.911532   \n",
       "53  0.955398  0.026607  0.949737  0.066143  0.940717  0.131029  0.919437   \n",
       "54  1.000000  0.027849  0.846777  0.058972  0.923389  0.128615  0.925517   \n",
       "55  0.953371  0.026550  0.952979  0.066368  0.947102  0.131918  0.936056   \n",
       "56  0.953877  0.026564  0.942440  0.065634  0.931901  0.129801  0.911735   \n",
       "57  0.956918  0.026649  0.951155  0.066241  0.940312  0.130972  0.922173   \n",
       "58  0.892043  0.024842  0.880219  0.061301  0.863296  0.120245  0.839380   \n",
       "59  0.887988  0.024729  0.876571  0.061047  0.860053  0.119793  0.838670   \n",
       "60  0.880385  0.024518  0.872720  0.060779  0.858938  0.119638  0.837708   \n",
       "61  0.877851  0.024447  0.872112  0.060737  0.859141  0.119666  0.837708   \n",
       "62  0.875824  0.024391  0.875557  0.060976  0.857722  0.119469  0.837404   \n",
       "\n",
       "     r_at_20   p_at_30   r_at_30   p_at_50   r_at_50   auc-roc  \n",
       "0   0.227095  0.800939  0.334679  0.782331  0.544850  0.592306  \n",
       "1   0.231908  0.819247  0.342329  0.788553  0.549183  0.618635  \n",
       "2   0.233334  0.823368  0.344051  0.791573  0.551287  0.624384  \n",
       "3   0.233531  0.823706  0.344192  0.791999  0.551583  0.625046  \n",
       "4   0.233489  0.823368  0.344051  0.791695  0.551371  0.624894  \n",
       "5   0.233390  0.823402  0.344065  0.791289  0.551089  0.624866  \n",
       "6   0.233461  0.823335  0.344037  0.791451  0.551202  0.624867  \n",
       "7   0.233433  0.823368  0.344051  0.791411  0.551174  0.624857  \n",
       "8   0.195393  0.800939  0.334679  0.880566  0.613265  0.550781  \n",
       "9   0.195393  0.800939  0.334679  0.880566  0.613265  0.550781  \n",
       "10  0.222663  0.769524  0.321552  0.783993  0.546008  0.610375  \n",
       "11  0.222663  0.769524  0.321552  0.783993  0.546008  0.610375  \n",
       "12  0.231372  0.823808  0.344235  0.792546  0.551964  0.626015  \n",
       "13  0.231188  0.823639  0.344164  0.792323  0.551809  0.625719  \n",
       "14  0.212161  0.841069  0.351447  0.869277  0.605403  0.745723  \n",
       "15  0.218570  0.856405  0.357856  0.863319  0.601253  0.734040  \n",
       "16  0.207320  0.829483  0.346606  0.874040  0.608720  0.748978  \n",
       "17  0.214250  0.846068  0.353536  0.865224  0.602580  0.736847  \n",
       "18  0.195393  0.800939  0.334679  0.880566  0.613265  0.550781  \n",
       "19  0.195393  0.800939  0.334679  0.880566  0.613265  0.550781  \n",
       "20  0.225853  0.767261  0.320606  0.782027  0.544638  0.609640  \n",
       "21  0.225825  0.767295  0.320620  0.781987  0.544610  0.609648  \n",
       "22  0.234731  0.823166  0.343967  0.794917  0.553616  0.625778  \n",
       "23  0.234745  0.822828  0.343825  0.794795  0.553531  0.625747  \n",
       "24  0.214208  0.845967  0.353494  0.867777  0.604359  0.742237  \n",
       "25  0.220136  0.860154  0.359422  0.870067  0.605954  0.733306  \n",
       "26  0.208280  0.831779  0.347566  0.875621  0.609821  0.749111  \n",
       "27  0.214716  0.847183  0.354002  0.866825  0.603695  0.739574  \n",
       "28  0.227095  0.800939  0.334679  0.782331  0.544850  0.592306  \n",
       "29  0.231908  0.819247  0.342329  0.788553  0.549183  0.618635  \n",
       "..       ...       ...       ...       ...       ...       ...  \n",
       "33  0.233390  0.823402  0.344065  0.791289  0.551089  0.624866  \n",
       "34  0.233447  0.823301  0.344023  0.791431  0.551188  0.624868  \n",
       "35  0.233433  0.823368  0.344051  0.791411  0.551174  0.624857  \n",
       "36  0.195393  0.800939  0.334679  0.880566  0.613265  0.550781  \n",
       "37  0.227843  0.793812  0.331701  0.797937  0.555719  0.603653  \n",
       "38  0.228591  0.791177  0.330600  0.784783  0.546558  0.606189  \n",
       "39  0.195393  0.800939  0.334679  0.880566  0.613265  0.550781  \n",
       "40  0.230031  0.812492  0.339506  0.803976  0.559925  0.612352  \n",
       "41  0.233517  0.823706  0.344192  0.792080  0.551639  0.624863  \n",
       "42  0.231767  0.807898  0.337587  0.782392  0.544893  0.611993  \n",
       "43  0.231852  0.820801  0.342979  0.787945  0.548760  0.621082  \n",
       "44  0.230864  0.804114  0.336006  0.781541  0.544300  0.610145  \n",
       "45  0.231711  0.819112  0.342273  0.787520  0.548464  0.620299  \n",
       "46  0.231301  0.818200  0.341892  0.786324  0.547631  0.616561  \n",
       "47  0.232924  0.822524  0.343698  0.789019  0.549508  0.622608  \n",
       "48  0.231217  0.819112  0.342273  0.787418  0.548393  0.617727  \n",
       "49  0.233108  0.823909  0.344277  0.789810  0.550059  0.623095  \n",
       "50  0.257851  0.911127  0.380722  0.871770  0.607139  0.764817  \n",
       "51  0.260152  0.918322  0.383728  0.880627  0.613308  0.779924  \n",
       "52  0.253927  0.894643  0.373834  0.854219  0.594916  0.733735  \n",
       "53  0.256129  0.903831  0.377673  0.866602  0.603540  0.754929  \n",
       "54  0.257823  0.910147  0.380313  0.870898  0.606532  0.763718  \n",
       "55  0.260759  0.920754  0.384745  0.879654  0.612630  0.780529  \n",
       "56  0.253984  0.894541  0.373791  0.855191  0.595593  0.734312  \n",
       "57  0.256892  0.903223  0.377419  0.867473  0.604147  0.755189  \n",
       "58  0.233828  0.823571  0.344136  0.791999  0.551583  0.625333  \n",
       "59  0.233630  0.824078  0.344348  0.791897  0.551512  0.625729  \n",
       "60  0.233362  0.823639  0.344164  0.792140  0.551682  0.625592  \n",
       "61  0.233362  0.823706  0.344192  0.791978  0.551569  0.625581  \n",
       "62  0.233277  0.823672  0.344178  0.791613  0.551315  0.625121  \n",
       "\n",
       "[63 rows x 18 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"With third train set (smallest one):\")\n",
    "pipeline.iterate_over_models(models_to_run, models, parameters_grid, x_train_3, x_test_3, y_train_3, y_test_3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
