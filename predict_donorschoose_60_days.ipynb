{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspired/based on https://github.com/rayidghani/magicloops and https://github.com/dssg/MLforPublicPolicy/blob/master/labs/2019/lab6_feature_generation_sol.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pipeline_v2 as pipeline\n",
    "import importlib\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(pipeline)\n",
    "\n",
    "datafile = \"projects_2012_2013.csv\"\n",
    "data = pd.read_csv(datafile, parse_dates=['date_posted', 'datefullyfunded'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data exploration...\n",
      "\n",
      "Number of rows: 124976\n",
      "\n",
      "Columns and types of data:\n",
      "projectid                                         object\n",
      "teacher_acctid                                    object\n",
      "schoolid                                          object\n",
      "school_ncesid                                    float64\n",
      "school_latitude                                  float64\n",
      "school_longitude                                 float64\n",
      "school_city                                       object\n",
      "school_state                                      object\n",
      "school_metro                                      object\n",
      "school_district                                   object\n",
      "school_county                                     object\n",
      "school_charter                                    object\n",
      "school_magnet                                     object\n",
      "teacher_prefix                                    object\n",
      "primary_focus_subject                             object\n",
      "primary_focus_area                                object\n",
      "secondary_focus_subject                           object\n",
      "secondary_focus_area                              object\n",
      "resource_type                                     object\n",
      "poverty_level                                     object\n",
      "grade_level                                       object\n",
      "total_price_including_optional_support           float64\n",
      "students_reached                                 float64\n",
      "eligible_double_your_impact_match                 object\n",
      "date_posted                               datetime64[ns]\n",
      "datefullyfunded                           datetime64[ns]\n",
      "dtype: object\n",
      "\n",
      "\n",
      "Statistics for selected variables:\n",
      "count    124976.000000\n",
      "mean        654.011811\n",
      "std        1098.015854\n",
      "min          92.000000\n",
      "25%         345.810000\n",
      "50%         510.500000\n",
      "75%         752.960000\n",
      "max      164382.840000\n",
      "Name: total_price_including_optional_support, dtype: float64\n",
      "Number of outliers (>4 standard dev):521\n",
      "\n",
      "\n",
      "count    124917.000000\n",
      "mean         95.445760\n",
      "std         163.481912\n",
      "min           1.000000\n",
      "25%          23.000000\n",
      "50%          30.000000\n",
      "75%         100.000000\n",
      "max       12143.000000\n",
      "Name: students_reached, dtype: float64\n",
      "Number of outliers (>4 standard dev):2063\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Correlation between ['total_price_including_optional_support', 'students_reached']\n",
      "0.1766274350291622\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEICAYAAACj2qi6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAG39JREFUeJzt3X+QFeWd7/H3JxAQTRTQOJcAJXgz5S7qJjGzSn7c3SlJFIwl3i3dxaIiiaTYzeom2bVqhbi75pf36t01Rl2jyw1sMEtEQ5KFMrqEUk/l3r2RqPEHIhJGJDJKRAXR0UQzyff+0c8k7fHMzOM5B85h+LyqTk33t5/ufp7u4XzmdPcMigjMzMxyvKXVHTAzswOHQ8PMzLI5NMzMLJtDw8zMsjk0zMwsm0PDzMyyOTTMzCybQ8MOOpK2S/pwq/uxv0kKSe9q0rYqkj7ZjG3ZgcWhYQcUSZ+X9G+t7ge0V1/M9heHhlkbkTS61X0wG4pDw9qWpEskPSXpJUlbJH0U+BzwZ5L6JD2U2r3uclP1JwBJH5P0M0nPS7q0ah9vkbRY0uNp+a2SJqZl09IlnQWSnpT03MD6kmYP0pePS9qW+vyEpPnDjPHjkv5T0tWSdgOfT/ULJG2WtEfSOknHlNa5RtIOSS9Kul/SfystGyXpc2k8L6XlU0u7/LCkrWm710tSad2h9vkRSY9J2ivpnwFhByWHhrUlSccBFwF/GBFvB04HHgP+B3BLRLwtIt6dsZ0ZwA3Ax4B3AkcCU0pNPg2cDfxxWr4HuL5qMx8CjgNmAf8g6fcj4j+q+yLpMOBaYE7q8weABzOGewqwDTgauFzS2RSB9CfAO4D/A9xcan8v8B5gIvAt4NuSDknL/gY4DzgDOBy4AHiltO6ZwB8C7wb+lOK4MtQ+JR0FfAf4O+Ao4HHggxnjshHIoWHt6tfAWGCGpLdGxPaIeLyO7ZwD3BYRP4yIV4G/B35TWv7nwKUR0ZuWfx44p+oy0Rci4hcR8RDwEMUb7mB+A5wgaVxE7IyITRl9fDoirouI/oj4RerT/4yIzRHRTxFO7xn4yT8i/i0ink/tr6I4TselbX0S+LuI2BKFhyLi+dK+roiIFyLiSeBuivBhmH2eATwaEasj4lfAV4GfZ4zLRiCHhrWliOgBPkvxJr5L0ipJ76xjU+8EdpS2+zJQfhM9BviepBckvQBspgisjlKb8hvkK8DbBunzy8CfAX8B7JT0fUm/l9HHHVXzxwDXlPq0m+Jy0GQASReny0h70/IjKD4BAEyl+CQwmMHGMtQ+q49h1OizHSQcGta2IuJbEfEhije0AK5MX6u9DBxamv8vpemdFG+kAEg6lOIS1YAdFJeTxpdeh0TEUzldrNHndRHxEWASxeW0/13HdnYAf17Vp3ER8f/S/YtLKC4tTYiI8cBefnePYQfwXzP2WW3QffLGY6jyvB1cHBrWliQdJ+lUSWOBXwK/oPgE8AwwTVL5e/dBYJ6kt0rqorgkNWA1cKakD0kaA3yR13/f30hxH+GYtN93SJqb2c3X9UVSh6Sz0r2NV4G+1Oc360ZgiaTj03aPkHRuWvZ2oB94Fhgt6R8o7l0M+DrwJUmdKvyBpHJI1rPP7wPHS/qTdNnu07w+mO0g4tCwdjUWuAJ4juKSytEUN2q/nZY/L+knafrvKX663gN8geLmMADpnsKFqbYztekt7ecaYC3wA0kvAfdQ3JjOUd2XtwAXA09TXN75Y+AvM7f1WxHxPYpPVaskvQg8AsxJi9cBdwA/BX5GEajlS0VfAW4FfgC8CCwDxjWyz4h4DjiX4nw8D3QC//lmx2Ujg/w/95mZWS5/0jAzs2wODbN9TNKN6RcAq183trpvZm+WL0+ZmVm2Efd3bo466qiYNm1aXeu+/PLLHHbYYc3tUAt4HO1npIzF42gvzRzH/fff/1xEvGO4diMuNKZNm8Z9991X17qVSoXu7u7mdqgFPI72M1LG4nG0l2aOQ9LPctr5noaZmWVzaJiZWTaHhpmZZXNomJlZNoeGmZllc2iYmVk2h4aZmWVzaJiZWTaHhpmZZRtxvxHeiI1P7eXji7/fkn1vv+KjLdmvmdmb4U8aZmaWzaFhZmbZHBpmZpbNoWFmZtmGDQ1JyyXtkvRIqfaPkh6T9LCk70kaX1q2RFKPpC2STi/VZ6daj6TFpfp0SRskbZV0i6QxqT42zfek5dOaNWgzM6tPzieNbwCzq2rrgRMi4g+AnwJLACTNAOYBx6d1viZplKRRwPXAHGAGcF5qC3AlcHVEdAJ7gIWpvhDYExHvAq5O7czMrIWGDY2I+CGwu6r2g4joT7P3AFPS9FxgVUS8GhFPAD3AyenVExHbIuI1YBUwV5KAU4HVaf0VwNmlba1I06uBWam9mZm1SDN+T+MC4JY0PZkiRAb0phrAjqr6KcCRwAulACq3nzywTkT0S9qb2j9X3QFJi4BFAB0dHVQqlboG0jEOLj6xf/iG+0C9fa6lr6+vqdtrlZEyDhg5Y/E42ksrxtFQaEi6FOgHVg6UajQLan+iiSHaD7WtNxYjlgJLAbq6uqLe//7wupVruGpja37fcfv87qZty/+VZfsZKWPxONpLK8ZR9zukpAXAmcCsiBh4M+8FppaaTQGeTtO16s8B4yWNTp82yu0HttUraTRwBFWXyczMbP+q65FbSbOBS4CzIuKV0qK1wLz05NN0oBP4MXAv0JmelBpDcbN8bQqbu4Fz0voLgDWlbS1I0+cAd5XCyczMWmDYTxqSbga6gaMk9QKXUTwtNRZYn+5N3xMRfxERmyTdCjxKcdnqwoj4ddrORcA6YBSwPCI2pV1cAqyS9GXgAWBZqi8Dvimph+ITxrwmjNfMzBowbGhExHk1ystq1AbaXw5cXqN+O3B7jfo2iqerquu/BM4drn9mZrb/+DfCzcwsm0PDzMyyOTTMzCybQ8PMzLI5NMzMLJtDw8zMsjk0zMwsm0PDzMyyOTTMzCybQ8PMzLI5NMzMLJtDw8zMsjk0zMwsm0PDzMyyOTTMzCybQ8PMzLI5NMzMLJtDw8zMsjk0zMwsm0PDzMyyOTTMzCybQ8PMzLI5NMzMLJtDw8zMsg0bGpKWS9ol6ZFSbaKk9ZK2pq8TUl2SrpXUI+lhSSeV1lmQ2m+VtKBUf5+kjWmdayVpqH2YmVnr5HzS+AYwu6q2GLgzIjqBO9M8wBygM70WATdAEQDAZcApwMnAZaUQuCG1HVhv9jD7MDOzFhk2NCLih8DuqvJcYEWaXgGcXarfFIV7gPGSJgGnA+sjYndE7AHWA7PTssMj4kcREcBNVduqtQ8zM2uR0XWu1xEROwEiYqeko1N9MrCj1K431Yaq99aoD7WPN5C0iOLTCh0dHVQqlfoGNQ4uPrG/rnUbVW+fa+nr62vq9lplpIwDRs5YPI720opx1Bsag1GNWtRRf1MiYimwFKCrqyu6u7vf7CYAuG7lGq7a2OxDkmf7/O6mbatSqVDvMWgnI2UcMHLG4nG0l1aMo96np55Jl5ZIX3elei8wtdRuCvD0MPUpNepD7cPMzFqk3tBYCww8AbUAWFOqn5+eopoJ7E2XmNYBp0makG6AnwasS8tekjQzPTV1ftW2au3DzMxaZNhrMZJuBrqBoyT1UjwFdQVwq6SFwJPAuan57cAZQA/wCvAJgIjYLelLwL2p3RcjYuDm+qcontAaB9yRXgyxDzMza5FhQyMizhtk0awabQO4cJDtLAeW16jfB5xQo/58rX2YmVnr+DfCzcwsm0PDzMyyOTTMzCybQ8PMzLI5NMzMLJtDw8zMsjk0zMwsm0PDzMyyOTTMzCybQ8PMzLI5NMzMLJtDw8zMsjk0zMwsm0PDzMyyOTTMzCybQ8PMzLI5NMzMLJtDw8zMsjk0zMwsm0PDzMyyOTTMzCybQ8PMzLI5NMzMLJtDw8zMsjUUGpL+WtImSY9IulnSIZKmS9ogaaukWySNSW3HpvmetHxaaTtLUn2LpNNL9dmp1iNpcSN9NTOzxtUdGpImA58GuiLiBGAUMA+4Erg6IjqBPcDCtMpCYE9EvAu4OrVD0oy03vHAbOBrkkZJGgVcD8wBZgDnpbZmZtYijV6eGg2MkzQaOBTYCZwKrE7LVwBnp+m5aZ60fJYkpfqqiHg1Ip4AeoCT06snIrZFxGvAqtTWzMxaZHS9K0bEU5L+CXgS+AXwA+B+4IWI6E/NeoHJaXoysCOt2y9pL3Bkqt9T2nR5nR1V9VNq9UXSImARQEdHB5VKpa4xdYyDi0/sH77hPlBvn2vp6+tr6vZaZaSMA0bOWDyO9tKKcdQdGpImUPzkPx14Afg2xaWkajGwyiDLBqvX+hQUNWpExFJgKUBXV1d0d3cP1fVBXbdyDVdtrPuQNGT7/O6mbatSqVDvMWgnI2UcMHLG4nG0l1aMo5HLUx8GnoiIZyPiV8B3gQ8A49PlKoApwNNpuheYCpCWHwHsLter1hmsbmZmLdJIaDwJzJR0aLo3MQt4FLgbOCe1WQCsSdNr0zxp+V0REak+Lz1dNR3oBH4M3At0pqexxlDcLF/bQH/NzKxBjdzT2CBpNfAToB94gOIS0feBVZK+nGrL0irLgG9K6qH4hDEvbWeTpFspAqcfuDAifg0g6SJgHcWTWcsjYlO9/TUzs8Y1dAE/Ii4DLqsqb6N48qm67S+BcwfZzuXA5TXqtwO3N9JHMzNrHv9GuJmZZXNomJlZNoeGmZllc2iYmVk2h4aZmWVzaJiZWTaHhpmZZXNomJlZNoeGmZllc2iYmVk2h4aZmWVzaJiZWTaHhpmZZXNomJlZNoeGmZllc2iYmVk2h4aZmWVzaJiZWTaHhpmZZXNomJlZNoeGmZllc2iYmVk2h4aZmWVzaJiZWbaGQkPSeEmrJT0mabOk90uaKGm9pK3p64TUVpKuldQj6WFJJ5W2syC13yppQan+Pkkb0zrXSlIj/TUzs8Y0+knjGuA/IuL3gHcDm4HFwJ0R0QncmeYB5gCd6bUIuAFA0kTgMuAU4GTgsoGgSW0Wldab3WB/zcysAXWHhqTDgT8ClgFExGsR8QIwF1iRmq0Azk7Tc4GbonAPMF7SJOB0YH1E7I6IPcB6YHZadnhE/CgiAriptC0zM2uB0Q2seyzwLPCvkt4N3A98BuiIiJ0AEbFT0tGp/WRgR2n93lQbqt5bo/4GkhZRfCKho6ODSqVS14A6xsHFJ/bXtW6j6u1zLX19fU3dXquMlHHAyBmLx9FeWjGORkJjNHAS8FcRsUHSNfzuUlQtte5HRB31NxYjlgJLAbq6uqK7u3uIbgzuupVruGpjI4ekftvndzdtW5VKhXqPQTsZKeOAkTMWj6O9tGIcjdzT6AV6I2JDml9NESLPpEtLpK+7Su2nltafAjw9TH1KjbqZmbVI3aERET8Hdkg6LpVmAY8Ca4GBJ6AWAGvS9Frg/PQU1Uxgb7qMtQ44TdKEdAP8NGBdWvaSpJnpqanzS9syM7MWaPRazF8BKyWNAbYBn6AIolslLQSeBM5NbW8HzgB6gFdSWyJit6QvAfemdl+MiN1p+lPAN4BxwB3pZWZmLdJQaETEg0BXjUWzarQN4MJBtrMcWF6jfh9wQiN9NDOz5vFvhJuZWTaHhpmZZXNomJlZNoeGmZllc2iYmVk2h4aZmWVzaJiZWTaHhpmZZXNomJlZNoeGmZllc2iYmVk2h4aZmWVzaJiZWTaHhpmZZXNomJlZNoeGmZllc2iYmVk2h4aZmWVzaJiZWTaHhpmZZXNomJlZNoeGmZllc2iYmVk2h4aZmWVrODQkjZL0gKTb0vx0SRskbZV0i6QxqT42zfek5dNK21iS6lsknV6qz061HkmLG+2rmZk1phmfND4DbC7NXwlcHRGdwB5gYaovBPZExLuAq1M7JM0A5gHHA7OBr6UgGgVcD8wBZgDnpbZmZtYiDYWGpCnAR4Gvp3kBpwKrU5MVwNlpem6aJy2fldrPBVZFxKsR8QTQA5ycXj0RsS0iXgNWpbZmZtYioxtc/6vA3wJvT/NHAi9ERH+a7wUmp+nJwA6AiOiXtDe1nwzcU9pmeZ0dVfVTanVC0iJgEUBHRweVSqWuwXSMg4tP7B++4T5Qb59r6evra+r2WmWkjANGzlg8jvbSinHUHRqSzgR2RcT9kroHyjWaxjDLBqvX+hQUNWpExFJgKUBXV1d0d3fXajas61au4aqNjeZofbbP727atiqVCvUeg3YyUsYBI2csHkd7acU4GnmH/CBwlqQzgEOAwyk+eYyXNDp92pgCPJ3a9wJTgV5Jo4EjgN2l+oDyOoPVzcysBeq+pxERSyJiSkRMo7iRfVdEzAfuBs5JzRYAa9L02jRPWn5XRESqz0tPV00HOoEfA/cCnelprDFpH2vr7a+ZmTVuX1yLuQRYJenLwAPAslRfBnxTUg/FJ4x5ABGxSdKtwKNAP3BhRPwaQNJFwDpgFLA8Ijbtg/6amVmmpoRGRFSASpreRvHkU3WbXwLnDrL+5cDlNeq3A7c3o49mZtY4/0a4mZllc2iYmVk2h4aZmWVzaJiZWTaHhpmZZXNomJlZNoeGmZllc2iYmVk2h4aZmWVzaJiZWTaHhpmZZXNomJlZNoeGmZllc2iYmVk2h4aZmWVzaJiZWTaHhpmZZXNomJlZNoeGmZllc2iYmVk2h4aZmWVzaJiZWTaHhpmZZXNomJlZtrpDQ9JUSXdL2ixpk6TPpPpESeslbU1fJ6S6JF0rqUfSw5JOKm1rQWq/VdKCUv19kjamda6VpEYGa2ZmjWnkk0Y/cHFE/D4wE7hQ0gxgMXBnRHQCd6Z5gDlAZ3otAm6AImSAy4BTgJOBywaCJrVZVFpvdgP9NTOzBtUdGhGxMyJ+kqZfAjYDk4G5wIrUbAVwdpqeC9wUhXuA8ZImAacD6yNid0TsAdYDs9OywyPiRxERwE2lbZmZWQs05Z6GpGnAe4ENQEdE7IQiWICjU7PJwI7Sar2pNlS9t0bdzMxaZHSjG5D0NuA7wGcj4sUhbjvUWhB11Gv1YRHFZSw6OjqoVCrD9Lq2jnFw8Yn9da3bqHr7XEtfX19Tt9cqI2UcMHLG4nG0l1aMo6HQkPRWisBYGRHfTeVnJE2KiJ3pEtOuVO8FppZWnwI8nerdVfVKqk+p0f4NImIpsBSgq6sruru7azUb1nUr13DVxoZztC7b53c3bVuVSoV6j0E7GSnjgJEzFo+jvbRiHI08PSVgGbA5Ir5SWrQWGHgCagGwplQ/Pz1FNRPYmy5frQNOkzQh3QA/DViXlr0kaWba1/mlbZmZWQs08mP1B4GPARslPZhqnwOuAG6VtBB4Ejg3LbsdOAPoAV4BPgEQEbslfQm4N7X7YkTsTtOfAr4BjAPuSC8zM2uRukMjIv4vte87AMyq0T6ACwfZ1nJgeY36fcAJ9fbRzMyay78RbmZm2RwaZmaWzaFhZmbZHBpmZpbNoWFmZtkcGmZmls2hYWZm2RwaZmaWzaFhZmbZHBpmZpbNoWFmZtkcGmZmls2hYWZm2RwaZmaWzaFhZmbZHBpmZpbNoWFmZtkcGmZmls2hYWZm2RwaZmaWzaFhZmbZHBpmZpbNoWFmZtkcGmZmls2hYWZm2do+NCTNlrRFUo+kxa3uj5nZwaytQ0PSKOB6YA4wAzhP0ozW9srM7ODV1qEBnAz0RMS2iHgNWAXMbXGfzMwOWqNb3YFhTAZ2lOZ7gVOqG0laBCxKs32SttS5v6OA5+pctyG6sqmba9k4mmykjANGzlg8jvbSzHEck9Oo3UNDNWrxhkLEUmBpwzuT7ouIrka302oeR/sZKWPxONpLK8bR7peneoGppfkpwNMt6ouZ2UGv3UPjXqBT0nRJY4B5wNoW98nM7KDV1penIqJf0kXAOmAUsDwiNu3DXTZ8iatNeBztZ6SMxeNoL/t9HIp4wy0CMzOzmtr98pSZmbURh4aZmWVzaCTt/OdKJE2VdLekzZI2SfpMqk+UtF7S1vR1QqpL0rVpLA9LOqm0rQWp/VZJC1o0nlGSHpB0W5qfLmlD6tMt6aEHJI1N8z1p+bTSNpak+hZJp7doHOMlrZb0WDo37z8Qz4mkv07fV49IulnSIQfCOZG0XNIuSY+Uak07/pLeJ2ljWudaSbV+BWBfjeMf0/fVw5K+J2l8aVnN4zzYe9hg57JuEXHQvyhusj8OHAuMAR4CZrS6X6X+TQJOStNvB35K8WdV/hewONUXA1em6TOAOyh+z2UmsCHVJwLb0tcJaXpCC8bzN8C3gNvS/K3AvDR9I/CpNP2XwI1peh5wS5qekc7RWGB6OnejWjCOFcAn0/QYYPyBdk4ofoH2CWBc6Vx8/EA4J8AfAScBj5RqTTv+wI+B96d17gDm7MdxnAaMTtNXlsZR8zgzxHvYYOey7v7ur2/Odn6lb4x1pfklwJJW92uI/q4BPgJsASal2iRgS5r+F+C8Uvstafl5wL+U6q9rt5/6PgW4EzgVuC39g3yu9A/kt+eC4qm596fp0amdqs9Pud1+HMfhFG+2qqofUOeE3/3VhYnpGN8GnH6gnBNgWtWbbVOOf1r2WKn+unb7ehxVy/47sDJN1zzODPIeNtS/r3pfvjxVqPXnSia3qC9DSpcD3gtsADoiYidA+np0ajbYeNphnF8F/hb4TZo/EnghIvpr9Om3/U3L96b27TCOY4FngX9Nl9q+LukwDrBzEhFPAf8EPAnspDjG93NgnhNo3vGfnKar661wAcUnHXjz4xjq31ddHBqFrD9X0mqS3gZ8B/hsRLw4VNMatRiivl9IOhPYFRH3l8s1msYwy9rhfI2muKRwQ0S8F3iZ4nLIYNpyLOma/1yKSx3vBA6j+KvSg/WpLceR4c32uy3GI+lSoB9YOVCq0Wy/jsOhUWj7P1ci6a0UgbEyIr6bys9ImpSWTwJ2pfpg42n1OD8InCVpO8VfLD6V4pPHeEkDv2ha7tNv+5uWHwHspvXjGOhbb0RsSPOrKULkQDsnHwaeiIhnI+JXwHeBD3BgnhNo3vHvTdPV9f0m3ZQ/E5gf6doSb34czzH4uayLQ6PQ1n+uJD21sQzYHBFfKS1aCww87bGA4l7HQP389MTITGBv+qi+DjhN0oT0E+ZpqbZfRMSSiJgSEdMojvFdETEfuBs4Z5BxDIzvnNQ+Un1eepJnOtBJcdNyv4mInwM7JB2XSrOARznAzgnFZamZkg5N32cD4zjgzkmN/tV9/NOylyTNTMfl/NK29jlJs4FLgLMi4pXSosGOc833sHRuBjuX9dnXN6oOlBfF0xU/pXgC4dJW96eqbx+i+Ej5MPBgep1Bcb3yTmBr+joxtRfFf171OLAR6Cpt6wKgJ70+0cIxdfO7p6eOTd/4PcC3gbGpfkia70nLjy2tf2ka3xb20VMtGWN4D3BfOi//TvH0zQF3ToAvAI8BjwDfpHgyp+3PCXAzxX2YX1H8pL2wmccf6ErH5HHgn6l66GEfj6OH4h7FwL/3G4c7zgzyHjbYuaz35T8jYmZm2Xx5yszMsjk0zMwsm0PDzMyyOTTMzCybQ8PMzLI5NMzMLJtDw8zMsv1/QMezCew0mgsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "importlib.reload(pipeline)\n",
    "\n",
    "stats_for_variables = [\n",
    "  'total_price_including_optional_support',\n",
    "  'students_reached'\n",
    "]\n",
    "\n",
    "variables_for_correlation = [\n",
    "  'total_price_including_optional_support',\n",
    "  'students_reached'\n",
    "]\n",
    "\n",
    "pipeline.explore_data(data, stats_for_variables, variables_for_correlation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can clearly see in the histograms that total_price_including_optional_support and students_reached have very big outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create outcome label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(pipeline)\n",
    "\n",
    "# The task is to predict if a project will not get fully funded within 60 days of posting.\n",
    "data['duration_of_funding'] = data.datefullyfunded - data.date_posted\n",
    "data['not_funded_in_60'] =  np.where(data['duration_of_funding']<=pd.Timedelta('60 days'), 1, 0)\n",
    "output_label ='not_funded_in_60'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will create binary features for categorical data, discretize features for contiuous data, and an aggregation feature\n",
    "\n",
    "#Select columns from which we will create binary features. We use string string columns who have less than 50 different values (we dont want to generate too many binary values)\n",
    "str_columns = [column for column in data.columns if data[column].dtype=='object' and len(data[column].unique())<51]\n",
    "\n",
    "#Columns with float values to generate discrete features\n",
    "float_columns = ['total_price_including_optional_support', 'students_reached']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(pipeline)\n",
    "\n",
    "#Generate the binary features\n",
    "features = pipeline.create_dummies(data[str_columns], str_columns)\n",
    "\n",
    "#Genereate discretized features. Using qcut due to outliers (if not, almost all datapoints end up in 'low')\n",
    "for float_column in float_columns:\n",
    "  features[float_column] = pd.qcut(data[float_column], 5, labels=['low', 'medium low', 'medium', 'medium high', 'high'])\n",
    "  \n",
    "# Generate binary features for the new discretized columns\n",
    "features = pipeline.create_dummies(features, float_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aggregate feature: number of projects that got funded in the last 10 days. Idea: if many projects have been funded lately, this could be good info to predictor if a project will be funded soon\n",
    "\n",
    "#List of all dates where projects have been posted\n",
    "date_posted_list = pd.to_datetime(data['date_posted'].unique())\n",
    "\n",
    "#We use a dictionary to save the amount of projects that have been funded within the last 10 days in each specific day\n",
    "num_projects_funded_dict = {}\n",
    "\n",
    "#For every possible date_posted\n",
    "for date_posted in date_posted_list:\n",
    "  #For each project, we calculate the difference between the current observed date and the project funded date\n",
    "  #Lets remember that the difference between a value (date_posted) and a series (data['datefullyfunded']) is a series\n",
    "  diff_date_and_fully_funded = date_posted - data['datefullyfunded']\n",
    "  \n",
    "  #Count how many projects have a difference between fully funded date and current date bigger than 0 and smaller or equal than 10\n",
    "  amount_funded_in_last_10_days = np.sum((diff_date_and_fully_funded>pd.Timedelta('0 days')) & (diff_date_and_fully_funded<=pd.Timedelta('10 days')))\n",
    "  \n",
    "  #Save the amount in dictionary\n",
    "  num_projects_funded_dict[date_posted.strftime(\"%Y%m%d\")]= amount_funded_in_last_10_days\n",
    "\n",
    "#We create the column to be attached, initially full of zeros for each row in the dataframe\n",
    "num_of_projects_funded_10_days = np.zeros(len(data))\n",
    "for index, row in data.iterrows():\n",
    "  num_of_projects_funded_10_days[index] = num_projects_funded_dict[row['date_posted'].strftime(\"%Y%m%d\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Attach the created column to features\n",
    "features['num_of_projects_funded_10_days']=num_of_projects_funded_10_days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create temporal train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(pipeline)\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "#Create three sets of train and test data, based on threee different split thresholds\n",
    "split_thresholds = [pd.Timestamp(2013,7,1), pd.Timestamp(2013,1,1), pd.Timestamp(2012,7,1)]\n",
    "\n",
    "#Indicating which is the column to be used for splitting training and test daata\n",
    "date_column='date_posted'\n",
    "\n",
    "#Amount of data used for test set\n",
    "test_window = relativedelta(months=6)\n",
    "\n",
    "#Gap needed between training and test set. 60 days in this case\n",
    "gap_training_test = relativedelta(days=100)\n",
    "\n",
    "#Generate train and test sets\n",
    "train_test_sets= pipeline.create_temp_validation_train_and_testing_sets(\n",
    "  data,\n",
    "  features,\n",
    "  date_column,\n",
    "  output_label,\n",
    "  split_thresholds,\n",
    "  test_window,\n",
    "  gap_training_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "importlib.reload(pipeline)\n",
    "\n",
    "columns_to_process = [\n",
    "  'total_price_including_optional_support',\n",
    "  'students_reached'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Clasifiers and parameters generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(pipeline)\n",
    "\n",
    "#We define the specific models we want to run\n",
    "models_to_run=['LR', 'DT', 'AB','RF']#,'KNN']#,'BA','SVM']\n",
    "\n",
    "#Get all posible models and their different sets of parameters\n",
    "models, parameters_grid = pipeline.get_models_and_parameters()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loop over models and different training/test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running LR with params: {'penalty': ['l1', 'l2'], 'C': [0.001, 0.1, 1, 10]} on train/test set 2013-07-01 00:00:00\n",
      "Running DT with params: {'criterion': ['gini', 'entropy'], 'max_depth': [1, 5, 10, 50, 100], 'min_samples_split': [2, 5]} on train/test set 2013-07-01 00:00:00\n",
      "Running AB with params: {'algorithm': ['SAMME', 'SAMME.R'], 'n_estimators': [1, 10, 100]} on train/test set 2013-07-01 00:00:00\n",
      "Running RF with params: {'n_estimators': [10, 100], 'max_depth': [5, 50], 'max_features': ['sqrt', 'log2'], 'min_samples_split': [2, 10], 'n_jobs': [-1]} on train/test set 2013-07-01 00:00:00\n",
      "Running LR with params: {'penalty': ['l1', 'l2'], 'C': [0.001, 0.1, 1, 10]} on train/test set 2013-01-01 00:00:00\n",
      "Running DT with params: {'criterion': ['gini', 'entropy'], 'max_depth': [1, 5, 10, 50, 100], 'min_samples_split': [2, 5]} on train/test set 2013-01-01 00:00:00\n",
      "Running AB with params: {'algorithm': ['SAMME', 'SAMME.R'], 'n_estimators': [1, 10, 100]} on train/test set 2013-01-01 00:00:00\n",
      "Running RF with params: {'n_estimators': [10, 100], 'max_depth': [5, 50], 'max_features': ['sqrt', 'log2'], 'min_samples_split': [2, 10], 'n_jobs': [-1]} on train/test set 2013-01-01 00:00:00\n",
      "Running LR with params: {'penalty': ['l1', 'l2'], 'C': [0.001, 0.1, 1, 10]} on train/test set 2012-07-01 00:00:00\n",
      "Running DT with params: {'criterion': ['gini', 'entropy'], 'max_depth': [1, 5, 10, 50, 100], 'min_samples_split': [2, 5]} on train/test set 2012-07-01 00:00:00\n",
      "Running AB with params: {'algorithm': ['SAMME', 'SAMME.R'], 'n_estimators': [1, 10, 100]} on train/test set 2012-07-01 00:00:00\n",
      "Running RF with params: {'n_estimators': [10, 100], 'max_depth': [5, 50], 'max_features': ['sqrt', 'log2'], 'min_samples_split': [2, 10], 'n_jobs': [-1]} on train/test set 2012-07-01 00:00:00\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>model</th>\n",
       "      <th>parameters</th>\n",
       "      <th>train_test_split_threshold</th>\n",
       "      <th>p_at_1</th>\n",
       "      <th>r_at_1</th>\n",
       "      <th>f1_at_1</th>\n",
       "      <th>p_at_2</th>\n",
       "      <th>r_at_2</th>\n",
       "      <th>f1_at_2</th>\n",
       "      <th>...</th>\n",
       "      <th>p_at_20</th>\n",
       "      <th>r_at_20</th>\n",
       "      <th>f1_at_20</th>\n",
       "      <th>p_at_30</th>\n",
       "      <th>r_at_30</th>\n",
       "      <th>f1_at_30</th>\n",
       "      <th>p_at_50</th>\n",
       "      <th>r_at_50</th>\n",
       "      <th>f1_at_50</th>\n",
       "      <th>auc-roc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>{'C': 0.001, 'penalty': 'l1'}</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>0.861678</td>\n",
       "      <td>0.012027</td>\n",
       "      <td>0.023723</td>\n",
       "      <td>0.840317</td>\n",
       "      <td>0.023485</td>\n",
       "      <td>0.045692</td>\n",
       "      <td>...</td>\n",
       "      <td>0.767689</td>\n",
       "      <td>0.214623</td>\n",
       "      <td>0.335461</td>\n",
       "      <td>0.756604</td>\n",
       "      <td>0.317297</td>\n",
       "      <td>0.447096</td>\n",
       "      <td>0.730653</td>\n",
       "      <td>0.510682</td>\n",
       "      <td>0.601177</td>\n",
       "      <td>0.537428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>{'C': 0.001, 'penalty': 'l2'}</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>0.934240</td>\n",
       "      <td>0.013040</td>\n",
       "      <td>0.025721</td>\n",
       "      <td>0.925255</td>\n",
       "      <td>0.025859</td>\n",
       "      <td>0.050311</td>\n",
       "      <td>...</td>\n",
       "      <td>0.858259</td>\n",
       "      <td>0.239943</td>\n",
       "      <td>0.375037</td>\n",
       "      <td>0.836906</td>\n",
       "      <td>0.350973</td>\n",
       "      <td>0.494548</td>\n",
       "      <td>0.799257</td>\n",
       "      <td>0.558633</td>\n",
       "      <td>0.657625</td>\n",
       "      <td>0.638292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'l1'}</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>0.963719</td>\n",
       "      <td>0.013451</td>\n",
       "      <td>0.026533</td>\n",
       "      <td>0.966025</td>\n",
       "      <td>0.026998</td>\n",
       "      <td>0.052528</td>\n",
       "      <td>...</td>\n",
       "      <td>0.903204</td>\n",
       "      <td>0.252508</td>\n",
       "      <td>0.394677</td>\n",
       "      <td>0.874717</td>\n",
       "      <td>0.366830</td>\n",
       "      <td>0.516892</td>\n",
       "      <td>0.820224</td>\n",
       "      <td>0.573287</td>\n",
       "      <td>0.674876</td>\n",
       "      <td>0.673192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'l2'}</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>0.959184</td>\n",
       "      <td>0.013388</td>\n",
       "      <td>0.026408</td>\n",
       "      <td>0.967157</td>\n",
       "      <td>0.027030</td>\n",
       "      <td>0.052589</td>\n",
       "      <td>...</td>\n",
       "      <td>0.899921</td>\n",
       "      <td>0.251590</td>\n",
       "      <td>0.393242</td>\n",
       "      <td>0.873208</td>\n",
       "      <td>0.366197</td>\n",
       "      <td>0.516000</td>\n",
       "      <td>0.820722</td>\n",
       "      <td>0.573635</td>\n",
       "      <td>0.675286</td>\n",
       "      <td>0.673600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>{'C': 1, 'penalty': 'l1'}</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>0.963719</td>\n",
       "      <td>0.013451</td>\n",
       "      <td>0.026533</td>\n",
       "      <td>0.960362</td>\n",
       "      <td>0.026840</td>\n",
       "      <td>0.052220</td>\n",
       "      <td>...</td>\n",
       "      <td>0.903770</td>\n",
       "      <td>0.252667</td>\n",
       "      <td>0.394924</td>\n",
       "      <td>0.875623</td>\n",
       "      <td>0.367210</td>\n",
       "      <td>0.517427</td>\n",
       "      <td>0.819997</td>\n",
       "      <td>0.573129</td>\n",
       "      <td>0.674690</td>\n",
       "      <td>0.672998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>{'C': 1, 'penalty': 'l2'}</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>0.963719</td>\n",
       "      <td>0.013451</td>\n",
       "      <td>0.026533</td>\n",
       "      <td>0.963760</td>\n",
       "      <td>0.026935</td>\n",
       "      <td>0.052405</td>\n",
       "      <td>...</td>\n",
       "      <td>0.903996</td>\n",
       "      <td>0.252730</td>\n",
       "      <td>0.395023</td>\n",
       "      <td>0.875170</td>\n",
       "      <td>0.367020</td>\n",
       "      <td>0.517159</td>\n",
       "      <td>0.819907</td>\n",
       "      <td>0.573065</td>\n",
       "      <td>0.674615</td>\n",
       "      <td>0.673964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>{'C': 10, 'penalty': 'l1'}</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>0.963719</td>\n",
       "      <td>0.013451</td>\n",
       "      <td>0.026533</td>\n",
       "      <td>0.960362</td>\n",
       "      <td>0.026840</td>\n",
       "      <td>0.052220</td>\n",
       "      <td>...</td>\n",
       "      <td>0.903544</td>\n",
       "      <td>0.252603</td>\n",
       "      <td>0.394825</td>\n",
       "      <td>0.875396</td>\n",
       "      <td>0.367115</td>\n",
       "      <td>0.517293</td>\n",
       "      <td>0.819997</td>\n",
       "      <td>0.573129</td>\n",
       "      <td>0.674690</td>\n",
       "      <td>0.672998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>{'C': 10, 'penalty': 'l2'}</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>0.959184</td>\n",
       "      <td>0.013388</td>\n",
       "      <td>0.026408</td>\n",
       "      <td>0.966025</td>\n",
       "      <td>0.026998</td>\n",
       "      <td>0.052528</td>\n",
       "      <td>...</td>\n",
       "      <td>0.899808</td>\n",
       "      <td>0.251559</td>\n",
       "      <td>0.393193</td>\n",
       "      <td>0.873962</td>\n",
       "      <td>0.366514</td>\n",
       "      <td>0.516446</td>\n",
       "      <td>0.820677</td>\n",
       "      <td>0.573603</td>\n",
       "      <td>0.675249</td>\n",
       "      <td>0.673729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 1, 'min_sam...</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013958</td>\n",
       "      <td>0.027532</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.027947</td>\n",
       "      <td>0.054375</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.279570</td>\n",
       "      <td>0.436974</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.419370</td>\n",
       "      <td>0.590924</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.698940</td>\n",
       "      <td>0.822795</td>\n",
       "      <td>0.579323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 1, 'min_sam...</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013958</td>\n",
       "      <td>0.027532</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.027947</td>\n",
       "      <td>0.054375</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.279570</td>\n",
       "      <td>0.436974</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.419370</td>\n",
       "      <td>0.590924</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.698940</td>\n",
       "      <td>0.822795</td>\n",
       "      <td>0.579323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'min_sam...</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013958</td>\n",
       "      <td>0.027532</td>\n",
       "      <td>0.967157</td>\n",
       "      <td>0.027030</td>\n",
       "      <td>0.052589</td>\n",
       "      <td>...</td>\n",
       "      <td>0.904676</td>\n",
       "      <td>0.252920</td>\n",
       "      <td>0.395320</td>\n",
       "      <td>0.858038</td>\n",
       "      <td>0.359835</td>\n",
       "      <td>0.507035</td>\n",
       "      <td>0.811575</td>\n",
       "      <td>0.567242</td>\n",
       "      <td>0.667760</td>\n",
       "      <td>0.653808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'min_sam...</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013958</td>\n",
       "      <td>0.027532</td>\n",
       "      <td>0.967157</td>\n",
       "      <td>0.027030</td>\n",
       "      <td>0.052589</td>\n",
       "      <td>...</td>\n",
       "      <td>0.904676</td>\n",
       "      <td>0.252920</td>\n",
       "      <td>0.395320</td>\n",
       "      <td>0.858038</td>\n",
       "      <td>0.359835</td>\n",
       "      <td>0.507035</td>\n",
       "      <td>0.811575</td>\n",
       "      <td>0.567242</td>\n",
       "      <td>0.667760</td>\n",
       "      <td>0.653808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 10, 'min_sa...</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>0.671202</td>\n",
       "      <td>0.009369</td>\n",
       "      <td>0.018479</td>\n",
       "      <td>0.767837</td>\n",
       "      <td>0.021459</td>\n",
       "      <td>0.041751</td>\n",
       "      <td>...</td>\n",
       "      <td>0.851579</td>\n",
       "      <td>0.238076</td>\n",
       "      <td>0.372118</td>\n",
       "      <td>0.833811</td>\n",
       "      <td>0.349676</td>\n",
       "      <td>0.492719</td>\n",
       "      <td>0.805823</td>\n",
       "      <td>0.563222</td>\n",
       "      <td>0.663028</td>\n",
       "      <td>0.646482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 10, 'min_sa...</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>0.673469</td>\n",
       "      <td>0.009400</td>\n",
       "      <td>0.018542</td>\n",
       "      <td>0.768969</td>\n",
       "      <td>0.021491</td>\n",
       "      <td>0.041813</td>\n",
       "      <td>...</td>\n",
       "      <td>0.851353</td>\n",
       "      <td>0.238012</td>\n",
       "      <td>0.372019</td>\n",
       "      <td>0.833887</td>\n",
       "      <td>0.349707</td>\n",
       "      <td>0.492764</td>\n",
       "      <td>0.806050</td>\n",
       "      <td>0.563380</td>\n",
       "      <td>0.663214</td>\n",
       "      <td>0.646512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 50, 'min_sa...</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>0.997732</td>\n",
       "      <td>0.013926</td>\n",
       "      <td>0.027469</td>\n",
       "      <td>0.998867</td>\n",
       "      <td>0.027916</td>\n",
       "      <td>0.054314</td>\n",
       "      <td>...</td>\n",
       "      <td>0.948262</td>\n",
       "      <td>0.265105</td>\n",
       "      <td>0.414366</td>\n",
       "      <td>0.965434</td>\n",
       "      <td>0.404874</td>\n",
       "      <td>0.570498</td>\n",
       "      <td>0.979215</td>\n",
       "      <td>0.684412</td>\n",
       "      <td>0.805693</td>\n",
       "      <td>0.540092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 50, 'min_sa...</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>0.997732</td>\n",
       "      <td>0.013926</td>\n",
       "      <td>0.027469</td>\n",
       "      <td>0.998867</td>\n",
       "      <td>0.027916</td>\n",
       "      <td>0.054314</td>\n",
       "      <td>...</td>\n",
       "      <td>0.687422</td>\n",
       "      <td>0.192182</td>\n",
       "      <td>0.300386</td>\n",
       "      <td>0.752830</td>\n",
       "      <td>0.315715</td>\n",
       "      <td>0.444866</td>\n",
       "      <td>0.851651</td>\n",
       "      <td>0.595252</td>\n",
       "      <td>0.700734</td>\n",
       "      <td>0.547933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 100, 'min_s...</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>0.997732</td>\n",
       "      <td>0.013926</td>\n",
       "      <td>0.027469</td>\n",
       "      <td>0.998867</td>\n",
       "      <td>0.027916</td>\n",
       "      <td>0.054314</td>\n",
       "      <td>...</td>\n",
       "      <td>0.931960</td>\n",
       "      <td>0.260548</td>\n",
       "      <td>0.407243</td>\n",
       "      <td>0.954566</td>\n",
       "      <td>0.400317</td>\n",
       "      <td>0.564076</td>\n",
       "      <td>0.972694</td>\n",
       "      <td>0.679854</td>\n",
       "      <td>0.800328</td>\n",
       "      <td>0.536223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 100, 'min_s...</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>0.997732</td>\n",
       "      <td>0.013926</td>\n",
       "      <td>0.027469</td>\n",
       "      <td>0.998867</td>\n",
       "      <td>0.027916</td>\n",
       "      <td>0.054314</td>\n",
       "      <td>...</td>\n",
       "      <td>0.687422</td>\n",
       "      <td>0.192182</td>\n",
       "      <td>0.300386</td>\n",
       "      <td>0.747019</td>\n",
       "      <td>0.313277</td>\n",
       "      <td>0.441432</td>\n",
       "      <td>0.848164</td>\n",
       "      <td>0.592815</td>\n",
       "      <td>0.697865</td>\n",
       "      <td>0.547202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 1, 'min_...</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013958</td>\n",
       "      <td>0.027532</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.027947</td>\n",
       "      <td>0.054375</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.279570</td>\n",
       "      <td>0.436974</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.419370</td>\n",
       "      <td>0.590924</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.698940</td>\n",
       "      <td>0.822795</td>\n",
       "      <td>0.579323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 1, 'min_...</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013958</td>\n",
       "      <td>0.027532</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.027947</td>\n",
       "      <td>0.054375</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.279570</td>\n",
       "      <td>0.436974</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.419370</td>\n",
       "      <td>0.590924</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.698940</td>\n",
       "      <td>0.822795</td>\n",
       "      <td>0.579323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'min_...</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>0.977324</td>\n",
       "      <td>0.013641</td>\n",
       "      <td>0.026907</td>\n",
       "      <td>0.984145</td>\n",
       "      <td>0.027504</td>\n",
       "      <td>0.053513</td>\n",
       "      <td>...</td>\n",
       "      <td>0.903544</td>\n",
       "      <td>0.252603</td>\n",
       "      <td>0.394825</td>\n",
       "      <td>0.855245</td>\n",
       "      <td>0.358664</td>\n",
       "      <td>0.505385</td>\n",
       "      <td>0.814427</td>\n",
       "      <td>0.569236</td>\n",
       "      <td>0.670107</td>\n",
       "      <td>0.653398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'min_...</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>0.977324</td>\n",
       "      <td>0.013641</td>\n",
       "      <td>0.026907</td>\n",
       "      <td>0.984145</td>\n",
       "      <td>0.027504</td>\n",
       "      <td>0.053513</td>\n",
       "      <td>...</td>\n",
       "      <td>0.903544</td>\n",
       "      <td>0.252603</td>\n",
       "      <td>0.394825</td>\n",
       "      <td>0.855245</td>\n",
       "      <td>0.358664</td>\n",
       "      <td>0.505385</td>\n",
       "      <td>0.814427</td>\n",
       "      <td>0.569236</td>\n",
       "      <td>0.670107</td>\n",
       "      <td>0.653398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 10, 'min...</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>0.650794</td>\n",
       "      <td>0.009084</td>\n",
       "      <td>0.017917</td>\n",
       "      <td>0.585504</td>\n",
       "      <td>0.016363</td>\n",
       "      <td>0.031837</td>\n",
       "      <td>...</td>\n",
       "      <td>0.850221</td>\n",
       "      <td>0.237696</td>\n",
       "      <td>0.371525</td>\n",
       "      <td>0.846264</td>\n",
       "      <td>0.354898</td>\n",
       "      <td>0.500078</td>\n",
       "      <td>0.807907</td>\n",
       "      <td>0.564678</td>\n",
       "      <td>0.664742</td>\n",
       "      <td>0.647379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 10, 'min...</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>0.648526</td>\n",
       "      <td>0.009052</td>\n",
       "      <td>0.017855</td>\n",
       "      <td>0.583239</td>\n",
       "      <td>0.016300</td>\n",
       "      <td>0.031714</td>\n",
       "      <td>...</td>\n",
       "      <td>0.849994</td>\n",
       "      <td>0.237633</td>\n",
       "      <td>0.371426</td>\n",
       "      <td>0.846189</td>\n",
       "      <td>0.354866</td>\n",
       "      <td>0.500033</td>\n",
       "      <td>0.807816</td>\n",
       "      <td>0.564615</td>\n",
       "      <td>0.664667</td>\n",
       "      <td>0.647223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 50, 'min...</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013958</td>\n",
       "      <td>0.027532</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.027947</td>\n",
       "      <td>0.054375</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.279570</td>\n",
       "      <td>0.436974</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.419370</td>\n",
       "      <td>0.590924</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.698940</td>\n",
       "      <td>0.822795</td>\n",
       "      <td>0.540259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 50, 'min...</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>0.997732</td>\n",
       "      <td>0.013926</td>\n",
       "      <td>0.027469</td>\n",
       "      <td>0.998867</td>\n",
       "      <td>0.027916</td>\n",
       "      <td>0.054314</td>\n",
       "      <td>...</td>\n",
       "      <td>0.795087</td>\n",
       "      <td>0.222282</td>\n",
       "      <td>0.347432</td>\n",
       "      <td>0.863321</td>\n",
       "      <td>0.362051</td>\n",
       "      <td>0.510157</td>\n",
       "      <td>0.917946</td>\n",
       "      <td>0.641589</td>\n",
       "      <td>0.755281</td>\n",
       "      <td>0.548255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 100, 'mi...</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013958</td>\n",
       "      <td>0.027532</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.027947</td>\n",
       "      <td>0.054375</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.279570</td>\n",
       "      <td>0.436974</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.419370</td>\n",
       "      <td>0.590924</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.698940</td>\n",
       "      <td>0.822795</td>\n",
       "      <td>0.543410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 100, 'mi...</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>0.997732</td>\n",
       "      <td>0.013926</td>\n",
       "      <td>0.027469</td>\n",
       "      <td>0.998867</td>\n",
       "      <td>0.027916</td>\n",
       "      <td>0.054314</td>\n",
       "      <td>...</td>\n",
       "      <td>0.819088</td>\n",
       "      <td>0.228992</td>\n",
       "      <td>0.357920</td>\n",
       "      <td>0.879321</td>\n",
       "      <td>0.368761</td>\n",
       "      <td>0.519612</td>\n",
       "      <td>0.927546</td>\n",
       "      <td>0.648299</td>\n",
       "      <td>0.763180</td>\n",
       "      <td>0.546703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>AB</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'algorithm': 'SAMME', 'n_estimators': 1}</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013958</td>\n",
       "      <td>0.027532</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.027947</td>\n",
       "      <td>0.054375</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.279570</td>\n",
       "      <td>0.436974</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.419370</td>\n",
       "      <td>0.590924</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.698940</td>\n",
       "      <td>0.822795</td>\n",
       "      <td>0.579323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>AB</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'algorithm': 'SAMME', 'n_estimators': 10}</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013958</td>\n",
       "      <td>0.027532</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.027947</td>\n",
       "      <td>0.054375</td>\n",
       "      <td>...</td>\n",
       "      <td>0.858259</td>\n",
       "      <td>0.239943</td>\n",
       "      <td>0.375037</td>\n",
       "      <td>0.823698</td>\n",
       "      <td>0.345434</td>\n",
       "      <td>0.486743</td>\n",
       "      <td>0.818684</td>\n",
       "      <td>0.572211</td>\n",
       "      <td>0.673609</td>\n",
       "      <td>0.651652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'min_...</td>\n",
       "      <td>2012-07-01</td>\n",
       "      <td>0.963415</td>\n",
       "      <td>0.012950</td>\n",
       "      <td>0.025557</td>\n",
       "      <td>0.788110</td>\n",
       "      <td>0.021188</td>\n",
       "      <td>0.041266</td>\n",
       "      <td>...</td>\n",
       "      <td>0.749201</td>\n",
       "      <td>0.201631</td>\n",
       "      <td>0.317747</td>\n",
       "      <td>0.829865</td>\n",
       "      <td>0.335027</td>\n",
       "      <td>0.477344</td>\n",
       "      <td>0.897923</td>\n",
       "      <td>0.604197</td>\n",
       "      <td>0.722342</td>\n",
       "      <td>0.605496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'min_...</td>\n",
       "      <td>2012-07-01</td>\n",
       "      <td>0.963415</td>\n",
       "      <td>0.012950</td>\n",
       "      <td>0.025557</td>\n",
       "      <td>0.788110</td>\n",
       "      <td>0.021188</td>\n",
       "      <td>0.041266</td>\n",
       "      <td>...</td>\n",
       "      <td>0.749201</td>\n",
       "      <td>0.201631</td>\n",
       "      <td>0.317747</td>\n",
       "      <td>0.829865</td>\n",
       "      <td>0.335027</td>\n",
       "      <td>0.477344</td>\n",
       "      <td>0.897923</td>\n",
       "      <td>0.604197</td>\n",
       "      <td>0.722342</td>\n",
       "      <td>0.605496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 10, 'min...</td>\n",
       "      <td>2012-07-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013442</td>\n",
       "      <td>0.026528</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.026884</td>\n",
       "      <td>0.052361</td>\n",
       "      <td>...</td>\n",
       "      <td>0.835998</td>\n",
       "      <td>0.224991</td>\n",
       "      <td>0.354560</td>\n",
       "      <td>0.821744</td>\n",
       "      <td>0.331749</td>\n",
       "      <td>0.472673</td>\n",
       "      <td>0.815458</td>\n",
       "      <td>0.548707</td>\n",
       "      <td>0.656002</td>\n",
       "      <td>0.613331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 10, 'min...</td>\n",
       "      <td>2012-07-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013442</td>\n",
       "      <td>0.026528</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.026884</td>\n",
       "      <td>0.052361</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838282</td>\n",
       "      <td>0.225606</td>\n",
       "      <td>0.355528</td>\n",
       "      <td>0.823267</td>\n",
       "      <td>0.332363</td>\n",
       "      <td>0.473549</td>\n",
       "      <td>0.815031</td>\n",
       "      <td>0.548420</td>\n",
       "      <td>0.655659</td>\n",
       "      <td>0.612698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 50, 'min...</td>\n",
       "      <td>2012-07-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013442</td>\n",
       "      <td>0.026528</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.026884</td>\n",
       "      <td>0.052361</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.269128</td>\n",
       "      <td>0.424115</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.403713</td>\n",
       "      <td>0.575207</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.672882</td>\n",
       "      <td>0.804459</td>\n",
       "      <td>0.545247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 50, 'min...</td>\n",
       "      <td>2012-07-01</td>\n",
       "      <td>0.996951</td>\n",
       "      <td>0.013401</td>\n",
       "      <td>0.026447</td>\n",
       "      <td>0.998476</td>\n",
       "      <td>0.026843</td>\n",
       "      <td>0.052281</td>\n",
       "      <td>...</td>\n",
       "      <td>0.976549</td>\n",
       "      <td>0.262817</td>\n",
       "      <td>0.414169</td>\n",
       "      <td>0.984367</td>\n",
       "      <td>0.397402</td>\n",
       "      <td>0.566215</td>\n",
       "      <td>0.990560</td>\n",
       "      <td>0.666530</td>\n",
       "      <td>0.796864</td>\n",
       "      <td>0.549429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 100, 'mi...</td>\n",
       "      <td>2012-07-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013442</td>\n",
       "      <td>0.026528</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.026884</td>\n",
       "      <td>0.052361</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.269128</td>\n",
       "      <td>0.424115</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.403713</td>\n",
       "      <td>0.575207</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.672882</td>\n",
       "      <td>0.804459</td>\n",
       "      <td>0.545247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 100, 'mi...</td>\n",
       "      <td>2012-07-01</td>\n",
       "      <td>0.996951</td>\n",
       "      <td>0.013401</td>\n",
       "      <td>0.026447</td>\n",
       "      <td>0.998476</td>\n",
       "      <td>0.026843</td>\n",
       "      <td>0.052281</td>\n",
       "      <td>...</td>\n",
       "      <td>0.976549</td>\n",
       "      <td>0.262817</td>\n",
       "      <td>0.414169</td>\n",
       "      <td>0.984367</td>\n",
       "      <td>0.397402</td>\n",
       "      <td>0.566215</td>\n",
       "      <td>0.990560</td>\n",
       "      <td>0.666530</td>\n",
       "      <td>0.796864</td>\n",
       "      <td>0.549429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>AB</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'algorithm': 'SAMME', 'n_estimators': 1}</td>\n",
       "      <td>2012-07-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013442</td>\n",
       "      <td>0.026528</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.026884</td>\n",
       "      <td>0.052361</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.269128</td>\n",
       "      <td>0.424115</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.403713</td>\n",
       "      <td>0.575207</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.672882</td>\n",
       "      <td>0.804459</td>\n",
       "      <td>0.559447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>AB</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'algorithm': 'SAMME', 'n_estimators': 10}</td>\n",
       "      <td>2012-07-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013442</td>\n",
       "      <td>0.026528</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.026884</td>\n",
       "      <td>0.052361</td>\n",
       "      <td>...</td>\n",
       "      <td>0.845135</td>\n",
       "      <td>0.227450</td>\n",
       "      <td>0.358435</td>\n",
       "      <td>0.853822</td>\n",
       "      <td>0.344699</td>\n",
       "      <td>0.491125</td>\n",
       "      <td>0.837871</td>\n",
       "      <td>0.563788</td>\n",
       "      <td>0.674032</td>\n",
       "      <td>0.624234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>AB</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'algorithm': 'SAMME', 'n_estimators': 100}</td>\n",
       "      <td>2012-07-01</td>\n",
       "      <td>0.954268</td>\n",
       "      <td>0.012827</td>\n",
       "      <td>0.025314</td>\n",
       "      <td>0.957317</td>\n",
       "      <td>0.025737</td>\n",
       "      <td>0.050126</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854576</td>\n",
       "      <td>0.229991</td>\n",
       "      <td>0.362439</td>\n",
       "      <td>0.855345</td>\n",
       "      <td>0.345314</td>\n",
       "      <td>0.492000</td>\n",
       "      <td>0.821609</td>\n",
       "      <td>0.552846</td>\n",
       "      <td>0.660951</td>\n",
       "      <td>0.637534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>AB</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'algorithm': 'SAMME.R', 'n_estimators': 1}</td>\n",
       "      <td>2012-07-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013442</td>\n",
       "      <td>0.026528</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.026884</td>\n",
       "      <td>0.052361</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.269128</td>\n",
       "      <td>0.424115</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.403713</td>\n",
       "      <td>0.575207</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.672882</td>\n",
       "      <td>0.804459</td>\n",
       "      <td>0.559447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>AB</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'algorithm': 'SAMME.R', 'n_estimators': 10}</td>\n",
       "      <td>2012-07-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013442</td>\n",
       "      <td>0.026528</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.026884</td>\n",
       "      <td>0.052361</td>\n",
       "      <td>...</td>\n",
       "      <td>0.865692</td>\n",
       "      <td>0.232982</td>\n",
       "      <td>0.367153</td>\n",
       "      <td>0.833113</td>\n",
       "      <td>0.336339</td>\n",
       "      <td>0.479213</td>\n",
       "      <td>0.835435</td>\n",
       "      <td>0.562149</td>\n",
       "      <td>0.672073</td>\n",
       "      <td>0.635815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>AB</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'algorithm': 'SAMME.R', 'n_estimators': 100}</td>\n",
       "      <td>2012-07-01</td>\n",
       "      <td>0.972561</td>\n",
       "      <td>0.013073</td>\n",
       "      <td>0.025800</td>\n",
       "      <td>0.961890</td>\n",
       "      <td>0.025860</td>\n",
       "      <td>0.050365</td>\n",
       "      <td>...</td>\n",
       "      <td>0.897518</td>\n",
       "      <td>0.241547</td>\n",
       "      <td>0.380651</td>\n",
       "      <td>0.872906</td>\n",
       "      <td>0.352404</td>\n",
       "      <td>0.502102</td>\n",
       "      <td>0.830319</td>\n",
       "      <td>0.558707</td>\n",
       "      <td>0.667957</td>\n",
       "      <td>0.653333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 'sqrt', 'min_...</td>\n",
       "      <td>2012-07-01</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.011762</td>\n",
       "      <td>0.023212</td>\n",
       "      <td>0.876524</td>\n",
       "      <td>0.023565</td>\n",
       "      <td>0.045895</td>\n",
       "      <td>...</td>\n",
       "      <td>0.845135</td>\n",
       "      <td>0.227450</td>\n",
       "      <td>0.358435</td>\n",
       "      <td>0.834839</td>\n",
       "      <td>0.337035</td>\n",
       "      <td>0.480206</td>\n",
       "      <td>0.815823</td>\n",
       "      <td>0.548953</td>\n",
       "      <td>0.656296</td>\n",
       "      <td>0.626015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 'sqrt', 'min_...</td>\n",
       "      <td>2012-07-01</td>\n",
       "      <td>0.951220</td>\n",
       "      <td>0.012786</td>\n",
       "      <td>0.025234</td>\n",
       "      <td>0.917683</td>\n",
       "      <td>0.024671</td>\n",
       "      <td>0.048050</td>\n",
       "      <td>...</td>\n",
       "      <td>0.864626</td>\n",
       "      <td>0.232695</td>\n",
       "      <td>0.366701</td>\n",
       "      <td>0.852096</td>\n",
       "      <td>0.344002</td>\n",
       "      <td>0.490132</td>\n",
       "      <td>0.823984</td>\n",
       "      <td>0.554444</td>\n",
       "      <td>0.662861</td>\n",
       "      <td>0.642483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 'sqrt', 'min_...</td>\n",
       "      <td>2012-07-01</td>\n",
       "      <td>0.905488</td>\n",
       "      <td>0.012172</td>\n",
       "      <td>0.024020</td>\n",
       "      <td>0.873476</td>\n",
       "      <td>0.023483</td>\n",
       "      <td>0.045736</td>\n",
       "      <td>...</td>\n",
       "      <td>0.845592</td>\n",
       "      <td>0.227573</td>\n",
       "      <td>0.358628</td>\n",
       "      <td>0.835753</td>\n",
       "      <td>0.337404</td>\n",
       "      <td>0.480731</td>\n",
       "      <td>0.817468</td>\n",
       "      <td>0.550059</td>\n",
       "      <td>0.657619</td>\n",
       "      <td>0.629299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 'sqrt', 'min_...</td>\n",
       "      <td>2012-07-01</td>\n",
       "      <td>0.948171</td>\n",
       "      <td>0.012745</td>\n",
       "      <td>0.025153</td>\n",
       "      <td>0.916159</td>\n",
       "      <td>0.024630</td>\n",
       "      <td>0.047971</td>\n",
       "      <td>...</td>\n",
       "      <td>0.865235</td>\n",
       "      <td>0.232859</td>\n",
       "      <td>0.366959</td>\n",
       "      <td>0.852299</td>\n",
       "      <td>0.344084</td>\n",
       "      <td>0.490249</td>\n",
       "      <td>0.824106</td>\n",
       "      <td>0.554526</td>\n",
       "      <td>0.662959</td>\n",
       "      <td>0.642183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 'log2', 'min_...</td>\n",
       "      <td>2012-07-01</td>\n",
       "      <td>0.887195</td>\n",
       "      <td>0.011926</td>\n",
       "      <td>0.023535</td>\n",
       "      <td>0.876524</td>\n",
       "      <td>0.023565</td>\n",
       "      <td>0.045895</td>\n",
       "      <td>...</td>\n",
       "      <td>0.856251</td>\n",
       "      <td>0.230441</td>\n",
       "      <td>0.363149</td>\n",
       "      <td>0.837275</td>\n",
       "      <td>0.338019</td>\n",
       "      <td>0.481607</td>\n",
       "      <td>0.818564</td>\n",
       "      <td>0.550797</td>\n",
       "      <td>0.658501</td>\n",
       "      <td>0.634428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 'log2', 'min_...</td>\n",
       "      <td>2012-07-01</td>\n",
       "      <td>0.896341</td>\n",
       "      <td>0.012049</td>\n",
       "      <td>0.023778</td>\n",
       "      <td>0.882622</td>\n",
       "      <td>0.023729</td>\n",
       "      <td>0.046215</td>\n",
       "      <td>...</td>\n",
       "      <td>0.862190</td>\n",
       "      <td>0.232040</td>\n",
       "      <td>0.365668</td>\n",
       "      <td>0.846818</td>\n",
       "      <td>0.341871</td>\n",
       "      <td>0.487096</td>\n",
       "      <td>0.822157</td>\n",
       "      <td>0.553215</td>\n",
       "      <td>0.661391</td>\n",
       "      <td>0.640744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 'log2', 'min_...</td>\n",
       "      <td>2012-07-01</td>\n",
       "      <td>0.899390</td>\n",
       "      <td>0.012090</td>\n",
       "      <td>0.023859</td>\n",
       "      <td>0.903963</td>\n",
       "      <td>0.024302</td>\n",
       "      <td>0.047332</td>\n",
       "      <td>...</td>\n",
       "      <td>0.851683</td>\n",
       "      <td>0.229212</td>\n",
       "      <td>0.361212</td>\n",
       "      <td>0.836565</td>\n",
       "      <td>0.337732</td>\n",
       "      <td>0.481198</td>\n",
       "      <td>0.818259</td>\n",
       "      <td>0.550592</td>\n",
       "      <td>0.658256</td>\n",
       "      <td>0.634022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 'log2', 'min_...</td>\n",
       "      <td>2012-07-01</td>\n",
       "      <td>0.905488</td>\n",
       "      <td>0.012172</td>\n",
       "      <td>0.024020</td>\n",
       "      <td>0.908537</td>\n",
       "      <td>0.024425</td>\n",
       "      <td>0.047572</td>\n",
       "      <td>...</td>\n",
       "      <td>0.865388</td>\n",
       "      <td>0.232900</td>\n",
       "      <td>0.367024</td>\n",
       "      <td>0.846513</td>\n",
       "      <td>0.341748</td>\n",
       "      <td>0.486920</td>\n",
       "      <td>0.821244</td>\n",
       "      <td>0.552600</td>\n",
       "      <td>0.660657</td>\n",
       "      <td>0.640944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 50, 'max_features': 'sqrt', 'min...</td>\n",
       "      <td>2012-07-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013442</td>\n",
       "      <td>0.026528</td>\n",
       "      <td>0.669207</td>\n",
       "      <td>0.017991</td>\n",
       "      <td>0.035040</td>\n",
       "      <td>...</td>\n",
       "      <td>0.841785</td>\n",
       "      <td>0.226548</td>\n",
       "      <td>0.357014</td>\n",
       "      <td>0.758096</td>\n",
       "      <td>0.306053</td>\n",
       "      <td>0.436062</td>\n",
       "      <td>0.853889</td>\n",
       "      <td>0.574567</td>\n",
       "      <td>0.686918</td>\n",
       "      <td>0.580721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 50, 'max_features': 'sqrt', 'min...</td>\n",
       "      <td>2012-07-01</td>\n",
       "      <td>0.926829</td>\n",
       "      <td>0.012459</td>\n",
       "      <td>0.024587</td>\n",
       "      <td>0.917683</td>\n",
       "      <td>0.024671</td>\n",
       "      <td>0.048050</td>\n",
       "      <td>...</td>\n",
       "      <td>0.853205</td>\n",
       "      <td>0.229622</td>\n",
       "      <td>0.361857</td>\n",
       "      <td>0.830677</td>\n",
       "      <td>0.335355</td>\n",
       "      <td>0.477812</td>\n",
       "      <td>0.807418</td>\n",
       "      <td>0.543297</td>\n",
       "      <td>0.649535</td>\n",
       "      <td>0.615841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 50, 'max_features': 'sqrt', 'min...</td>\n",
       "      <td>2012-07-01</td>\n",
       "      <td>0.884146</td>\n",
       "      <td>0.011885</td>\n",
       "      <td>0.023454</td>\n",
       "      <td>0.876524</td>\n",
       "      <td>0.023565</td>\n",
       "      <td>0.045895</td>\n",
       "      <td>...</td>\n",
       "      <td>0.831430</td>\n",
       "      <td>0.223761</td>\n",
       "      <td>0.352622</td>\n",
       "      <td>0.826109</td>\n",
       "      <td>0.333511</td>\n",
       "      <td>0.475184</td>\n",
       "      <td>0.799257</td>\n",
       "      <td>0.537806</td>\n",
       "      <td>0.642969</td>\n",
       "      <td>0.603359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 50, 'max_features': 'sqrt', 'min...</td>\n",
       "      <td>2012-07-01</td>\n",
       "      <td>0.932927</td>\n",
       "      <td>0.012540</td>\n",
       "      <td>0.024748</td>\n",
       "      <td>0.925305</td>\n",
       "      <td>0.024876</td>\n",
       "      <td>0.048450</td>\n",
       "      <td>...</td>\n",
       "      <td>0.872697</td>\n",
       "      <td>0.234867</td>\n",
       "      <td>0.370124</td>\n",
       "      <td>0.849254</td>\n",
       "      <td>0.342855</td>\n",
       "      <td>0.488497</td>\n",
       "      <td>0.815336</td>\n",
       "      <td>0.548625</td>\n",
       "      <td>0.655904</td>\n",
       "      <td>0.632106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 50, 'max_features': 'log2', 'min...</td>\n",
       "      <td>2012-07-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013442</td>\n",
       "      <td>0.026528</td>\n",
       "      <td>0.704268</td>\n",
       "      <td>0.018934</td>\n",
       "      <td>0.036876</td>\n",
       "      <td>...</td>\n",
       "      <td>0.844221</td>\n",
       "      <td>0.227204</td>\n",
       "      <td>0.358047</td>\n",
       "      <td>0.767739</td>\n",
       "      <td>0.309946</td>\n",
       "      <td>0.441609</td>\n",
       "      <td>0.843779</td>\n",
       "      <td>0.567764</td>\n",
       "      <td>0.678785</td>\n",
       "      <td>0.571762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 50, 'max_features': 'log2', 'min...</td>\n",
       "      <td>2012-07-01</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.011762</td>\n",
       "      <td>0.023212</td>\n",
       "      <td>0.858232</td>\n",
       "      <td>0.023073</td>\n",
       "      <td>0.044938</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838587</td>\n",
       "      <td>0.225687</td>\n",
       "      <td>0.355657</td>\n",
       "      <td>0.821033</td>\n",
       "      <td>0.331462</td>\n",
       "      <td>0.472264</td>\n",
       "      <td>0.810463</td>\n",
       "      <td>0.545347</td>\n",
       "      <td>0.651984</td>\n",
       "      <td>0.606153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 50, 'max_features': 'log2', 'min...</td>\n",
       "      <td>2012-07-01</td>\n",
       "      <td>0.890244</td>\n",
       "      <td>0.011967</td>\n",
       "      <td>0.023616</td>\n",
       "      <td>0.890244</td>\n",
       "      <td>0.023933</td>\n",
       "      <td>0.046614</td>\n",
       "      <td>...</td>\n",
       "      <td>0.842089</td>\n",
       "      <td>0.226630</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.827023</td>\n",
       "      <td>0.333880</td>\n",
       "      <td>0.475709</td>\n",
       "      <td>0.804373</td>\n",
       "      <td>0.541248</td>\n",
       "      <td>0.647085</td>\n",
       "      <td>0.607609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 50, 'max_features': 'log2', 'min...</td>\n",
       "      <td>2012-07-01</td>\n",
       "      <td>0.902439</td>\n",
       "      <td>0.012131</td>\n",
       "      <td>0.023940</td>\n",
       "      <td>0.916159</td>\n",
       "      <td>0.024630</td>\n",
       "      <td>0.047971</td>\n",
       "      <td>...</td>\n",
       "      <td>0.865083</td>\n",
       "      <td>0.232818</td>\n",
       "      <td>0.366895</td>\n",
       "      <td>0.847224</td>\n",
       "      <td>0.342035</td>\n",
       "      <td>0.487329</td>\n",
       "      <td>0.814361</td>\n",
       "      <td>0.547969</td>\n",
       "      <td>0.655120</td>\n",
       "      <td>0.632334</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    model_name                                              model  \\\n",
       "0           LR  LogisticRegression(C=10, class_weight=None, du...   \n",
       "1           LR  LogisticRegression(C=10, class_weight=None, du...   \n",
       "2           LR  LogisticRegression(C=10, class_weight=None, du...   \n",
       "3           LR  LogisticRegression(C=10, class_weight=None, du...   \n",
       "4           LR  LogisticRegression(C=10, class_weight=None, du...   \n",
       "5           LR  LogisticRegression(C=10, class_weight=None, du...   \n",
       "6           LR  LogisticRegression(C=10, class_weight=None, du...   \n",
       "7           LR  LogisticRegression(C=10, class_weight=None, du...   \n",
       "8           DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "9           DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "10          DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "11          DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "12          DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "13          DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "14          DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "15          DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "16          DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "17          DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "18          DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "19          DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "20          DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "21          DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "22          DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "23          DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "24          DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "25          DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "26          DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "27          DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "28          AB  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "29          AB  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "..         ...                                                ...   \n",
       "120         DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "121         DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "122         DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "123         DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "124         DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "125         DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "126         DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "127         DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "128         AB  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "129         AB  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "130         AB  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "131         AB  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "132         AB  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "133         AB  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "134         RF  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "135         RF  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "136         RF  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "137         RF  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "138         RF  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "139         RF  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "140         RF  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "141         RF  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "142         RF  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "143         RF  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "144         RF  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "145         RF  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "146         RF  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "147         RF  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "148         RF  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "149         RF  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "\n",
       "                                            parameters  \\\n",
       "0                        {'C': 0.001, 'penalty': 'l1'}   \n",
       "1                        {'C': 0.001, 'penalty': 'l2'}   \n",
       "2                          {'C': 0.1, 'penalty': 'l1'}   \n",
       "3                          {'C': 0.1, 'penalty': 'l2'}   \n",
       "4                            {'C': 1, 'penalty': 'l1'}   \n",
       "5                            {'C': 1, 'penalty': 'l2'}   \n",
       "6                           {'C': 10, 'penalty': 'l1'}   \n",
       "7                           {'C': 10, 'penalty': 'l2'}   \n",
       "8    {'criterion': 'gini', 'max_depth': 1, 'min_sam...   \n",
       "9    {'criterion': 'gini', 'max_depth': 1, 'min_sam...   \n",
       "10   {'criterion': 'gini', 'max_depth': 5, 'min_sam...   \n",
       "11   {'criterion': 'gini', 'max_depth': 5, 'min_sam...   \n",
       "12   {'criterion': 'gini', 'max_depth': 10, 'min_sa...   \n",
       "13   {'criterion': 'gini', 'max_depth': 10, 'min_sa...   \n",
       "14   {'criterion': 'gini', 'max_depth': 50, 'min_sa...   \n",
       "15   {'criterion': 'gini', 'max_depth': 50, 'min_sa...   \n",
       "16   {'criterion': 'gini', 'max_depth': 100, 'min_s...   \n",
       "17   {'criterion': 'gini', 'max_depth': 100, 'min_s...   \n",
       "18   {'criterion': 'entropy', 'max_depth': 1, 'min_...   \n",
       "19   {'criterion': 'entropy', 'max_depth': 1, 'min_...   \n",
       "20   {'criterion': 'entropy', 'max_depth': 5, 'min_...   \n",
       "21   {'criterion': 'entropy', 'max_depth': 5, 'min_...   \n",
       "22   {'criterion': 'entropy', 'max_depth': 10, 'min...   \n",
       "23   {'criterion': 'entropy', 'max_depth': 10, 'min...   \n",
       "24   {'criterion': 'entropy', 'max_depth': 50, 'min...   \n",
       "25   {'criterion': 'entropy', 'max_depth': 50, 'min...   \n",
       "26   {'criterion': 'entropy', 'max_depth': 100, 'mi...   \n",
       "27   {'criterion': 'entropy', 'max_depth': 100, 'mi...   \n",
       "28           {'algorithm': 'SAMME', 'n_estimators': 1}   \n",
       "29          {'algorithm': 'SAMME', 'n_estimators': 10}   \n",
       "..                                                 ...   \n",
       "120  {'criterion': 'entropy', 'max_depth': 5, 'min_...   \n",
       "121  {'criterion': 'entropy', 'max_depth': 5, 'min_...   \n",
       "122  {'criterion': 'entropy', 'max_depth': 10, 'min...   \n",
       "123  {'criterion': 'entropy', 'max_depth': 10, 'min...   \n",
       "124  {'criterion': 'entropy', 'max_depth': 50, 'min...   \n",
       "125  {'criterion': 'entropy', 'max_depth': 50, 'min...   \n",
       "126  {'criterion': 'entropy', 'max_depth': 100, 'mi...   \n",
       "127  {'criterion': 'entropy', 'max_depth': 100, 'mi...   \n",
       "128          {'algorithm': 'SAMME', 'n_estimators': 1}   \n",
       "129         {'algorithm': 'SAMME', 'n_estimators': 10}   \n",
       "130        {'algorithm': 'SAMME', 'n_estimators': 100}   \n",
       "131        {'algorithm': 'SAMME.R', 'n_estimators': 1}   \n",
       "132       {'algorithm': 'SAMME.R', 'n_estimators': 10}   \n",
       "133      {'algorithm': 'SAMME.R', 'n_estimators': 100}   \n",
       "134  {'max_depth': 5, 'max_features': 'sqrt', 'min_...   \n",
       "135  {'max_depth': 5, 'max_features': 'sqrt', 'min_...   \n",
       "136  {'max_depth': 5, 'max_features': 'sqrt', 'min_...   \n",
       "137  {'max_depth': 5, 'max_features': 'sqrt', 'min_...   \n",
       "138  {'max_depth': 5, 'max_features': 'log2', 'min_...   \n",
       "139  {'max_depth': 5, 'max_features': 'log2', 'min_...   \n",
       "140  {'max_depth': 5, 'max_features': 'log2', 'min_...   \n",
       "141  {'max_depth': 5, 'max_features': 'log2', 'min_...   \n",
       "142  {'max_depth': 50, 'max_features': 'sqrt', 'min...   \n",
       "143  {'max_depth': 50, 'max_features': 'sqrt', 'min...   \n",
       "144  {'max_depth': 50, 'max_features': 'sqrt', 'min...   \n",
       "145  {'max_depth': 50, 'max_features': 'sqrt', 'min...   \n",
       "146  {'max_depth': 50, 'max_features': 'log2', 'min...   \n",
       "147  {'max_depth': 50, 'max_features': 'log2', 'min...   \n",
       "148  {'max_depth': 50, 'max_features': 'log2', 'min...   \n",
       "149  {'max_depth': 50, 'max_features': 'log2', 'min...   \n",
       "\n",
       "    train_test_split_threshold    p_at_1    r_at_1   f1_at_1    p_at_2  \\\n",
       "0                   2013-07-01  0.861678  0.012027  0.023723  0.840317   \n",
       "1                   2013-07-01  0.934240  0.013040  0.025721  0.925255   \n",
       "2                   2013-07-01  0.963719  0.013451  0.026533  0.966025   \n",
       "3                   2013-07-01  0.959184  0.013388  0.026408  0.967157   \n",
       "4                   2013-07-01  0.963719  0.013451  0.026533  0.960362   \n",
       "5                   2013-07-01  0.963719  0.013451  0.026533  0.963760   \n",
       "6                   2013-07-01  0.963719  0.013451  0.026533  0.960362   \n",
       "7                   2013-07-01  0.959184  0.013388  0.026408  0.966025   \n",
       "8                   2013-07-01  1.000000  0.013958  0.027532  1.000000   \n",
       "9                   2013-07-01  1.000000  0.013958  0.027532  1.000000   \n",
       "10                  2013-07-01  1.000000  0.013958  0.027532  0.967157   \n",
       "11                  2013-07-01  1.000000  0.013958  0.027532  0.967157   \n",
       "12                  2013-07-01  0.671202  0.009369  0.018479  0.767837   \n",
       "13                  2013-07-01  0.673469  0.009400  0.018542  0.768969   \n",
       "14                  2013-07-01  0.997732  0.013926  0.027469  0.998867   \n",
       "15                  2013-07-01  0.997732  0.013926  0.027469  0.998867   \n",
       "16                  2013-07-01  0.997732  0.013926  0.027469  0.998867   \n",
       "17                  2013-07-01  0.997732  0.013926  0.027469  0.998867   \n",
       "18                  2013-07-01  1.000000  0.013958  0.027532  1.000000   \n",
       "19                  2013-07-01  1.000000  0.013958  0.027532  1.000000   \n",
       "20                  2013-07-01  0.977324  0.013641  0.026907  0.984145   \n",
       "21                  2013-07-01  0.977324  0.013641  0.026907  0.984145   \n",
       "22                  2013-07-01  0.650794  0.009084  0.017917  0.585504   \n",
       "23                  2013-07-01  0.648526  0.009052  0.017855  0.583239   \n",
       "24                  2013-07-01  1.000000  0.013958  0.027532  1.000000   \n",
       "25                  2013-07-01  0.997732  0.013926  0.027469  0.998867   \n",
       "26                  2013-07-01  1.000000  0.013958  0.027532  1.000000   \n",
       "27                  2013-07-01  0.997732  0.013926  0.027469  0.998867   \n",
       "28                  2013-07-01  1.000000  0.013958  0.027532  1.000000   \n",
       "29                  2013-07-01  1.000000  0.013958  0.027532  1.000000   \n",
       "..                         ...       ...       ...       ...       ...   \n",
       "120                 2012-07-01  0.963415  0.012950  0.025557  0.788110   \n",
       "121                 2012-07-01  0.963415  0.012950  0.025557  0.788110   \n",
       "122                 2012-07-01  1.000000  0.013442  0.026528  1.000000   \n",
       "123                 2012-07-01  1.000000  0.013442  0.026528  1.000000   \n",
       "124                 2012-07-01  1.000000  0.013442  0.026528  1.000000   \n",
       "125                 2012-07-01  0.996951  0.013401  0.026447  0.998476   \n",
       "126                 2012-07-01  1.000000  0.013442  0.026528  1.000000   \n",
       "127                 2012-07-01  0.996951  0.013401  0.026447  0.998476   \n",
       "128                 2012-07-01  1.000000  0.013442  0.026528  1.000000   \n",
       "129                 2012-07-01  1.000000  0.013442  0.026528  1.000000   \n",
       "130                 2012-07-01  0.954268  0.012827  0.025314  0.957317   \n",
       "131                 2012-07-01  1.000000  0.013442  0.026528  1.000000   \n",
       "132                 2012-07-01  1.000000  0.013442  0.026528  1.000000   \n",
       "133                 2012-07-01  0.972561  0.013073  0.025800  0.961890   \n",
       "134                 2012-07-01  0.875000  0.011762  0.023212  0.876524   \n",
       "135                 2012-07-01  0.951220  0.012786  0.025234  0.917683   \n",
       "136                 2012-07-01  0.905488  0.012172  0.024020  0.873476   \n",
       "137                 2012-07-01  0.948171  0.012745  0.025153  0.916159   \n",
       "138                 2012-07-01  0.887195  0.011926  0.023535  0.876524   \n",
       "139                 2012-07-01  0.896341  0.012049  0.023778  0.882622   \n",
       "140                 2012-07-01  0.899390  0.012090  0.023859  0.903963   \n",
       "141                 2012-07-01  0.905488  0.012172  0.024020  0.908537   \n",
       "142                 2012-07-01  1.000000  0.013442  0.026528  0.669207   \n",
       "143                 2012-07-01  0.926829  0.012459  0.024587  0.917683   \n",
       "144                 2012-07-01  0.884146  0.011885  0.023454  0.876524   \n",
       "145                 2012-07-01  0.932927  0.012540  0.024748  0.925305   \n",
       "146                 2012-07-01  1.000000  0.013442  0.026528  0.704268   \n",
       "147                 2012-07-01  0.875000  0.011762  0.023212  0.858232   \n",
       "148                 2012-07-01  0.890244  0.011967  0.023616  0.890244   \n",
       "149                 2012-07-01  0.902439  0.012131  0.023940  0.916159   \n",
       "\n",
       "       r_at_2   f1_at_2    ...      p_at_20   r_at_20  f1_at_20   p_at_30  \\\n",
       "0    0.023485  0.045692    ...     0.767689  0.214623  0.335461  0.756604   \n",
       "1    0.025859  0.050311    ...     0.858259  0.239943  0.375037  0.836906   \n",
       "2    0.026998  0.052528    ...     0.903204  0.252508  0.394677  0.874717   \n",
       "3    0.027030  0.052589    ...     0.899921  0.251590  0.393242  0.873208   \n",
       "4    0.026840  0.052220    ...     0.903770  0.252667  0.394924  0.875623   \n",
       "5    0.026935  0.052405    ...     0.903996  0.252730  0.395023  0.875170   \n",
       "6    0.026840  0.052220    ...     0.903544  0.252603  0.394825  0.875396   \n",
       "7    0.026998  0.052528    ...     0.899808  0.251559  0.393193  0.873962   \n",
       "8    0.027947  0.054375    ...     1.000000  0.279570  0.436974  1.000000   \n",
       "9    0.027947  0.054375    ...     1.000000  0.279570  0.436974  1.000000   \n",
       "10   0.027030  0.052589    ...     0.904676  0.252920  0.395320  0.858038   \n",
       "11   0.027030  0.052589    ...     0.904676  0.252920  0.395320  0.858038   \n",
       "12   0.021459  0.041751    ...     0.851579  0.238076  0.372118  0.833811   \n",
       "13   0.021491  0.041813    ...     0.851353  0.238012  0.372019  0.833887   \n",
       "14   0.027916  0.054314    ...     0.948262  0.265105  0.414366  0.965434   \n",
       "15   0.027916  0.054314    ...     0.687422  0.192182  0.300386  0.752830   \n",
       "16   0.027916  0.054314    ...     0.931960  0.260548  0.407243  0.954566   \n",
       "17   0.027916  0.054314    ...     0.687422  0.192182  0.300386  0.747019   \n",
       "18   0.027947  0.054375    ...     1.000000  0.279570  0.436974  1.000000   \n",
       "19   0.027947  0.054375    ...     1.000000  0.279570  0.436974  1.000000   \n",
       "20   0.027504  0.053513    ...     0.903544  0.252603  0.394825  0.855245   \n",
       "21   0.027504  0.053513    ...     0.903544  0.252603  0.394825  0.855245   \n",
       "22   0.016363  0.031837    ...     0.850221  0.237696  0.371525  0.846264   \n",
       "23   0.016300  0.031714    ...     0.849994  0.237633  0.371426  0.846189   \n",
       "24   0.027947  0.054375    ...     1.000000  0.279570  0.436974  1.000000   \n",
       "25   0.027916  0.054314    ...     0.795087  0.222282  0.347432  0.863321   \n",
       "26   0.027947  0.054375    ...     1.000000  0.279570  0.436974  1.000000   \n",
       "27   0.027916  0.054314    ...     0.819088  0.228992  0.357920  0.879321   \n",
       "28   0.027947  0.054375    ...     1.000000  0.279570  0.436974  1.000000   \n",
       "29   0.027947  0.054375    ...     0.858259  0.239943  0.375037  0.823698   \n",
       "..        ...       ...    ...          ...       ...       ...       ...   \n",
       "120  0.021188  0.041266    ...     0.749201  0.201631  0.317747  0.829865   \n",
       "121  0.021188  0.041266    ...     0.749201  0.201631  0.317747  0.829865   \n",
       "122  0.026884  0.052361    ...     0.835998  0.224991  0.354560  0.821744   \n",
       "123  0.026884  0.052361    ...     0.838282  0.225606  0.355528  0.823267   \n",
       "124  0.026884  0.052361    ...     1.000000  0.269128  0.424115  1.000000   \n",
       "125  0.026843  0.052281    ...     0.976549  0.262817  0.414169  0.984367   \n",
       "126  0.026884  0.052361    ...     1.000000  0.269128  0.424115  1.000000   \n",
       "127  0.026843  0.052281    ...     0.976549  0.262817  0.414169  0.984367   \n",
       "128  0.026884  0.052361    ...     1.000000  0.269128  0.424115  1.000000   \n",
       "129  0.026884  0.052361    ...     0.845135  0.227450  0.358435  0.853822   \n",
       "130  0.025737  0.050126    ...     0.854576  0.229991  0.362439  0.855345   \n",
       "131  0.026884  0.052361    ...     1.000000  0.269128  0.424115  1.000000   \n",
       "132  0.026884  0.052361    ...     0.865692  0.232982  0.367153  0.833113   \n",
       "133  0.025860  0.050365    ...     0.897518  0.241547  0.380651  0.872906   \n",
       "134  0.023565  0.045895    ...     0.845135  0.227450  0.358435  0.834839   \n",
       "135  0.024671  0.048050    ...     0.864626  0.232695  0.366701  0.852096   \n",
       "136  0.023483  0.045736    ...     0.845592  0.227573  0.358628  0.835753   \n",
       "137  0.024630  0.047971    ...     0.865235  0.232859  0.366959  0.852299   \n",
       "138  0.023565  0.045895    ...     0.856251  0.230441  0.363149  0.837275   \n",
       "139  0.023729  0.046215    ...     0.862190  0.232040  0.365668  0.846818   \n",
       "140  0.024302  0.047332    ...     0.851683  0.229212  0.361212  0.836565   \n",
       "141  0.024425  0.047572    ...     0.865388  0.232900  0.367024  0.846513   \n",
       "142  0.017991  0.035040    ...     0.841785  0.226548  0.357014  0.758096   \n",
       "143  0.024671  0.048050    ...     0.853205  0.229622  0.361857  0.830677   \n",
       "144  0.023565  0.045895    ...     0.831430  0.223761  0.352622  0.826109   \n",
       "145  0.024876  0.048450    ...     0.872697  0.234867  0.370124  0.849254   \n",
       "146  0.018934  0.036876    ...     0.844221  0.227204  0.358047  0.767739   \n",
       "147  0.023073  0.044938    ...     0.838587  0.225687  0.355657  0.821033   \n",
       "148  0.023933  0.046614    ...     0.842089  0.226630  0.357143  0.827023   \n",
       "149  0.024630  0.047971    ...     0.865083  0.232818  0.366895  0.847224   \n",
       "\n",
       "      r_at_30  f1_at_30   p_at_50   r_at_50  f1_at_50   auc-roc  \n",
       "0    0.317297  0.447096  0.730653  0.510682  0.601177  0.537428  \n",
       "1    0.350973  0.494548  0.799257  0.558633  0.657625  0.638292  \n",
       "2    0.366830  0.516892  0.820224  0.573287  0.674876  0.673192  \n",
       "3    0.366197  0.516000  0.820722  0.573635  0.675286  0.673600  \n",
       "4    0.367210  0.517427  0.819997  0.573129  0.674690  0.672998  \n",
       "5    0.367020  0.517159  0.819907  0.573065  0.674615  0.673964  \n",
       "6    0.367115  0.517293  0.819997  0.573129  0.674690  0.672998  \n",
       "7    0.366514  0.516446  0.820677  0.573603  0.675249  0.673729  \n",
       "8    0.419370  0.590924  1.000000  0.698940  0.822795  0.579323  \n",
       "9    0.419370  0.590924  1.000000  0.698940  0.822795  0.579323  \n",
       "10   0.359835  0.507035  0.811575  0.567242  0.667760  0.653808  \n",
       "11   0.359835  0.507035  0.811575  0.567242  0.667760  0.653808  \n",
       "12   0.349676  0.492719  0.805823  0.563222  0.663028  0.646482  \n",
       "13   0.349707  0.492764  0.806050  0.563380  0.663214  0.646512  \n",
       "14   0.404874  0.570498  0.979215  0.684412  0.805693  0.540092  \n",
       "15   0.315715  0.444866  0.851651  0.595252  0.700734  0.547933  \n",
       "16   0.400317  0.564076  0.972694  0.679854  0.800328  0.536223  \n",
       "17   0.313277  0.441432  0.848164  0.592815  0.697865  0.547202  \n",
       "18   0.419370  0.590924  1.000000  0.698940  0.822795  0.579323  \n",
       "19   0.419370  0.590924  1.000000  0.698940  0.822795  0.579323  \n",
       "20   0.358664  0.505385  0.814427  0.569236  0.670107  0.653398  \n",
       "21   0.358664  0.505385  0.814427  0.569236  0.670107  0.653398  \n",
       "22   0.354898  0.500078  0.807907  0.564678  0.664742  0.647379  \n",
       "23   0.354866  0.500033  0.807816  0.564615  0.664667  0.647223  \n",
       "24   0.419370  0.590924  1.000000  0.698940  0.822795  0.540259  \n",
       "25   0.362051  0.510157  0.917946  0.641589  0.755281  0.548255  \n",
       "26   0.419370  0.590924  1.000000  0.698940  0.822795  0.543410  \n",
       "27   0.368761  0.519612  0.927546  0.648299  0.763180  0.546703  \n",
       "28   0.419370  0.590924  1.000000  0.698940  0.822795  0.579323  \n",
       "29   0.345434  0.486743  0.818684  0.572211  0.673609  0.651652  \n",
       "..        ...       ...       ...       ...       ...       ...  \n",
       "120  0.335027  0.477344  0.897923  0.604197  0.722342  0.605496  \n",
       "121  0.335027  0.477344  0.897923  0.604197  0.722342  0.605496  \n",
       "122  0.331749  0.472673  0.815458  0.548707  0.656002  0.613331  \n",
       "123  0.332363  0.473549  0.815031  0.548420  0.655659  0.612698  \n",
       "124  0.403713  0.575207  1.000000  0.672882  0.804459  0.545247  \n",
       "125  0.397402  0.566215  0.990560  0.666530  0.796864  0.549429  \n",
       "126  0.403713  0.575207  1.000000  0.672882  0.804459  0.545247  \n",
       "127  0.397402  0.566215  0.990560  0.666530  0.796864  0.549429  \n",
       "128  0.403713  0.575207  1.000000  0.672882  0.804459  0.559447  \n",
       "129  0.344699  0.491125  0.837871  0.563788  0.674032  0.624234  \n",
       "130  0.345314  0.492000  0.821609  0.552846  0.660951  0.637534  \n",
       "131  0.403713  0.575207  1.000000  0.672882  0.804459  0.559447  \n",
       "132  0.336339  0.479213  0.835435  0.562149  0.672073  0.635815  \n",
       "133  0.352404  0.502102  0.830319  0.558707  0.667957  0.653333  \n",
       "134  0.337035  0.480206  0.815823  0.548953  0.656296  0.626015  \n",
       "135  0.344002  0.490132  0.823984  0.554444  0.662861  0.642483  \n",
       "136  0.337404  0.480731  0.817468  0.550059  0.657619  0.629299  \n",
       "137  0.344084  0.490249  0.824106  0.554526  0.662959  0.642183  \n",
       "138  0.338019  0.481607  0.818564  0.550797  0.658501  0.634428  \n",
       "139  0.341871  0.487096  0.822157  0.553215  0.661391  0.640744  \n",
       "140  0.337732  0.481198  0.818259  0.550592  0.658256  0.634022  \n",
       "141  0.341748  0.486920  0.821244  0.552600  0.660657  0.640944  \n",
       "142  0.306053  0.436062  0.853889  0.574567  0.686918  0.580721  \n",
       "143  0.335355  0.477812  0.807418  0.543297  0.649535  0.615841  \n",
       "144  0.333511  0.475184  0.799257  0.537806  0.642969  0.603359  \n",
       "145  0.342855  0.488497  0.815336  0.548625  0.655904  0.632106  \n",
       "146  0.309946  0.441609  0.843779  0.567764  0.678785  0.571762  \n",
       "147  0.331462  0.472264  0.810463  0.545347  0.651984  0.606153  \n",
       "148  0.333880  0.475709  0.804373  0.541248  0.647085  0.607609  \n",
       "149  0.342035  0.487329  0.814361  0.547969  0.655120  0.632334  \n",
       "\n",
       "[150 rows x 26 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "importlib.reload(pipeline)\n",
    "\n",
    "results = pipeline.iterate_over_models_and_training_test_sets(models_to_run, models, parameters_grid, train_test_sets)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observe best models for each train/test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ranking by AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>model</th>\n",
       "      <th>parameters</th>\n",
       "      <th>train_test_split_threshold</th>\n",
       "      <th>p_at_1</th>\n",
       "      <th>r_at_1</th>\n",
       "      <th>f1_at_1</th>\n",
       "      <th>p_at_2</th>\n",
       "      <th>r_at_2</th>\n",
       "      <th>f1_at_2</th>\n",
       "      <th>...</th>\n",
       "      <th>p_at_20</th>\n",
       "      <th>r_at_20</th>\n",
       "      <th>f1_at_20</th>\n",
       "      <th>p_at_30</th>\n",
       "      <th>r_at_30</th>\n",
       "      <th>f1_at_30</th>\n",
       "      <th>p_at_50</th>\n",
       "      <th>r_at_50</th>\n",
       "      <th>f1_at_50</th>\n",
       "      <th>auc-roc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>AB</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'algorithm': 'SAMME.R', 'n_estimators': 100}</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>0.961451</td>\n",
       "      <td>0.013420</td>\n",
       "      <td>0.026470</td>\n",
       "      <td>0.959230</td>\n",
       "      <td>0.026808</td>\n",
       "      <td>0.052158</td>\n",
       "      <td>...</td>\n",
       "      <td>0.903996</td>\n",
       "      <td>0.252730</td>\n",
       "      <td>0.395023</td>\n",
       "      <td>0.874943</td>\n",
       "      <td>0.366925</td>\n",
       "      <td>0.517025</td>\n",
       "      <td>0.821084</td>\n",
       "      <td>0.573888</td>\n",
       "      <td>0.675584</td>\n",
       "      <td>0.674833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'l1'}</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>0.948837</td>\n",
       "      <td>0.013796</td>\n",
       "      <td>0.027196</td>\n",
       "      <td>0.925754</td>\n",
       "      <td>0.026983</td>\n",
       "      <td>0.052438</td>\n",
       "      <td>...</td>\n",
       "      <td>0.876303</td>\n",
       "      <td>0.255833</td>\n",
       "      <td>0.396043</td>\n",
       "      <td>0.851274</td>\n",
       "      <td>0.372760</td>\n",
       "      <td>0.518484</td>\n",
       "      <td>0.800130</td>\n",
       "      <td>0.583959</td>\n",
       "      <td>0.675163</td>\n",
       "      <td>0.680477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>{'C': 1, 'penalty': 'l1'}</td>\n",
       "      <td>2012-07-01</td>\n",
       "      <td>0.957317</td>\n",
       "      <td>0.012868</td>\n",
       "      <td>0.025395</td>\n",
       "      <td>0.963415</td>\n",
       "      <td>0.025901</td>\n",
       "      <td>0.050445</td>\n",
       "      <td>...</td>\n",
       "      <td>0.906502</td>\n",
       "      <td>0.243965</td>\n",
       "      <td>0.384461</td>\n",
       "      <td>0.876459</td>\n",
       "      <td>0.353838</td>\n",
       "      <td>0.504146</td>\n",
       "      <td>0.838358</td>\n",
       "      <td>0.564116</td>\n",
       "      <td>0.674424</td>\n",
       "      <td>0.665507</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    model_name                                              model  \\\n",
       "33          AB  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "52          LR  LogisticRegression(C=10, class_weight=None, du...   \n",
       "104         LR  LogisticRegression(C=10, class_weight=None, du...   \n",
       "\n",
       "                                        parameters train_test_split_threshold  \\\n",
       "33   {'algorithm': 'SAMME.R', 'n_estimators': 100}                 2013-07-01   \n",
       "52                     {'C': 0.1, 'penalty': 'l1'}                 2013-01-01   \n",
       "104                      {'C': 1, 'penalty': 'l1'}                 2012-07-01   \n",
       "\n",
       "       p_at_1    r_at_1   f1_at_1    p_at_2    r_at_2   f1_at_2    ...     \\\n",
       "33   0.961451  0.013420  0.026470  0.959230  0.026808  0.052158    ...      \n",
       "52   0.948837  0.013796  0.027196  0.925754  0.026983  0.052438    ...      \n",
       "104  0.957317  0.012868  0.025395  0.963415  0.025901  0.050445    ...      \n",
       "\n",
       "      p_at_20   r_at_20  f1_at_20   p_at_30   r_at_30  f1_at_30   p_at_50  \\\n",
       "33   0.903996  0.252730  0.395023  0.874943  0.366925  0.517025  0.821084   \n",
       "52   0.876303  0.255833  0.396043  0.851274  0.372760  0.518484  0.800130   \n",
       "104  0.906502  0.243965  0.384461  0.876459  0.353838  0.504146  0.838358   \n",
       "\n",
       "      r_at_50  f1_at_50   auc-roc  \n",
       "33   0.573888  0.675584  0.674833  \n",
       "52   0.583959  0.675163  0.680477  \n",
       "104  0.564116  0.674424  0.665507  \n",
       "\n",
       "[3 rows x 26 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lets obtain the best model for each train/test set\n",
    "\n",
    "#indices of rows that have max auc for each train/test set\n",
    "idx = results.groupby(['train_test_split_threshold'])['auc-roc'].transform(max) == results['auc-roc']\n",
    "\n",
    "#display best models\n",
    "best_auc = results[idx]\n",
    "best_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare all models performance at different train/test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For each model, find the set of parameters that work the best in each train/test set\n",
    "\n",
    "#In this dataframe we will save the best model for each type of model (ex 1 LR, 1 RF..), whichever perfomed the best in each train/test set\n",
    "best_models= pd.DataFrame()\n",
    "\n",
    "for model in models_to_run:\n",
    "  #Filter data selecting only rows of this specific model\n",
    "  results_of_model = results[results[\"model_name\"]==model]  \n",
    "  #For each train/test set, find index of best model (parameters)\n",
    "  idx = results_of_model.groupby(['train_test_split_threshold'])['auc-roc'].transform(max) == results_of_model['auc-roc']\n",
    "    \n",
    "  #Grab those results based on index\n",
    "  best_model = results_of_model[idx]\n",
    "  #Append it to final list\n",
    "  best_models=best_models.append(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Clear plot\n",
    "plt.clf()\n",
    "\n",
    "#Create plot and axis\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "#Create lines for each model\n",
    "for model in models_to_run:\n",
    "  ax1.plot( 'train_test_split_threshold', 'auc-roc', data=best_models[best_models['model_name']==model], label=model, marker='o', markersize=6, linewidth=4,alpha=0.6)\n",
    "\n",
    "#Show legends\n",
    "plt.legend()\n",
    "\n",
    "#Set axis labels\n",
    "ax1.set_xlabel('Train/test set split')\n",
    "ax1.set_ylabel('AUC-ROC',)\n",
    "\n",
    "#Invert x_axis so as to show from earliest to latest\n",
    "ax1.invert_xaxis()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
