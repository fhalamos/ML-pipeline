{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspired/based on https://github.com/rayidghani/magicloops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pipeline_v2 as pipeline\n",
    "import importlib\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(pipeline)\n",
    "\n",
    "data = pipeline.read_csv('projects_2012_2013.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data exploration...\n",
      "\n",
      "Number of rows: 124976\n",
      "\n",
      "Columns and types of data:\n",
      "projectid                                  object\n",
      "teacher_acctid                             object\n",
      "schoolid                                   object\n",
      "school_ncesid                             float64\n",
      "school_latitude                           float64\n",
      "school_longitude                          float64\n",
      "school_city                                object\n",
      "school_state                               object\n",
      "school_metro                               object\n",
      "school_district                            object\n",
      "school_county                              object\n",
      "school_charter                             object\n",
      "school_magnet                              object\n",
      "teacher_prefix                             object\n",
      "primary_focus_subject                      object\n",
      "primary_focus_area                         object\n",
      "secondary_focus_subject                    object\n",
      "secondary_focus_area                       object\n",
      "resource_type                              object\n",
      "poverty_level                              object\n",
      "grade_level                                object\n",
      "total_price_including_optional_support    float64\n",
      "students_reached                          float64\n",
      "eligible_double_your_impact_match          object\n",
      "date_posted                                object\n",
      "datefullyfunded                            object\n",
      "dtype: object\n",
      "\n",
      "\n",
      "Statistics for selected variables:\n",
      "count    124976.000000\n",
      "mean        654.011811\n",
      "std        1098.015854\n",
      "min          92.000000\n",
      "25%         345.810000\n",
      "50%         510.500000\n",
      "75%         752.960000\n",
      "max      164382.840000\n",
      "Name: total_price_including_optional_support, dtype: float64\n",
      "Number of outliers (>4 standard dev):521\n",
      "\n",
      "\n",
      "count    124917.000000\n",
      "mean         95.445760\n",
      "std         163.481912\n",
      "min           1.000000\n",
      "25%          23.000000\n",
      "50%          30.000000\n",
      "75%         100.000000\n",
      "max       12143.000000\n",
      "Name: students_reached, dtype: float64\n",
      "Number of outliers (>4 standard dev):2063\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Correlation between ['total_price_including_optional_support', 'students_reached']\n",
      "0.1766274350291622\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "importlib.reload(pipeline)\n",
    "\n",
    "stats_for_variables = [\n",
    "  'total_price_including_optional_support',\n",
    "  'students_reached'\n",
    "]\n",
    "\n",
    "variables_for_correlation = [\n",
    "  'total_price_including_optional_support',\n",
    "  'students_reached'\n",
    "]\n",
    "\n",
    "pipeline.explore_data(data, stats_for_variables, variables_for_correlation)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can clearly see in the histograms that DebtRadio MontlyIncome have very big outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre processing data...\n",
      "Done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(pipeline)\n",
    "\n",
    "columns_to_process = [\n",
    "  'total_price_including_optional_support',\n",
    "  'students_reached'\n",
    "]\n",
    "\n",
    "data = pipeline.pre_process_data(data, columns_to_process)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create discrete features and select predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(pipeline)\n",
    "\n",
    "cols_to_transform = [\n",
    "'school_state',\n",
    "'school_metro',\n",
    "'school_charter',\n",
    "'school_magnet',\n",
    "'primary_focus_subject',\n",
    "'primary_focus_area',\n",
    "'resource_type',\n",
    "'poverty_level',\n",
    "'grade_level',\n",
    "'eligible_double_your_impact_match']\n",
    "\n",
    "\n",
    "data = pipeline.create_dummies(data, cols_to_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = ['school_state_AK','school_state_AL','school_state_AR','school_state_AZ','school_state_CA','school_state_CO','school_state_CT','school_state_DC','school_state_DE','school_state_FL','school_state_GA','school_state_HI','school_state_IA','school_state_ID','school_state_IL','school_state_IN','school_state_KS','school_state_KY','school_state_LA','school_state_MA','school_state_MD','school_state_ME','school_state_MI','school_state_MN','school_state_MO','school_state_MS','school_state_MT','school_state_NC','school_state_ND','school_state_NE','school_state_NH','school_state_NJ','school_state_NM','school_state_NV','school_state_NY','school_state_OH','school_state_OK','school_state_OR','school_state_PA','school_state_RI','school_state_SC','school_state_SD','school_state_TN','school_state_TX','school_state_UT','school_state_VA','school_state_VT','school_state_WA','school_state_WI','school_state_WV','school_state_WY','school_state_nan','school_metro_rural','school_metro_suburban','school_metro_urban','school_metro_nan','school_charter_f','school_charter_t','school_charter_nan','school_magnet_f','school_magnet_t','school_magnet_nan','primary_focus_subject_Applied Sciences','primary_focus_subject_Character Education','primary_focus_subject_Civics & Government','primary_focus_subject_College & Career Prep','primary_focus_subject_Community Service','primary_focus_subject_ESL','primary_focus_subject_Early Development','primary_focus_subject_Economics','primary_focus_subject_Environmental Science','primary_focus_subject_Extracurricular','primary_focus_subject_Foreign Languages','primary_focus_subject_Gym & Fitness','primary_focus_subject_Health & Life Science','primary_focus_subject_Health & Wellness','primary_focus_subject_History & Geography','primary_focus_subject_Literacy','primary_focus_subject_Literature & Writing','primary_focus_subject_Mathematics','primary_focus_subject_Music','primary_focus_subject_Nutrition','primary_focus_subject_Other','primary_focus_subject_Parent Involvement','primary_focus_subject_Performing Arts','primary_focus_subject_Social Sciences','primary_focus_subject_Special Needs','primary_focus_subject_Sports','primary_focus_subject_Visual Arts','primary_focus_subject_nan','primary_focus_area_Applied Learning','primary_focus_area_Health & Sports','primary_focus_area_History & Civics','primary_focus_area_Literacy & Language','primary_focus_area_Math & Science','primary_focus_area_Music & The Arts','primary_focus_area_Special Needs','primary_focus_area_nan','resource_type_Books','resource_type_Other','resource_type_Supplies','resource_type_Technology','resource_type_Trips','resource_type_Visitors','resource_type_nan','poverty_level_high poverty','poverty_level_highest poverty','poverty_level_low poverty','poverty_level_moderate poverty','poverty_level_nan','grade_level_Grades 3-5','grade_level_Grades 6-8','grade_level_Grades 9-12','grade_level_Grades PreK-2','grade_level_nan','eligible_double_your_impact_match_f','eligible_double_your_impact_match_t','eligible_double_your_impact_match_nan']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create binary variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(pipeline)\n",
    "\n",
    "# The task is to predict if a project on donorschoose will not get fully funded within 60 days of posting.\n",
    "\n",
    "# Change dates to date format\n",
    "data['datefullyfunded_formated'] = pd.to_datetime(data['datefullyfunded'])\n",
    "data['date_posted_formated'] = pd.to_datetime(data['date_posted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(pipeline)\n",
    "\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "#Calculate difference between two dates\n",
    "data['time_to_fund'] = data['datefullyfunded_formated'].sub(data['date_posted_formated'], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(pipeline)\n",
    "\n",
    "data['time_to_fund'] = pd.to_numeric(data['time_to_fund'] / np.timedelta64(1, 'D'))\n",
    "data['funded_in_60'] = np.where(data['time_to_fund']<61, 1, 0)\n",
    "\n",
    "outcome ='funded_in_60'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count                  124976\n",
       "unique                    731\n",
       "top       2012-09-30 00:00:00\n",
       "freq                      728\n",
       "first     2012-01-01 00:00:00\n",
       "last      2013-12-31 00:00:00\n",
       "Name: date_posted_formated, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['date_posted_formated'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(pipeline)\n",
    "\n",
    "start_time = str(data['date_posted_formated'].describe()['first']).split(\" \")[0]\n",
    "end_time = str(data['date_posted_formated'].describe()['last']).split(\" \")[0]\n",
    "prediction_window = 6\n",
    "date_column='date_posted_formated'\n",
    "\n",
    "\n",
    "sets = pipeline.create_temp_validation_train_and_testing_sets(data, \n",
    "                                                                   selected_features,\n",
    "                                                                   outcome,\n",
    "                                                                   start_time,\n",
    "                                                                   end_time,\n",
    "                                                                   prediction_window,\n",
    "                                                                   date_column)\n",
    "x_train_1 = sets[0]\n",
    "x_test_1 = sets[1]\n",
    "y_train_1 = sets[2]\n",
    "y_test_1 = sets[3]\n",
    "\n",
    "x_train_2 = sets[4]\n",
    "x_test_2 = sets[5]\n",
    "y_train_2 = sets[6]\n",
    "y_test_2 = sets[7]\n",
    "\n",
    "x_train_3 = sets[8]\n",
    "x_test_3 = sets[9]\n",
    "y_train_3 = sets[10]\n",
    "y_test_3 = sets[11]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Clasifiers and parameters generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(pipeline)\n",
    "\n",
    "#We define the specific models we want to run\n",
    "\n",
    "#Not running BA and KNN because they are taking ages\n",
    "models_to_run=['LR','DT','LR','AB','RF','SVM']#,'BA','KNN']\n",
    "\n",
    "#Get all posible models and their different sets of parameters\n",
    "models, parameters_grid = pipeline.get_models_and_parameters()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loop over models and different training/test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With first train set (biggest one):\n",
      "Running LR...\n",
      "Running DT...\n",
      "Running LR...\n",
      "Running AB...\n",
      "Running RF...\n",
      "Running SVM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/felipe/.local/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>model</th>\n",
       "      <th>parameters</th>\n",
       "      <th>p_at_1</th>\n",
       "      <th>r_at_1</th>\n",
       "      <th>p_at_2</th>\n",
       "      <th>r_at_2</th>\n",
       "      <th>p_at_5</th>\n",
       "      <th>r_at_5</th>\n",
       "      <th>p_at_10</th>\n",
       "      <th>r_at_10</th>\n",
       "      <th>p_at_20</th>\n",
       "      <th>r_at_20</th>\n",
       "      <th>p_at_30</th>\n",
       "      <th>r_at_30</th>\n",
       "      <th>p_at_50</th>\n",
       "      <th>r_at_50</th>\n",
       "      <th>auc-roc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>{'C': 0.001, 'penalty': 'l1'}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013956</td>\n",
       "      <td>0.710079</td>\n",
       "      <td>0.019842</td>\n",
       "      <td>0.867301</td>\n",
       "      <td>0.060601</td>\n",
       "      <td>0.837220</td>\n",
       "      <td>0.117025</td>\n",
       "      <td>0.803396</td>\n",
       "      <td>0.224620</td>\n",
       "      <td>0.781467</td>\n",
       "      <td>0.327722</td>\n",
       "      <td>0.785313</td>\n",
       "      <td>0.548924</td>\n",
       "      <td>0.593102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>{'C': 0.001, 'penalty': 'l2'}</td>\n",
       "      <td>0.877551</td>\n",
       "      <td>0.012247</td>\n",
       "      <td>0.883352</td>\n",
       "      <td>0.024684</td>\n",
       "      <td>0.871830</td>\n",
       "      <td>0.060918</td>\n",
       "      <td>0.854426</td>\n",
       "      <td>0.119430</td>\n",
       "      <td>0.828862</td>\n",
       "      <td>0.231741</td>\n",
       "      <td>0.817386</td>\n",
       "      <td>0.342785</td>\n",
       "      <td>0.783412</td>\n",
       "      <td>0.547595</td>\n",
       "      <td>0.617331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'l1'}</td>\n",
       "      <td>0.825397</td>\n",
       "      <td>0.011519</td>\n",
       "      <td>0.828992</td>\n",
       "      <td>0.023165</td>\n",
       "      <td>0.850091</td>\n",
       "      <td>0.059399</td>\n",
       "      <td>0.843559</td>\n",
       "      <td>0.117911</td>\n",
       "      <td>0.827617</td>\n",
       "      <td>0.231392</td>\n",
       "      <td>0.817235</td>\n",
       "      <td>0.342722</td>\n",
       "      <td>0.787396</td>\n",
       "      <td>0.550380</td>\n",
       "      <td>0.619974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'l2'}</td>\n",
       "      <td>0.845805</td>\n",
       "      <td>0.011804</td>\n",
       "      <td>0.843715</td>\n",
       "      <td>0.023576</td>\n",
       "      <td>0.852808</td>\n",
       "      <td>0.059589</td>\n",
       "      <td>0.845370</td>\n",
       "      <td>0.118165</td>\n",
       "      <td>0.828976</td>\n",
       "      <td>0.231772</td>\n",
       "      <td>0.817235</td>\n",
       "      <td>0.342722</td>\n",
       "      <td>0.786490</td>\n",
       "      <td>0.549747</td>\n",
       "      <td>0.620281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>{'C': 1, 'penalty': 'l1'}</td>\n",
       "      <td>0.775510</td>\n",
       "      <td>0.010823</td>\n",
       "      <td>0.795017</td>\n",
       "      <td>0.022215</td>\n",
       "      <td>0.843297</td>\n",
       "      <td>0.058924</td>\n",
       "      <td>0.844238</td>\n",
       "      <td>0.118006</td>\n",
       "      <td>0.828297</td>\n",
       "      <td>0.231582</td>\n",
       "      <td>0.817009</td>\n",
       "      <td>0.342627</td>\n",
       "      <td>0.786445</td>\n",
       "      <td>0.549715</td>\n",
       "      <td>0.619894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>{'C': 1, 'penalty': 'l2'}</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.010854</td>\n",
       "      <td>0.800680</td>\n",
       "      <td>0.022373</td>\n",
       "      <td>0.843750</td>\n",
       "      <td>0.058956</td>\n",
       "      <td>0.844238</td>\n",
       "      <td>0.118006</td>\n",
       "      <td>0.827391</td>\n",
       "      <td>0.231329</td>\n",
       "      <td>0.816707</td>\n",
       "      <td>0.342500</td>\n",
       "      <td>0.786671</td>\n",
       "      <td>0.549873</td>\n",
       "      <td>0.619810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>{'C': 10, 'penalty': 'l1'}</td>\n",
       "      <td>0.773243</td>\n",
       "      <td>0.010791</td>\n",
       "      <td>0.793884</td>\n",
       "      <td>0.022184</td>\n",
       "      <td>0.844203</td>\n",
       "      <td>0.058987</td>\n",
       "      <td>0.844917</td>\n",
       "      <td>0.118101</td>\n",
       "      <td>0.827504</td>\n",
       "      <td>0.231361</td>\n",
       "      <td>0.816556</td>\n",
       "      <td>0.342437</td>\n",
       "      <td>0.786671</td>\n",
       "      <td>0.549873</td>\n",
       "      <td>0.619781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>{'C': 10, 'penalty': 'l2'}</td>\n",
       "      <td>0.770975</td>\n",
       "      <td>0.010759</td>\n",
       "      <td>0.793884</td>\n",
       "      <td>0.022184</td>\n",
       "      <td>0.844203</td>\n",
       "      <td>0.058987</td>\n",
       "      <td>0.844917</td>\n",
       "      <td>0.118101</td>\n",
       "      <td>0.827617</td>\n",
       "      <td>0.231392</td>\n",
       "      <td>0.816556</td>\n",
       "      <td>0.342437</td>\n",
       "      <td>0.786762</td>\n",
       "      <td>0.549937</td>\n",
       "      <td>0.619771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 1, 'min_sam...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013956</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.027943</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.069873</td>\n",
       "      <td>0.744623</td>\n",
       "      <td>0.104082</td>\n",
       "      <td>0.672213</td>\n",
       "      <td>0.187943</td>\n",
       "      <td>0.781467</td>\n",
       "      <td>0.327722</td>\n",
       "      <td>0.868843</td>\n",
       "      <td>0.607310</td>\n",
       "      <td>0.547044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 1, 'min_sam...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013956</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.027943</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.069873</td>\n",
       "      <td>0.744623</td>\n",
       "      <td>0.104082</td>\n",
       "      <td>0.672213</td>\n",
       "      <td>0.187943</td>\n",
       "      <td>0.781467</td>\n",
       "      <td>0.327722</td>\n",
       "      <td>0.868843</td>\n",
       "      <td>0.607310</td>\n",
       "      <td>0.547044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'min_sam...</td>\n",
       "      <td>0.775510</td>\n",
       "      <td>0.010823</td>\n",
       "      <td>0.705549</td>\n",
       "      <td>0.019715</td>\n",
       "      <td>0.788496</td>\n",
       "      <td>0.055095</td>\n",
       "      <td>0.749830</td>\n",
       "      <td>0.104810</td>\n",
       "      <td>0.805999</td>\n",
       "      <td>0.225348</td>\n",
       "      <td>0.780486</td>\n",
       "      <td>0.327310</td>\n",
       "      <td>0.784227</td>\n",
       "      <td>0.548165</td>\n",
       "      <td>0.609405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'min_sam...</td>\n",
       "      <td>0.775510</td>\n",
       "      <td>0.010823</td>\n",
       "      <td>0.705549</td>\n",
       "      <td>0.019715</td>\n",
       "      <td>0.788496</td>\n",
       "      <td>0.055095</td>\n",
       "      <td>0.749830</td>\n",
       "      <td>0.104810</td>\n",
       "      <td>0.805999</td>\n",
       "      <td>0.225348</td>\n",
       "      <td>0.780486</td>\n",
       "      <td>0.327310</td>\n",
       "      <td>0.784227</td>\n",
       "      <td>0.548165</td>\n",
       "      <td>0.609405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 10, 'min_sa...</td>\n",
       "      <td>0.512472</td>\n",
       "      <td>0.007152</td>\n",
       "      <td>0.749717</td>\n",
       "      <td>0.020949</td>\n",
       "      <td>0.802989</td>\n",
       "      <td>0.056108</td>\n",
       "      <td>0.803939</td>\n",
       "      <td>0.112373</td>\n",
       "      <td>0.804188</td>\n",
       "      <td>0.224842</td>\n",
       "      <td>0.801011</td>\n",
       "      <td>0.335918</td>\n",
       "      <td>0.781375</td>\n",
       "      <td>0.546171</td>\n",
       "      <td>0.603402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 10, 'min_sa...</td>\n",
       "      <td>0.530612</td>\n",
       "      <td>0.007405</td>\n",
       "      <td>0.747452</td>\n",
       "      <td>0.020886</td>\n",
       "      <td>0.803895</td>\n",
       "      <td>0.056171</td>\n",
       "      <td>0.800091</td>\n",
       "      <td>0.111835</td>\n",
       "      <td>0.804188</td>\n",
       "      <td>0.224842</td>\n",
       "      <td>0.800936</td>\n",
       "      <td>0.335886</td>\n",
       "      <td>0.781239</td>\n",
       "      <td>0.546076</td>\n",
       "      <td>0.603347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 50, 'min_sa...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013956</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.027943</td>\n",
       "      <td>0.993207</td>\n",
       "      <td>0.069399</td>\n",
       "      <td>0.996378</td>\n",
       "      <td>0.139272</td>\n",
       "      <td>0.528919</td>\n",
       "      <td>0.147880</td>\n",
       "      <td>0.644959</td>\n",
       "      <td>0.270475</td>\n",
       "      <td>0.756836</td>\n",
       "      <td>0.529019</td>\n",
       "      <td>0.553882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 50, 'min_sa...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013956</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.027943</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.069873</td>\n",
       "      <td>0.970342</td>\n",
       "      <td>0.135633</td>\n",
       "      <td>0.518846</td>\n",
       "      <td>0.145063</td>\n",
       "      <td>0.679218</td>\n",
       "      <td>0.284842</td>\n",
       "      <td>0.755433</td>\n",
       "      <td>0.528038</td>\n",
       "      <td>0.556310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 100, 'min_s...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013956</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.027943</td>\n",
       "      <td>0.967844</td>\n",
       "      <td>0.067627</td>\n",
       "      <td>0.983926</td>\n",
       "      <td>0.137532</td>\n",
       "      <td>0.555178</td>\n",
       "      <td>0.155222</td>\n",
       "      <td>0.619076</td>\n",
       "      <td>0.259620</td>\n",
       "      <td>0.753577</td>\n",
       "      <td>0.526741</td>\n",
       "      <td>0.550751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 100, 'min_s...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013956</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.027943</td>\n",
       "      <td>0.987319</td>\n",
       "      <td>0.068987</td>\n",
       "      <td>0.993661</td>\n",
       "      <td>0.138892</td>\n",
       "      <td>0.509338</td>\n",
       "      <td>0.142405</td>\n",
       "      <td>0.656127</td>\n",
       "      <td>0.275158</td>\n",
       "      <td>0.753079</td>\n",
       "      <td>0.526392</td>\n",
       "      <td>0.552637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 1, 'min_...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013956</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.027943</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.069873</td>\n",
       "      <td>0.744623</td>\n",
       "      <td>0.104082</td>\n",
       "      <td>0.672213</td>\n",
       "      <td>0.187943</td>\n",
       "      <td>0.781467</td>\n",
       "      <td>0.327722</td>\n",
       "      <td>0.868843</td>\n",
       "      <td>0.607310</td>\n",
       "      <td>0.547044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 1, 'min_...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013956</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.027943</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.069873</td>\n",
       "      <td>0.744623</td>\n",
       "      <td>0.104082</td>\n",
       "      <td>0.672213</td>\n",
       "      <td>0.187943</td>\n",
       "      <td>0.781467</td>\n",
       "      <td>0.327722</td>\n",
       "      <td>0.868843</td>\n",
       "      <td>0.607310</td>\n",
       "      <td>0.547044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'min_...</td>\n",
       "      <td>0.773243</td>\n",
       "      <td>0.010791</td>\n",
       "      <td>0.795017</td>\n",
       "      <td>0.022215</td>\n",
       "      <td>0.810236</td>\n",
       "      <td>0.056614</td>\n",
       "      <td>0.760697</td>\n",
       "      <td>0.106329</td>\n",
       "      <td>0.821279</td>\n",
       "      <td>0.229620</td>\n",
       "      <td>0.776411</td>\n",
       "      <td>0.325601</td>\n",
       "      <td>0.780695</td>\n",
       "      <td>0.545696</td>\n",
       "      <td>0.608205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'min_...</td>\n",
       "      <td>0.775510</td>\n",
       "      <td>0.010823</td>\n",
       "      <td>0.796149</td>\n",
       "      <td>0.022247</td>\n",
       "      <td>0.810688</td>\n",
       "      <td>0.056646</td>\n",
       "      <td>0.760924</td>\n",
       "      <td>0.106361</td>\n",
       "      <td>0.821166</td>\n",
       "      <td>0.229589</td>\n",
       "      <td>0.776487</td>\n",
       "      <td>0.325633</td>\n",
       "      <td>0.780741</td>\n",
       "      <td>0.545728</td>\n",
       "      <td>0.608252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 10, 'min...</td>\n",
       "      <td>0.646259</td>\n",
       "      <td>0.009019</td>\n",
       "      <td>0.730464</td>\n",
       "      <td>0.020411</td>\n",
       "      <td>0.795743</td>\n",
       "      <td>0.055601</td>\n",
       "      <td>0.827258</td>\n",
       "      <td>0.115633</td>\n",
       "      <td>0.818789</td>\n",
       "      <td>0.228924</td>\n",
       "      <td>0.801087</td>\n",
       "      <td>0.335949</td>\n",
       "      <td>0.786264</td>\n",
       "      <td>0.549589</td>\n",
       "      <td>0.608688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 10, 'min...</td>\n",
       "      <td>0.637188</td>\n",
       "      <td>0.008892</td>\n",
       "      <td>0.727067</td>\n",
       "      <td>0.020316</td>\n",
       "      <td>0.794384</td>\n",
       "      <td>0.055506</td>\n",
       "      <td>0.826806</td>\n",
       "      <td>0.115570</td>\n",
       "      <td>0.818789</td>\n",
       "      <td>0.228924</td>\n",
       "      <td>0.800634</td>\n",
       "      <td>0.335759</td>\n",
       "      <td>0.786309</td>\n",
       "      <td>0.549620</td>\n",
       "      <td>0.608738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 50, 'min...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013956</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.027943</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.069873</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.139778</td>\n",
       "      <td>0.517148</td>\n",
       "      <td>0.144589</td>\n",
       "      <td>0.655901</td>\n",
       "      <td>0.275063</td>\n",
       "      <td>0.754573</td>\n",
       "      <td>0.527437</td>\n",
       "      <td>0.554204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 50, 'min...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013956</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.027943</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.069873</td>\n",
       "      <td>0.953362</td>\n",
       "      <td>0.133259</td>\n",
       "      <td>0.531409</td>\n",
       "      <td>0.148576</td>\n",
       "      <td>0.687594</td>\n",
       "      <td>0.288354</td>\n",
       "      <td>0.763944</td>\n",
       "      <td>0.533987</td>\n",
       "      <td>0.557241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 100, 'mi...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013956</td>\n",
       "      <td>0.998867</td>\n",
       "      <td>0.027911</td>\n",
       "      <td>0.971014</td>\n",
       "      <td>0.067848</td>\n",
       "      <td>0.985511</td>\n",
       "      <td>0.137753</td>\n",
       "      <td>0.549179</td>\n",
       "      <td>0.153544</td>\n",
       "      <td>0.624208</td>\n",
       "      <td>0.261772</td>\n",
       "      <td>0.751630</td>\n",
       "      <td>0.525380</td>\n",
       "      <td>0.550796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 100, 'mi...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013956</td>\n",
       "      <td>0.998867</td>\n",
       "      <td>0.027911</td>\n",
       "      <td>0.992754</td>\n",
       "      <td>0.069367</td>\n",
       "      <td>0.996378</td>\n",
       "      <td>0.139272</td>\n",
       "      <td>0.508432</td>\n",
       "      <td>0.142152</td>\n",
       "      <td>0.658618</td>\n",
       "      <td>0.276203</td>\n",
       "      <td>0.753984</td>\n",
       "      <td>0.527025</td>\n",
       "      <td>0.552605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>{'C': 0.001, 'penalty': 'l1'}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013956</td>\n",
       "      <td>0.710079</td>\n",
       "      <td>0.019842</td>\n",
       "      <td>0.867301</td>\n",
       "      <td>0.060601</td>\n",
       "      <td>0.837220</td>\n",
       "      <td>0.117025</td>\n",
       "      <td>0.799095</td>\n",
       "      <td>0.223418</td>\n",
       "      <td>0.781467</td>\n",
       "      <td>0.327722</td>\n",
       "      <td>0.785313</td>\n",
       "      <td>0.548924</td>\n",
       "      <td>0.590088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>{'C': 0.001, 'penalty': 'l2'}</td>\n",
       "      <td>0.877551</td>\n",
       "      <td>0.012247</td>\n",
       "      <td>0.883352</td>\n",
       "      <td>0.024684</td>\n",
       "      <td>0.871830</td>\n",
       "      <td>0.060918</td>\n",
       "      <td>0.854426</td>\n",
       "      <td>0.119430</td>\n",
       "      <td>0.828862</td>\n",
       "      <td>0.231741</td>\n",
       "      <td>0.817386</td>\n",
       "      <td>0.342785</td>\n",
       "      <td>0.783412</td>\n",
       "      <td>0.547595</td>\n",
       "      <td>0.617331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>{'C': 1, 'penalty': 'l2'}</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.010854</td>\n",
       "      <td>0.800680</td>\n",
       "      <td>0.022373</td>\n",
       "      <td>0.843750</td>\n",
       "      <td>0.058956</td>\n",
       "      <td>0.844238</td>\n",
       "      <td>0.118006</td>\n",
       "      <td>0.827391</td>\n",
       "      <td>0.231329</td>\n",
       "      <td>0.816707</td>\n",
       "      <td>0.342500</td>\n",
       "      <td>0.786671</td>\n",
       "      <td>0.549873</td>\n",
       "      <td>0.619810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>{'C': 10, 'penalty': 'l1'}</td>\n",
       "      <td>0.773243</td>\n",
       "      <td>0.010791</td>\n",
       "      <td>0.793884</td>\n",
       "      <td>0.022184</td>\n",
       "      <td>0.844656</td>\n",
       "      <td>0.059019</td>\n",
       "      <td>0.844917</td>\n",
       "      <td>0.118101</td>\n",
       "      <td>0.827278</td>\n",
       "      <td>0.231297</td>\n",
       "      <td>0.816556</td>\n",
       "      <td>0.342437</td>\n",
       "      <td>0.786853</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.619792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>{'C': 10, 'penalty': 'l2'}</td>\n",
       "      <td>0.770975</td>\n",
       "      <td>0.010759</td>\n",
       "      <td>0.793884</td>\n",
       "      <td>0.022184</td>\n",
       "      <td>0.844203</td>\n",
       "      <td>0.058987</td>\n",
       "      <td>0.844917</td>\n",
       "      <td>0.118101</td>\n",
       "      <td>0.827617</td>\n",
       "      <td>0.231392</td>\n",
       "      <td>0.816556</td>\n",
       "      <td>0.342437</td>\n",
       "      <td>0.786762</td>\n",
       "      <td>0.549937</td>\n",
       "      <td>0.619771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>AB</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'algorithm': 'SAMME', 'n_estimators': 1}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013956</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.027943</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.069873</td>\n",
       "      <td>0.744623</td>\n",
       "      <td>0.104082</td>\n",
       "      <td>0.672213</td>\n",
       "      <td>0.187943</td>\n",
       "      <td>0.781467</td>\n",
       "      <td>0.327722</td>\n",
       "      <td>0.868843</td>\n",
       "      <td>0.607310</td>\n",
       "      <td>0.547044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>AB</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'algorithm': 'SAMME', 'n_estimators': 10}</td>\n",
       "      <td>0.836735</td>\n",
       "      <td>0.011677</td>\n",
       "      <td>0.898075</td>\n",
       "      <td>0.025095</td>\n",
       "      <td>0.902174</td>\n",
       "      <td>0.063038</td>\n",
       "      <td>0.823862</td>\n",
       "      <td>0.115158</td>\n",
       "      <td>0.822524</td>\n",
       "      <td>0.229968</td>\n",
       "      <td>0.779882</td>\n",
       "      <td>0.327057</td>\n",
       "      <td>0.783140</td>\n",
       "      <td>0.547405</td>\n",
       "      <td>0.601875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>AB</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'algorithm': 'SAMME', 'n_estimators': 100}</td>\n",
       "      <td>0.739229</td>\n",
       "      <td>0.010316</td>\n",
       "      <td>0.781427</td>\n",
       "      <td>0.021835</td>\n",
       "      <td>0.838315</td>\n",
       "      <td>0.058576</td>\n",
       "      <td>0.830428</td>\n",
       "      <td>0.116076</td>\n",
       "      <td>0.819581</td>\n",
       "      <td>0.229146</td>\n",
       "      <td>0.774374</td>\n",
       "      <td>0.324747</td>\n",
       "      <td>0.782280</td>\n",
       "      <td>0.546804</td>\n",
       "      <td>0.602678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>AB</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'algorithm': 'SAMME.R', 'n_estimators': 1}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013956</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.027943</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.069873</td>\n",
       "      <td>0.744623</td>\n",
       "      <td>0.104082</td>\n",
       "      <td>0.672213</td>\n",
       "      <td>0.187943</td>\n",
       "      <td>0.781467</td>\n",
       "      <td>0.327722</td>\n",
       "      <td>0.868843</td>\n",
       "      <td>0.607310</td>\n",
       "      <td>0.547044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>AB</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'algorithm': 'SAMME.R', 'n_estimators': 10}</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.010633</td>\n",
       "      <td>0.784824</td>\n",
       "      <td>0.021930</td>\n",
       "      <td>0.821105</td>\n",
       "      <td>0.057373</td>\n",
       "      <td>0.815033</td>\n",
       "      <td>0.113924</td>\n",
       "      <td>0.820147</td>\n",
       "      <td>0.229304</td>\n",
       "      <td>0.809010</td>\n",
       "      <td>0.339272</td>\n",
       "      <td>0.802562</td>\n",
       "      <td>0.560981</td>\n",
       "      <td>0.610830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>AB</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'algorithm': 'SAMME.R', 'n_estimators': 100}</td>\n",
       "      <td>0.775510</td>\n",
       "      <td>0.010823</td>\n",
       "      <td>0.790487</td>\n",
       "      <td>0.022089</td>\n",
       "      <td>0.843750</td>\n",
       "      <td>0.058956</td>\n",
       "      <td>0.845144</td>\n",
       "      <td>0.118133</td>\n",
       "      <td>0.827165</td>\n",
       "      <td>0.231266</td>\n",
       "      <td>0.817160</td>\n",
       "      <td>0.342690</td>\n",
       "      <td>0.786807</td>\n",
       "      <td>0.549968</td>\n",
       "      <td>0.619644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 'sqrt', 'min_...</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.011962</td>\n",
       "      <td>0.862967</td>\n",
       "      <td>0.024114</td>\n",
       "      <td>0.857790</td>\n",
       "      <td>0.059937</td>\n",
       "      <td>0.844691</td>\n",
       "      <td>0.118070</td>\n",
       "      <td>0.826712</td>\n",
       "      <td>0.231139</td>\n",
       "      <td>0.795804</td>\n",
       "      <td>0.333734</td>\n",
       "      <td>0.775715</td>\n",
       "      <td>0.542215</td>\n",
       "      <td>0.606076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 'sqrt', 'min_...</td>\n",
       "      <td>0.902494</td>\n",
       "      <td>0.012595</td>\n",
       "      <td>0.876557</td>\n",
       "      <td>0.024494</td>\n",
       "      <td>0.874547</td>\n",
       "      <td>0.061108</td>\n",
       "      <td>0.856237</td>\n",
       "      <td>0.119684</td>\n",
       "      <td>0.826712</td>\n",
       "      <td>0.231139</td>\n",
       "      <td>0.814066</td>\n",
       "      <td>0.341392</td>\n",
       "      <td>0.780650</td>\n",
       "      <td>0.545665</td>\n",
       "      <td>0.616676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 'sqrt', 'min_...</td>\n",
       "      <td>0.877551</td>\n",
       "      <td>0.012247</td>\n",
       "      <td>0.866365</td>\n",
       "      <td>0.024209</td>\n",
       "      <td>0.855525</td>\n",
       "      <td>0.059778</td>\n",
       "      <td>0.844012</td>\n",
       "      <td>0.117975</td>\n",
       "      <td>0.819468</td>\n",
       "      <td>0.229114</td>\n",
       "      <td>0.792409</td>\n",
       "      <td>0.332310</td>\n",
       "      <td>0.772365</td>\n",
       "      <td>0.539873</td>\n",
       "      <td>0.603239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 'sqrt', 'min_...</td>\n",
       "      <td>0.895692</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>0.875425</td>\n",
       "      <td>0.024462</td>\n",
       "      <td>0.873641</td>\n",
       "      <td>0.061044</td>\n",
       "      <td>0.855558</td>\n",
       "      <td>0.119589</td>\n",
       "      <td>0.826486</td>\n",
       "      <td>0.231076</td>\n",
       "      <td>0.811877</td>\n",
       "      <td>0.340475</td>\n",
       "      <td>0.780560</td>\n",
       "      <td>0.545601</td>\n",
       "      <td>0.615912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 'log2', 'min_...</td>\n",
       "      <td>0.868481</td>\n",
       "      <td>0.012120</td>\n",
       "      <td>0.859570</td>\n",
       "      <td>0.024019</td>\n",
       "      <td>0.846467</td>\n",
       "      <td>0.059146</td>\n",
       "      <td>0.846955</td>\n",
       "      <td>0.118386</td>\n",
       "      <td>0.826938</td>\n",
       "      <td>0.231203</td>\n",
       "      <td>0.812708</td>\n",
       "      <td>0.340823</td>\n",
       "      <td>0.781963</td>\n",
       "      <td>0.546582</td>\n",
       "      <td>0.614701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 'log2', 'min_...</td>\n",
       "      <td>0.886621</td>\n",
       "      <td>0.012373</td>\n",
       "      <td>0.877690</td>\n",
       "      <td>0.024525</td>\n",
       "      <td>0.876359</td>\n",
       "      <td>0.061234</td>\n",
       "      <td>0.855105</td>\n",
       "      <td>0.119525</td>\n",
       "      <td>0.831239</td>\n",
       "      <td>0.232405</td>\n",
       "      <td>0.816254</td>\n",
       "      <td>0.342310</td>\n",
       "      <td>0.783910</td>\n",
       "      <td>0.547943</td>\n",
       "      <td>0.618690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 'log2', 'min_...</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.012405</td>\n",
       "      <td>0.859570</td>\n",
       "      <td>0.024019</td>\n",
       "      <td>0.855525</td>\n",
       "      <td>0.059778</td>\n",
       "      <td>0.847861</td>\n",
       "      <td>0.118513</td>\n",
       "      <td>0.827504</td>\n",
       "      <td>0.231361</td>\n",
       "      <td>0.815952</td>\n",
       "      <td>0.342184</td>\n",
       "      <td>0.784634</td>\n",
       "      <td>0.548449</td>\n",
       "      <td>0.616462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 'log2', 'min_...</td>\n",
       "      <td>0.886621</td>\n",
       "      <td>0.012373</td>\n",
       "      <td>0.882220</td>\n",
       "      <td>0.024652</td>\n",
       "      <td>0.876359</td>\n",
       "      <td>0.061234</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.119810</td>\n",
       "      <td>0.831579</td>\n",
       "      <td>0.232500</td>\n",
       "      <td>0.816933</td>\n",
       "      <td>0.342595</td>\n",
       "      <td>0.784996</td>\n",
       "      <td>0.548703</td>\n",
       "      <td>0.619532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 50, 'max_features': 'sqrt', 'min...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013956</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.027943</td>\n",
       "      <td>0.639493</td>\n",
       "      <td>0.044684</td>\n",
       "      <td>0.808467</td>\n",
       "      <td>0.113006</td>\n",
       "      <td>0.794001</td>\n",
       "      <td>0.221994</td>\n",
       "      <td>0.780486</td>\n",
       "      <td>0.327310</td>\n",
       "      <td>0.762586</td>\n",
       "      <td>0.533038</td>\n",
       "      <td>0.577122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 50, 'max_features': 'sqrt', 'min...</td>\n",
       "      <td>0.841270</td>\n",
       "      <td>0.011741</td>\n",
       "      <td>0.847112</td>\n",
       "      <td>0.023671</td>\n",
       "      <td>0.850543</td>\n",
       "      <td>0.059430</td>\n",
       "      <td>0.816844</td>\n",
       "      <td>0.114177</td>\n",
       "      <td>0.790492</td>\n",
       "      <td>0.221013</td>\n",
       "      <td>0.781920</td>\n",
       "      <td>0.327911</td>\n",
       "      <td>0.766570</td>\n",
       "      <td>0.535823</td>\n",
       "      <td>0.583090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 50, 'max_features': 'sqrt', 'min...</td>\n",
       "      <td>0.850340</td>\n",
       "      <td>0.011867</td>\n",
       "      <td>0.845980</td>\n",
       "      <td>0.023639</td>\n",
       "      <td>0.850091</td>\n",
       "      <td>0.059399</td>\n",
       "      <td>0.829975</td>\n",
       "      <td>0.116013</td>\n",
       "      <td>0.805433</td>\n",
       "      <td>0.225190</td>\n",
       "      <td>0.793390</td>\n",
       "      <td>0.332722</td>\n",
       "      <td>0.768607</td>\n",
       "      <td>0.537247</td>\n",
       "      <td>0.589409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 50, 'max_features': 'sqrt', 'min...</td>\n",
       "      <td>0.879819</td>\n",
       "      <td>0.012278</td>\n",
       "      <td>0.879955</td>\n",
       "      <td>0.024589</td>\n",
       "      <td>0.859149</td>\n",
       "      <td>0.060032</td>\n",
       "      <td>0.839937</td>\n",
       "      <td>0.117405</td>\n",
       "      <td>0.819015</td>\n",
       "      <td>0.228987</td>\n",
       "      <td>0.800634</td>\n",
       "      <td>0.335759</td>\n",
       "      <td>0.773044</td>\n",
       "      <td>0.540348</td>\n",
       "      <td>0.601300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 50, 'max_features': 'log2', 'min...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013956</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.027943</td>\n",
       "      <td>0.657609</td>\n",
       "      <td>0.045949</td>\n",
       "      <td>0.802355</td>\n",
       "      <td>0.112152</td>\n",
       "      <td>0.793775</td>\n",
       "      <td>0.221930</td>\n",
       "      <td>0.774374</td>\n",
       "      <td>0.324747</td>\n",
       "      <td>0.758783</td>\n",
       "      <td>0.530380</td>\n",
       "      <td>0.572474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 50, 'max_features': 'log2', 'min...</td>\n",
       "      <td>0.829932</td>\n",
       "      <td>0.011582</td>\n",
       "      <td>0.830125</td>\n",
       "      <td>0.023196</td>\n",
       "      <td>0.837409</td>\n",
       "      <td>0.058513</td>\n",
       "      <td>0.817976</td>\n",
       "      <td>0.114335</td>\n",
       "      <td>0.790606</td>\n",
       "      <td>0.221044</td>\n",
       "      <td>0.784410</td>\n",
       "      <td>0.328956</td>\n",
       "      <td>0.763627</td>\n",
       "      <td>0.533766</td>\n",
       "      <td>0.582335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 50, 'max_features': 'log2', 'min...</td>\n",
       "      <td>0.861678</td>\n",
       "      <td>0.012025</td>\n",
       "      <td>0.860702</td>\n",
       "      <td>0.024051</td>\n",
       "      <td>0.848279</td>\n",
       "      <td>0.059272</td>\n",
       "      <td>0.831560</td>\n",
       "      <td>0.116234</td>\n",
       "      <td>0.810300</td>\n",
       "      <td>0.226551</td>\n",
       "      <td>0.796106</td>\n",
       "      <td>0.333861</td>\n",
       "      <td>0.773814</td>\n",
       "      <td>0.540886</td>\n",
       "      <td>0.596438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 50, 'max_features': 'log2', 'min...</td>\n",
       "      <td>0.882086</td>\n",
       "      <td>0.012310</td>\n",
       "      <td>0.876557</td>\n",
       "      <td>0.024494</td>\n",
       "      <td>0.866848</td>\n",
       "      <td>0.060570</td>\n",
       "      <td>0.843333</td>\n",
       "      <td>0.117880</td>\n",
       "      <td>0.823090</td>\n",
       "      <td>0.230127</td>\n",
       "      <td>0.802294</td>\n",
       "      <td>0.336456</td>\n",
       "      <td>0.777390</td>\n",
       "      <td>0.543386</td>\n",
       "      <td>0.604583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>SVM</td>\n",
       "      <td>LinearSVC(C=10, class_weight=None, dual=True, ...</td>\n",
       "      <td>{'C': 0.001}</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.012405</td>\n",
       "      <td>0.899207</td>\n",
       "      <td>0.025127</td>\n",
       "      <td>0.876359</td>\n",
       "      <td>0.061234</td>\n",
       "      <td>0.858275</td>\n",
       "      <td>0.119968</td>\n",
       "      <td>0.833164</td>\n",
       "      <td>0.232943</td>\n",
       "      <td>0.819423</td>\n",
       "      <td>0.343639</td>\n",
       "      <td>0.788482</td>\n",
       "      <td>0.551139</td>\n",
       "      <td>0.622892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>SVM</td>\n",
       "      <td>LinearSVC(C=10, class_weight=None, dual=True, ...</td>\n",
       "      <td>{'C': 0.01}</td>\n",
       "      <td>0.868481</td>\n",
       "      <td>0.012120</td>\n",
       "      <td>0.867497</td>\n",
       "      <td>0.024241</td>\n",
       "      <td>0.865036</td>\n",
       "      <td>0.060443</td>\n",
       "      <td>0.851030</td>\n",
       "      <td>0.118956</td>\n",
       "      <td>0.828636</td>\n",
       "      <td>0.231677</td>\n",
       "      <td>0.817839</td>\n",
       "      <td>0.342975</td>\n",
       "      <td>0.787984</td>\n",
       "      <td>0.550791</td>\n",
       "      <td>0.621633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>SVM</td>\n",
       "      <td>LinearSVC(C=10, class_weight=None, dual=True, ...</td>\n",
       "      <td>{'C': 0.1}</td>\n",
       "      <td>0.848073</td>\n",
       "      <td>0.011835</td>\n",
       "      <td>0.857305</td>\n",
       "      <td>0.023956</td>\n",
       "      <td>0.853714</td>\n",
       "      <td>0.059652</td>\n",
       "      <td>0.846729</td>\n",
       "      <td>0.118354</td>\n",
       "      <td>0.827278</td>\n",
       "      <td>0.231297</td>\n",
       "      <td>0.817084</td>\n",
       "      <td>0.342658</td>\n",
       "      <td>0.788030</td>\n",
       "      <td>0.550823</td>\n",
       "      <td>0.621200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>SVM</td>\n",
       "      <td>LinearSVC(C=10, class_weight=None, dual=True, ...</td>\n",
       "      <td>{'C': 1}</td>\n",
       "      <td>0.850340</td>\n",
       "      <td>0.011867</td>\n",
       "      <td>0.850510</td>\n",
       "      <td>0.023766</td>\n",
       "      <td>0.854620</td>\n",
       "      <td>0.059715</td>\n",
       "      <td>0.846729</td>\n",
       "      <td>0.118354</td>\n",
       "      <td>0.826825</td>\n",
       "      <td>0.231171</td>\n",
       "      <td>0.816933</td>\n",
       "      <td>0.342595</td>\n",
       "      <td>0.788211</td>\n",
       "      <td>0.550949</td>\n",
       "      <td>0.621155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>SVM</td>\n",
       "      <td>LinearSVC(C=10, class_weight=None, dual=True, ...</td>\n",
       "      <td>{'C': 10}</td>\n",
       "      <td>0.841270</td>\n",
       "      <td>0.011741</td>\n",
       "      <td>0.843715</td>\n",
       "      <td>0.023576</td>\n",
       "      <td>0.857337</td>\n",
       "      <td>0.059905</td>\n",
       "      <td>0.845370</td>\n",
       "      <td>0.118165</td>\n",
       "      <td>0.827051</td>\n",
       "      <td>0.231234</td>\n",
       "      <td>0.817537</td>\n",
       "      <td>0.342848</td>\n",
       "      <td>0.788120</td>\n",
       "      <td>0.550886</td>\n",
       "      <td>0.620483</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63 rows  18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   model_name                                              model  \\\n",
       "0          LR  LogisticRegression(C=10, class_weight=None, du...   \n",
       "1          LR  LogisticRegression(C=10, class_weight=None, du...   \n",
       "2          LR  LogisticRegression(C=10, class_weight=None, du...   \n",
       "3          LR  LogisticRegression(C=10, class_weight=None, du...   \n",
       "4          LR  LogisticRegression(C=10, class_weight=None, du...   \n",
       "5          LR  LogisticRegression(C=10, class_weight=None, du...   \n",
       "6          LR  LogisticRegression(C=10, class_weight=None, du...   \n",
       "7          LR  LogisticRegression(C=10, class_weight=None, du...   \n",
       "8          DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "9          DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "10         DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "11         DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "12         DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "13         DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "14         DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "15         DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "16         DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "17         DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "18         DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "19         DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "20         DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "21         DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "22         DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "23         DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "24         DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "25         DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "26         DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "27         DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "28         LR  LogisticRegression(C=10, class_weight=None, du...   \n",
       "29         LR  LogisticRegression(C=10, class_weight=None, du...   \n",
       "..        ...                                                ...   \n",
       "33         LR  LogisticRegression(C=10, class_weight=None, du...   \n",
       "34         LR  LogisticRegression(C=10, class_weight=None, du...   \n",
       "35         LR  LogisticRegression(C=10, class_weight=None, du...   \n",
       "36         AB  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "37         AB  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "38         AB  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "39         AB  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "40         AB  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "41         AB  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "42         RF  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "43         RF  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "44         RF  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "45         RF  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "46         RF  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "47         RF  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "48         RF  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "49         RF  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "50         RF  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "51         RF  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "52         RF  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "53         RF  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "54         RF  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "55         RF  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "56         RF  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "57         RF  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "58        SVM  LinearSVC(C=10, class_weight=None, dual=True, ...   \n",
       "59        SVM  LinearSVC(C=10, class_weight=None, dual=True, ...   \n",
       "60        SVM  LinearSVC(C=10, class_weight=None, dual=True, ...   \n",
       "61        SVM  LinearSVC(C=10, class_weight=None, dual=True, ...   \n",
       "62        SVM  LinearSVC(C=10, class_weight=None, dual=True, ...   \n",
       "\n",
       "                                           parameters    p_at_1    r_at_1  \\\n",
       "0                       {'C': 0.001, 'penalty': 'l1'}  1.000000  0.013956   \n",
       "1                       {'C': 0.001, 'penalty': 'l2'}  0.877551  0.012247   \n",
       "2                         {'C': 0.1, 'penalty': 'l1'}  0.825397  0.011519   \n",
       "3                         {'C': 0.1, 'penalty': 'l2'}  0.845805  0.011804   \n",
       "4                           {'C': 1, 'penalty': 'l1'}  0.775510  0.010823   \n",
       "5                           {'C': 1, 'penalty': 'l2'}  0.777778  0.010854   \n",
       "6                          {'C': 10, 'penalty': 'l1'}  0.773243  0.010791   \n",
       "7                          {'C': 10, 'penalty': 'l2'}  0.770975  0.010759   \n",
       "8   {'criterion': 'gini', 'max_depth': 1, 'min_sam...  1.000000  0.013956   \n",
       "9   {'criterion': 'gini', 'max_depth': 1, 'min_sam...  1.000000  0.013956   \n",
       "10  {'criterion': 'gini', 'max_depth': 5, 'min_sam...  0.775510  0.010823   \n",
       "11  {'criterion': 'gini', 'max_depth': 5, 'min_sam...  0.775510  0.010823   \n",
       "12  {'criterion': 'gini', 'max_depth': 10, 'min_sa...  0.512472  0.007152   \n",
       "13  {'criterion': 'gini', 'max_depth': 10, 'min_sa...  0.530612  0.007405   \n",
       "14  {'criterion': 'gini', 'max_depth': 50, 'min_sa...  1.000000  0.013956   \n",
       "15  {'criterion': 'gini', 'max_depth': 50, 'min_sa...  1.000000  0.013956   \n",
       "16  {'criterion': 'gini', 'max_depth': 100, 'min_s...  1.000000  0.013956   \n",
       "17  {'criterion': 'gini', 'max_depth': 100, 'min_s...  1.000000  0.013956   \n",
       "18  {'criterion': 'entropy', 'max_depth': 1, 'min_...  1.000000  0.013956   \n",
       "19  {'criterion': 'entropy', 'max_depth': 1, 'min_...  1.000000  0.013956   \n",
       "20  {'criterion': 'entropy', 'max_depth': 5, 'min_...  0.773243  0.010791   \n",
       "21  {'criterion': 'entropy', 'max_depth': 5, 'min_...  0.775510  0.010823   \n",
       "22  {'criterion': 'entropy', 'max_depth': 10, 'min...  0.646259  0.009019   \n",
       "23  {'criterion': 'entropy', 'max_depth': 10, 'min...  0.637188  0.008892   \n",
       "24  {'criterion': 'entropy', 'max_depth': 50, 'min...  1.000000  0.013956   \n",
       "25  {'criterion': 'entropy', 'max_depth': 50, 'min...  1.000000  0.013956   \n",
       "26  {'criterion': 'entropy', 'max_depth': 100, 'mi...  1.000000  0.013956   \n",
       "27  {'criterion': 'entropy', 'max_depth': 100, 'mi...  1.000000  0.013956   \n",
       "28                      {'C': 0.001, 'penalty': 'l1'}  1.000000  0.013956   \n",
       "29                      {'C': 0.001, 'penalty': 'l2'}  0.877551  0.012247   \n",
       "..                                                ...       ...       ...   \n",
       "33                          {'C': 1, 'penalty': 'l2'}  0.777778  0.010854   \n",
       "34                         {'C': 10, 'penalty': 'l1'}  0.773243  0.010791   \n",
       "35                         {'C': 10, 'penalty': 'l2'}  0.770975  0.010759   \n",
       "36          {'algorithm': 'SAMME', 'n_estimators': 1}  1.000000  0.013956   \n",
       "37         {'algorithm': 'SAMME', 'n_estimators': 10}  0.836735  0.011677   \n",
       "38        {'algorithm': 'SAMME', 'n_estimators': 100}  0.739229  0.010316   \n",
       "39        {'algorithm': 'SAMME.R', 'n_estimators': 1}  1.000000  0.013956   \n",
       "40       {'algorithm': 'SAMME.R', 'n_estimators': 10}  0.761905  0.010633   \n",
       "41      {'algorithm': 'SAMME.R', 'n_estimators': 100}  0.775510  0.010823   \n",
       "42  {'max_depth': 5, 'max_features': 'sqrt', 'min_...  0.857143  0.011962   \n",
       "43  {'max_depth': 5, 'max_features': 'sqrt', 'min_...  0.902494  0.012595   \n",
       "44  {'max_depth': 5, 'max_features': 'sqrt', 'min_...  0.877551  0.012247   \n",
       "45  {'max_depth': 5, 'max_features': 'sqrt', 'min_...  0.895692  0.012500   \n",
       "46  {'max_depth': 5, 'max_features': 'log2', 'min_...  0.868481  0.012120   \n",
       "47  {'max_depth': 5, 'max_features': 'log2', 'min_...  0.886621  0.012373   \n",
       "48  {'max_depth': 5, 'max_features': 'log2', 'min_...  0.888889  0.012405   \n",
       "49  {'max_depth': 5, 'max_features': 'log2', 'min_...  0.886621  0.012373   \n",
       "50  {'max_depth': 50, 'max_features': 'sqrt', 'min...  1.000000  0.013956   \n",
       "51  {'max_depth': 50, 'max_features': 'sqrt', 'min...  0.841270  0.011741   \n",
       "52  {'max_depth': 50, 'max_features': 'sqrt', 'min...  0.850340  0.011867   \n",
       "53  {'max_depth': 50, 'max_features': 'sqrt', 'min...  0.879819  0.012278   \n",
       "54  {'max_depth': 50, 'max_features': 'log2', 'min...  1.000000  0.013956   \n",
       "55  {'max_depth': 50, 'max_features': 'log2', 'min...  0.829932  0.011582   \n",
       "56  {'max_depth': 50, 'max_features': 'log2', 'min...  0.861678  0.012025   \n",
       "57  {'max_depth': 50, 'max_features': 'log2', 'min...  0.882086  0.012310   \n",
       "58                                       {'C': 0.001}  0.888889  0.012405   \n",
       "59                                        {'C': 0.01}  0.868481  0.012120   \n",
       "60                                         {'C': 0.1}  0.848073  0.011835   \n",
       "61                                           {'C': 1}  0.850340  0.011867   \n",
       "62                                          {'C': 10}  0.841270  0.011741   \n",
       "\n",
       "      p_at_2    r_at_2    p_at_5    r_at_5   p_at_10   r_at_10   p_at_20  \\\n",
       "0   0.710079  0.019842  0.867301  0.060601  0.837220  0.117025  0.803396   \n",
       "1   0.883352  0.024684  0.871830  0.060918  0.854426  0.119430  0.828862   \n",
       "2   0.828992  0.023165  0.850091  0.059399  0.843559  0.117911  0.827617   \n",
       "3   0.843715  0.023576  0.852808  0.059589  0.845370  0.118165  0.828976   \n",
       "4   0.795017  0.022215  0.843297  0.058924  0.844238  0.118006  0.828297   \n",
       "5   0.800680  0.022373  0.843750  0.058956  0.844238  0.118006  0.827391   \n",
       "6   0.793884  0.022184  0.844203  0.058987  0.844917  0.118101  0.827504   \n",
       "7   0.793884  0.022184  0.844203  0.058987  0.844917  0.118101  0.827617   \n",
       "8   1.000000  0.027943  1.000000  0.069873  0.744623  0.104082  0.672213   \n",
       "9   1.000000  0.027943  1.000000  0.069873  0.744623  0.104082  0.672213   \n",
       "10  0.705549  0.019715  0.788496  0.055095  0.749830  0.104810  0.805999   \n",
       "11  0.705549  0.019715  0.788496  0.055095  0.749830  0.104810  0.805999   \n",
       "12  0.749717  0.020949  0.802989  0.056108  0.803939  0.112373  0.804188   \n",
       "13  0.747452  0.020886  0.803895  0.056171  0.800091  0.111835  0.804188   \n",
       "14  1.000000  0.027943  0.993207  0.069399  0.996378  0.139272  0.528919   \n",
       "15  1.000000  0.027943  1.000000  0.069873  0.970342  0.135633  0.518846   \n",
       "16  1.000000  0.027943  0.967844  0.067627  0.983926  0.137532  0.555178   \n",
       "17  1.000000  0.027943  0.987319  0.068987  0.993661  0.138892  0.509338   \n",
       "18  1.000000  0.027943  1.000000  0.069873  0.744623  0.104082  0.672213   \n",
       "19  1.000000  0.027943  1.000000  0.069873  0.744623  0.104082  0.672213   \n",
       "20  0.795017  0.022215  0.810236  0.056614  0.760697  0.106329  0.821279   \n",
       "21  0.796149  0.022247  0.810688  0.056646  0.760924  0.106361  0.821166   \n",
       "22  0.730464  0.020411  0.795743  0.055601  0.827258  0.115633  0.818789   \n",
       "23  0.727067  0.020316  0.794384  0.055506  0.826806  0.115570  0.818789   \n",
       "24  1.000000  0.027943  1.000000  0.069873  1.000000  0.139778  0.517148   \n",
       "25  1.000000  0.027943  1.000000  0.069873  0.953362  0.133259  0.531409   \n",
       "26  0.998867  0.027911  0.971014  0.067848  0.985511  0.137753  0.549179   \n",
       "27  0.998867  0.027911  0.992754  0.069367  0.996378  0.139272  0.508432   \n",
       "28  0.710079  0.019842  0.867301  0.060601  0.837220  0.117025  0.799095   \n",
       "29  0.883352  0.024684  0.871830  0.060918  0.854426  0.119430  0.828862   \n",
       "..       ...       ...       ...       ...       ...       ...       ...   \n",
       "33  0.800680  0.022373  0.843750  0.058956  0.844238  0.118006  0.827391   \n",
       "34  0.793884  0.022184  0.844656  0.059019  0.844917  0.118101  0.827278   \n",
       "35  0.793884  0.022184  0.844203  0.058987  0.844917  0.118101  0.827617   \n",
       "36  1.000000  0.027943  1.000000  0.069873  0.744623  0.104082  0.672213   \n",
       "37  0.898075  0.025095  0.902174  0.063038  0.823862  0.115158  0.822524   \n",
       "38  0.781427  0.021835  0.838315  0.058576  0.830428  0.116076  0.819581   \n",
       "39  1.000000  0.027943  1.000000  0.069873  0.744623  0.104082  0.672213   \n",
       "40  0.784824  0.021930  0.821105  0.057373  0.815033  0.113924  0.820147   \n",
       "41  0.790487  0.022089  0.843750  0.058956  0.845144  0.118133  0.827165   \n",
       "42  0.862967  0.024114  0.857790  0.059937  0.844691  0.118070  0.826712   \n",
       "43  0.876557  0.024494  0.874547  0.061108  0.856237  0.119684  0.826712   \n",
       "44  0.866365  0.024209  0.855525  0.059778  0.844012  0.117975  0.819468   \n",
       "45  0.875425  0.024462  0.873641  0.061044  0.855558  0.119589  0.826486   \n",
       "46  0.859570  0.024019  0.846467  0.059146  0.846955  0.118386  0.826938   \n",
       "47  0.877690  0.024525  0.876359  0.061234  0.855105  0.119525  0.831239   \n",
       "48  0.859570  0.024019  0.855525  0.059778  0.847861  0.118513  0.827504   \n",
       "49  0.882220  0.024652  0.876359  0.061234  0.857143  0.119810  0.831579   \n",
       "50  1.000000  0.027943  0.639493  0.044684  0.808467  0.113006  0.794001   \n",
       "51  0.847112  0.023671  0.850543  0.059430  0.816844  0.114177  0.790492   \n",
       "52  0.845980  0.023639  0.850091  0.059399  0.829975  0.116013  0.805433   \n",
       "53  0.879955  0.024589  0.859149  0.060032  0.839937  0.117405  0.819015   \n",
       "54  1.000000  0.027943  0.657609  0.045949  0.802355  0.112152  0.793775   \n",
       "55  0.830125  0.023196  0.837409  0.058513  0.817976  0.114335  0.790606   \n",
       "56  0.860702  0.024051  0.848279  0.059272  0.831560  0.116234  0.810300   \n",
       "57  0.876557  0.024494  0.866848  0.060570  0.843333  0.117880  0.823090   \n",
       "58  0.899207  0.025127  0.876359  0.061234  0.858275  0.119968  0.833164   \n",
       "59  0.867497  0.024241  0.865036  0.060443  0.851030  0.118956  0.828636   \n",
       "60  0.857305  0.023956  0.853714  0.059652  0.846729  0.118354  0.827278   \n",
       "61  0.850510  0.023766  0.854620  0.059715  0.846729  0.118354  0.826825   \n",
       "62  0.843715  0.023576  0.857337  0.059905  0.845370  0.118165  0.827051   \n",
       "\n",
       "     r_at_20   p_at_30   r_at_30   p_at_50   r_at_50   auc-roc  \n",
       "0   0.224620  0.781467  0.327722  0.785313  0.548924  0.593102  \n",
       "1   0.231741  0.817386  0.342785  0.783412  0.547595  0.617331  \n",
       "2   0.231392  0.817235  0.342722  0.787396  0.550380  0.619974  \n",
       "3   0.231772  0.817235  0.342722  0.786490  0.549747  0.620281  \n",
       "4   0.231582  0.817009  0.342627  0.786445  0.549715  0.619894  \n",
       "5   0.231329  0.816707  0.342500  0.786671  0.549873  0.619810  \n",
       "6   0.231361  0.816556  0.342437  0.786671  0.549873  0.619781  \n",
       "7   0.231392  0.816556  0.342437  0.786762  0.549937  0.619771  \n",
       "8   0.187943  0.781467  0.327722  0.868843  0.607310  0.547044  \n",
       "9   0.187943  0.781467  0.327722  0.868843  0.607310  0.547044  \n",
       "10  0.225348  0.780486  0.327310  0.784227  0.548165  0.609405  \n",
       "11  0.225348  0.780486  0.327310  0.784227  0.548165  0.609405  \n",
       "12  0.224842  0.801011  0.335918  0.781375  0.546171  0.603402  \n",
       "13  0.224842  0.800936  0.335886  0.781239  0.546076  0.603347  \n",
       "14  0.147880  0.644959  0.270475  0.756836  0.529019  0.553882  \n",
       "15  0.145063  0.679218  0.284842  0.755433  0.528038  0.556310  \n",
       "16  0.155222  0.619076  0.259620  0.753577  0.526741  0.550751  \n",
       "17  0.142405  0.656127  0.275158  0.753079  0.526392  0.552637  \n",
       "18  0.187943  0.781467  0.327722  0.868843  0.607310  0.547044  \n",
       "19  0.187943  0.781467  0.327722  0.868843  0.607310  0.547044  \n",
       "20  0.229620  0.776411  0.325601  0.780695  0.545696  0.608205  \n",
       "21  0.229589  0.776487  0.325633  0.780741  0.545728  0.608252  \n",
       "22  0.228924  0.801087  0.335949  0.786264  0.549589  0.608688  \n",
       "23  0.228924  0.800634  0.335759  0.786309  0.549620  0.608738  \n",
       "24  0.144589  0.655901  0.275063  0.754573  0.527437  0.554204  \n",
       "25  0.148576  0.687594  0.288354  0.763944  0.533987  0.557241  \n",
       "26  0.153544  0.624208  0.261772  0.751630  0.525380  0.550796  \n",
       "27  0.142152  0.658618  0.276203  0.753984  0.527025  0.552605  \n",
       "28  0.223418  0.781467  0.327722  0.785313  0.548924  0.590088  \n",
       "29  0.231741  0.817386  0.342785  0.783412  0.547595  0.617331  \n",
       "..       ...       ...       ...       ...       ...       ...  \n",
       "33  0.231329  0.816707  0.342500  0.786671  0.549873  0.619810  \n",
       "34  0.231297  0.816556  0.342437  0.786853  0.550000  0.619792  \n",
       "35  0.231392  0.816556  0.342437  0.786762  0.549937  0.619771  \n",
       "36  0.187943  0.781467  0.327722  0.868843  0.607310  0.547044  \n",
       "37  0.229968  0.779882  0.327057  0.783140  0.547405  0.601875  \n",
       "38  0.229146  0.774374  0.324747  0.782280  0.546804  0.602678  \n",
       "39  0.187943  0.781467  0.327722  0.868843  0.607310  0.547044  \n",
       "40  0.229304  0.809010  0.339272  0.802562  0.560981  0.610830  \n",
       "41  0.231266  0.817160  0.342690  0.786807  0.549968  0.619644  \n",
       "42  0.231139  0.795804  0.333734  0.775715  0.542215  0.606076  \n",
       "43  0.231139  0.814066  0.341392  0.780650  0.545665  0.616676  \n",
       "44  0.229114  0.792409  0.332310  0.772365  0.539873  0.603239  \n",
       "45  0.231076  0.811877  0.340475  0.780560  0.545601  0.615912  \n",
       "46  0.231203  0.812708  0.340823  0.781963  0.546582  0.614701  \n",
       "47  0.232405  0.816254  0.342310  0.783910  0.547943  0.618690  \n",
       "48  0.231361  0.815952  0.342184  0.784634  0.548449  0.616462  \n",
       "49  0.232500  0.816933  0.342595  0.784996  0.548703  0.619532  \n",
       "50  0.221994  0.780486  0.327310  0.762586  0.533038  0.577122  \n",
       "51  0.221013  0.781920  0.327911  0.766570  0.535823  0.583090  \n",
       "52  0.225190  0.793390  0.332722  0.768607  0.537247  0.589409  \n",
       "53  0.228987  0.800634  0.335759  0.773044  0.540348  0.601300  \n",
       "54  0.221930  0.774374  0.324747  0.758783  0.530380  0.572474  \n",
       "55  0.221044  0.784410  0.328956  0.763627  0.533766  0.582335  \n",
       "56  0.226551  0.796106  0.333861  0.773814  0.540886  0.596438  \n",
       "57  0.230127  0.802294  0.336456  0.777390  0.543386  0.604583  \n",
       "58  0.232943  0.819423  0.343639  0.788482  0.551139  0.622892  \n",
       "59  0.231677  0.817839  0.342975  0.787984  0.550791  0.621633  \n",
       "60  0.231297  0.817084  0.342658  0.788030  0.550823  0.621200  \n",
       "61  0.231171  0.816933  0.342595  0.788211  0.550949  0.621155  \n",
       "62  0.231234  0.817537  0.342848  0.788120  0.550886  0.620483  \n",
       "\n",
       "[63 rows x 18 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(pipeline)\n",
    "\n",
    "print(\"With first train set (biggest one):\")\n",
    "pipeline.iterate_over_models(models_to_run, models, parameters_grid, x_train_1, x_test_1, y_train_1, y_test_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With second train set:\n",
      "Running LR...\n",
      "Running DT...\n",
      "Running LR...\n",
      "Running AB...\n",
      "Running RF...\n",
      "Running SVM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/felipe/.local/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>model</th>\n",
       "      <th>parameters</th>\n",
       "      <th>p_at_1</th>\n",
       "      <th>r_at_1</th>\n",
       "      <th>p_at_2</th>\n",
       "      <th>r_at_2</th>\n",
       "      <th>p_at_5</th>\n",
       "      <th>r_at_5</th>\n",
       "      <th>p_at_10</th>\n",
       "      <th>r_at_10</th>\n",
       "      <th>p_at_20</th>\n",
       "      <th>r_at_20</th>\n",
       "      <th>p_at_30</th>\n",
       "      <th>r_at_30</th>\n",
       "      <th>p_at_50</th>\n",
       "      <th>r_at_50</th>\n",
       "      <th>auc-roc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>{'C': 0.001, 'penalty': 'l1'}</td>\n",
       "      <td>0.986322</td>\n",
       "      <td>0.013979</td>\n",
       "      <td>0.695289</td>\n",
       "      <td>0.019708</td>\n",
       "      <td>0.823100</td>\n",
       "      <td>0.058327</td>\n",
       "      <td>0.838474</td>\n",
       "      <td>0.118851</td>\n",
       "      <td>0.798830</td>\n",
       "      <td>0.226480</td>\n",
       "      <td>0.753102</td>\n",
       "      <td>0.320281</td>\n",
       "      <td>0.783494</td>\n",
       "      <td>0.555355</td>\n",
       "      <td>0.589707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>{'C': 0.001, 'penalty': 'l2'}</td>\n",
       "      <td>0.881459</td>\n",
       "      <td>0.012492</td>\n",
       "      <td>0.876900</td>\n",
       "      <td>0.024856</td>\n",
       "      <td>0.871733</td>\n",
       "      <td>0.061773</td>\n",
       "      <td>0.845008</td>\n",
       "      <td>0.119777</td>\n",
       "      <td>0.823672</td>\n",
       "      <td>0.233523</td>\n",
       "      <td>0.809268</td>\n",
       "      <td>0.344167</td>\n",
       "      <td>0.775016</td>\n",
       "      <td>0.549345</td>\n",
       "      <td>0.616552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'l1'}</td>\n",
       "      <td>0.841945</td>\n",
       "      <td>0.011932</td>\n",
       "      <td>0.843465</td>\n",
       "      <td>0.023908</td>\n",
       "      <td>0.854407</td>\n",
       "      <td>0.060545</td>\n",
       "      <td>0.845160</td>\n",
       "      <td>0.119798</td>\n",
       "      <td>0.823520</td>\n",
       "      <td>0.233480</td>\n",
       "      <td>0.812459</td>\n",
       "      <td>0.345524</td>\n",
       "      <td>0.779088</td>\n",
       "      <td>0.552231</td>\n",
       "      <td>0.621434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'l2'}</td>\n",
       "      <td>0.860182</td>\n",
       "      <td>0.012191</td>\n",
       "      <td>0.851064</td>\n",
       "      <td>0.024123</td>\n",
       "      <td>0.856535</td>\n",
       "      <td>0.060696</td>\n",
       "      <td>0.845312</td>\n",
       "      <td>0.119820</td>\n",
       "      <td>0.824508</td>\n",
       "      <td>0.233760</td>\n",
       "      <td>0.810382</td>\n",
       "      <td>0.344641</td>\n",
       "      <td>0.778693</td>\n",
       "      <td>0.551951</td>\n",
       "      <td>0.621850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>{'C': 1, 'penalty': 'l1'}</td>\n",
       "      <td>0.794833</td>\n",
       "      <td>0.011265</td>\n",
       "      <td>0.826748</td>\n",
       "      <td>0.023434</td>\n",
       "      <td>0.853495</td>\n",
       "      <td>0.060481</td>\n",
       "      <td>0.844097</td>\n",
       "      <td>0.119648</td>\n",
       "      <td>0.824128</td>\n",
       "      <td>0.233652</td>\n",
       "      <td>0.810332</td>\n",
       "      <td>0.344620</td>\n",
       "      <td>0.778571</td>\n",
       "      <td>0.551865</td>\n",
       "      <td>0.621629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>{'C': 1, 'penalty': 'l2'}</td>\n",
       "      <td>0.802432</td>\n",
       "      <td>0.011372</td>\n",
       "      <td>0.826748</td>\n",
       "      <td>0.023434</td>\n",
       "      <td>0.853191</td>\n",
       "      <td>0.060459</td>\n",
       "      <td>0.843641</td>\n",
       "      <td>0.119583</td>\n",
       "      <td>0.823824</td>\n",
       "      <td>0.233566</td>\n",
       "      <td>0.809927</td>\n",
       "      <td>0.344447</td>\n",
       "      <td>0.778632</td>\n",
       "      <td>0.551908</td>\n",
       "      <td>0.621587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>{'C': 10, 'penalty': 'l1'}</td>\n",
       "      <td>0.793313</td>\n",
       "      <td>0.011243</td>\n",
       "      <td>0.825228</td>\n",
       "      <td>0.023391</td>\n",
       "      <td>0.852888</td>\n",
       "      <td>0.060438</td>\n",
       "      <td>0.843185</td>\n",
       "      <td>0.119518</td>\n",
       "      <td>0.824052</td>\n",
       "      <td>0.233631</td>\n",
       "      <td>0.809977</td>\n",
       "      <td>0.344469</td>\n",
       "      <td>0.778693</td>\n",
       "      <td>0.551951</td>\n",
       "      <td>0.621588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>{'C': 10, 'penalty': 'l2'}</td>\n",
       "      <td>0.791793</td>\n",
       "      <td>0.011222</td>\n",
       "      <td>0.825228</td>\n",
       "      <td>0.023391</td>\n",
       "      <td>0.852888</td>\n",
       "      <td>0.060438</td>\n",
       "      <td>0.843185</td>\n",
       "      <td>0.119518</td>\n",
       "      <td>0.824052</td>\n",
       "      <td>0.233631</td>\n",
       "      <td>0.809876</td>\n",
       "      <td>0.344426</td>\n",
       "      <td>0.778632</td>\n",
       "      <td>0.551908</td>\n",
       "      <td>0.621575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 1, 'min_sam...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.014172</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.028345</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.070862</td>\n",
       "      <td>0.663273</td>\n",
       "      <td>0.094017</td>\n",
       "      <td>0.707969</td>\n",
       "      <td>0.200719</td>\n",
       "      <td>0.805318</td>\n",
       "      <td>0.342487</td>\n",
       "      <td>0.883193</td>\n",
       "      <td>0.626023</td>\n",
       "      <td>0.547378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 1, 'min_sam...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.014172</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.028345</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.070862</td>\n",
       "      <td>0.663273</td>\n",
       "      <td>0.094017</td>\n",
       "      <td>0.707969</td>\n",
       "      <td>0.200719</td>\n",
       "      <td>0.805318</td>\n",
       "      <td>0.342487</td>\n",
       "      <td>0.883193</td>\n",
       "      <td>0.626023</td>\n",
       "      <td>0.547378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'min_sam...</td>\n",
       "      <td>0.844985</td>\n",
       "      <td>0.011976</td>\n",
       "      <td>0.780395</td>\n",
       "      <td>0.022120</td>\n",
       "      <td>0.827356</td>\n",
       "      <td>0.058628</td>\n",
       "      <td>0.781188</td>\n",
       "      <td>0.110731</td>\n",
       "      <td>0.806731</td>\n",
       "      <td>0.228720</td>\n",
       "      <td>0.774424</td>\n",
       "      <td>0.329349</td>\n",
       "      <td>0.784102</td>\n",
       "      <td>0.555785</td>\n",
       "      <td>0.609611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'min_sam...</td>\n",
       "      <td>0.844985</td>\n",
       "      <td>0.011976</td>\n",
       "      <td>0.780395</td>\n",
       "      <td>0.022120</td>\n",
       "      <td>0.827356</td>\n",
       "      <td>0.058628</td>\n",
       "      <td>0.781188</td>\n",
       "      <td>0.110731</td>\n",
       "      <td>0.806731</td>\n",
       "      <td>0.228720</td>\n",
       "      <td>0.774424</td>\n",
       "      <td>0.329349</td>\n",
       "      <td>0.784102</td>\n",
       "      <td>0.555785</td>\n",
       "      <td>0.609611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 10, 'min_sa...</td>\n",
       "      <td>0.673252</td>\n",
       "      <td>0.009542</td>\n",
       "      <td>0.818389</td>\n",
       "      <td>0.023197</td>\n",
       "      <td>0.842553</td>\n",
       "      <td>0.059705</td>\n",
       "      <td>0.828749</td>\n",
       "      <td>0.117472</td>\n",
       "      <td>0.821393</td>\n",
       "      <td>0.232877</td>\n",
       "      <td>0.805622</td>\n",
       "      <td>0.342617</td>\n",
       "      <td>0.775715</td>\n",
       "      <td>0.549841</td>\n",
       "      <td>0.615923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 10, 'min_sa...</td>\n",
       "      <td>0.685410</td>\n",
       "      <td>0.009714</td>\n",
       "      <td>0.820669</td>\n",
       "      <td>0.023262</td>\n",
       "      <td>0.843465</td>\n",
       "      <td>0.059770</td>\n",
       "      <td>0.828901</td>\n",
       "      <td>0.117494</td>\n",
       "      <td>0.821393</td>\n",
       "      <td>0.232877</td>\n",
       "      <td>0.805622</td>\n",
       "      <td>0.342617</td>\n",
       "      <td>0.775563</td>\n",
       "      <td>0.549733</td>\n",
       "      <td>0.615698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 50, 'min_sa...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.014172</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.028345</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.070862</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.141746</td>\n",
       "      <td>0.649548</td>\n",
       "      <td>0.184156</td>\n",
       "      <td>0.761712</td>\n",
       "      <td>0.323942</td>\n",
       "      <td>0.817223</td>\n",
       "      <td>0.579263</td>\n",
       "      <td>0.671708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 50, 'min_sa...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.014172</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.028345</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.070862</td>\n",
       "      <td>0.918401</td>\n",
       "      <td>0.130180</td>\n",
       "      <td>0.677049</td>\n",
       "      <td>0.191953</td>\n",
       "      <td>0.784705</td>\n",
       "      <td>0.333721</td>\n",
       "      <td>0.816646</td>\n",
       "      <td>0.578853</td>\n",
       "      <td>0.665784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 100, 'min_s...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.014172</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.028345</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.070862</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.141746</td>\n",
       "      <td>0.669452</td>\n",
       "      <td>0.189799</td>\n",
       "      <td>0.744340</td>\n",
       "      <td>0.316555</td>\n",
       "      <td>0.820870</td>\n",
       "      <td>0.581847</td>\n",
       "      <td>0.673102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 100, 'min_s...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.014172</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.028345</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.070862</td>\n",
       "      <td>0.973256</td>\n",
       "      <td>0.137956</td>\n",
       "      <td>0.653802</td>\n",
       "      <td>0.185362</td>\n",
       "      <td>0.769207</td>\n",
       "      <td>0.327130</td>\n",
       "      <td>0.816616</td>\n",
       "      <td>0.578832</td>\n",
       "      <td>0.666648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 1, 'min_...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.014172</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.028345</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.070862</td>\n",
       "      <td>0.663273</td>\n",
       "      <td>0.094017</td>\n",
       "      <td>0.707969</td>\n",
       "      <td>0.200719</td>\n",
       "      <td>0.805318</td>\n",
       "      <td>0.342487</td>\n",
       "      <td>0.883193</td>\n",
       "      <td>0.626023</td>\n",
       "      <td>0.547378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 1, 'min_...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.014172</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.028345</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.070862</td>\n",
       "      <td>0.663273</td>\n",
       "      <td>0.094017</td>\n",
       "      <td>0.707969</td>\n",
       "      <td>0.200719</td>\n",
       "      <td>0.805318</td>\n",
       "      <td>0.342487</td>\n",
       "      <td>0.883193</td>\n",
       "      <td>0.626023</td>\n",
       "      <td>0.547378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'min_...</td>\n",
       "      <td>0.831307</td>\n",
       "      <td>0.011782</td>\n",
       "      <td>0.832067</td>\n",
       "      <td>0.023585</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.060739</td>\n",
       "      <td>0.796080</td>\n",
       "      <td>0.112841</td>\n",
       "      <td>0.802097</td>\n",
       "      <td>0.227406</td>\n",
       "      <td>0.771486</td>\n",
       "      <td>0.328099</td>\n",
       "      <td>0.781245</td>\n",
       "      <td>0.553761</td>\n",
       "      <td>0.609104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'min_...</td>\n",
       "      <td>0.832827</td>\n",
       "      <td>0.011803</td>\n",
       "      <td>0.830547</td>\n",
       "      <td>0.023542</td>\n",
       "      <td>0.857447</td>\n",
       "      <td>0.060761</td>\n",
       "      <td>0.796232</td>\n",
       "      <td>0.112863</td>\n",
       "      <td>0.802173</td>\n",
       "      <td>0.227427</td>\n",
       "      <td>0.771537</td>\n",
       "      <td>0.328121</td>\n",
       "      <td>0.781276</td>\n",
       "      <td>0.553782</td>\n",
       "      <td>0.609113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 10, 'min...</td>\n",
       "      <td>0.706687</td>\n",
       "      <td>0.010016</td>\n",
       "      <td>0.819149</td>\n",
       "      <td>0.023219</td>\n",
       "      <td>0.850152</td>\n",
       "      <td>0.060244</td>\n",
       "      <td>0.835587</td>\n",
       "      <td>0.118441</td>\n",
       "      <td>0.831497</td>\n",
       "      <td>0.235741</td>\n",
       "      <td>0.807242</td>\n",
       "      <td>0.343306</td>\n",
       "      <td>0.782248</td>\n",
       "      <td>0.554471</td>\n",
       "      <td>0.618732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 10, 'min...</td>\n",
       "      <td>0.705167</td>\n",
       "      <td>0.009994</td>\n",
       "      <td>0.816869</td>\n",
       "      <td>0.023154</td>\n",
       "      <td>0.849240</td>\n",
       "      <td>0.060179</td>\n",
       "      <td>0.835283</td>\n",
       "      <td>0.118398</td>\n",
       "      <td>0.831497</td>\n",
       "      <td>0.235741</td>\n",
       "      <td>0.807242</td>\n",
       "      <td>0.343306</td>\n",
       "      <td>0.782370</td>\n",
       "      <td>0.554558</td>\n",
       "      <td>0.618663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 50, 'min...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.014172</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.028345</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.070862</td>\n",
       "      <td>0.981158</td>\n",
       "      <td>0.139076</td>\n",
       "      <td>0.653574</td>\n",
       "      <td>0.185298</td>\n",
       "      <td>0.769055</td>\n",
       "      <td>0.327066</td>\n",
       "      <td>0.815977</td>\n",
       "      <td>0.578379</td>\n",
       "      <td>0.669600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 50, 'min...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.014172</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.028345</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.070862</td>\n",
       "      <td>0.906245</td>\n",
       "      <td>0.128457</td>\n",
       "      <td>0.685482</td>\n",
       "      <td>0.194344</td>\n",
       "      <td>0.790327</td>\n",
       "      <td>0.336112</td>\n",
       "      <td>0.825610</td>\n",
       "      <td>0.585207</td>\n",
       "      <td>0.665806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 100, 'mi...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.014172</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.028345</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.070862</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.141746</td>\n",
       "      <td>0.664134</td>\n",
       "      <td>0.188292</td>\n",
       "      <td>0.747784</td>\n",
       "      <td>0.318019</td>\n",
       "      <td>0.823240</td>\n",
       "      <td>0.583527</td>\n",
       "      <td>0.673119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 100, 'mi...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.014172</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.028345</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.070862</td>\n",
       "      <td>0.976295</td>\n",
       "      <td>0.138386</td>\n",
       "      <td>0.656309</td>\n",
       "      <td>0.186073</td>\n",
       "      <td>0.770879</td>\n",
       "      <td>0.327841</td>\n",
       "      <td>0.818044</td>\n",
       "      <td>0.579844</td>\n",
       "      <td>0.668566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>{'C': 0.001, 'penalty': 'l1'}</td>\n",
       "      <td>0.986322</td>\n",
       "      <td>0.013979</td>\n",
       "      <td>0.695289</td>\n",
       "      <td>0.019708</td>\n",
       "      <td>0.823100</td>\n",
       "      <td>0.058327</td>\n",
       "      <td>0.838474</td>\n",
       "      <td>0.118851</td>\n",
       "      <td>0.798830</td>\n",
       "      <td>0.226480</td>\n",
       "      <td>0.753102</td>\n",
       "      <td>0.320281</td>\n",
       "      <td>0.783494</td>\n",
       "      <td>0.555355</td>\n",
       "      <td>0.589707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>{'C': 0.001, 'penalty': 'l2'}</td>\n",
       "      <td>0.881459</td>\n",
       "      <td>0.012492</td>\n",
       "      <td>0.876900</td>\n",
       "      <td>0.024856</td>\n",
       "      <td>0.871733</td>\n",
       "      <td>0.061773</td>\n",
       "      <td>0.845008</td>\n",
       "      <td>0.119777</td>\n",
       "      <td>0.823672</td>\n",
       "      <td>0.233523</td>\n",
       "      <td>0.809268</td>\n",
       "      <td>0.344167</td>\n",
       "      <td>0.775016</td>\n",
       "      <td>0.549345</td>\n",
       "      <td>0.616552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>{'C': 1, 'penalty': 'l2'}</td>\n",
       "      <td>0.802432</td>\n",
       "      <td>0.011372</td>\n",
       "      <td>0.826748</td>\n",
       "      <td>0.023434</td>\n",
       "      <td>0.853191</td>\n",
       "      <td>0.060459</td>\n",
       "      <td>0.843641</td>\n",
       "      <td>0.119583</td>\n",
       "      <td>0.823824</td>\n",
       "      <td>0.233566</td>\n",
       "      <td>0.809927</td>\n",
       "      <td>0.344447</td>\n",
       "      <td>0.778632</td>\n",
       "      <td>0.551908</td>\n",
       "      <td>0.621587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>{'C': 10, 'penalty': 'l1'}</td>\n",
       "      <td>0.793313</td>\n",
       "      <td>0.011243</td>\n",
       "      <td>0.825228</td>\n",
       "      <td>0.023391</td>\n",
       "      <td>0.852888</td>\n",
       "      <td>0.060438</td>\n",
       "      <td>0.843185</td>\n",
       "      <td>0.119518</td>\n",
       "      <td>0.824052</td>\n",
       "      <td>0.233631</td>\n",
       "      <td>0.809977</td>\n",
       "      <td>0.344469</td>\n",
       "      <td>0.778693</td>\n",
       "      <td>0.551951</td>\n",
       "      <td>0.621592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>{'C': 10, 'penalty': 'l2'}</td>\n",
       "      <td>0.791793</td>\n",
       "      <td>0.011222</td>\n",
       "      <td>0.825228</td>\n",
       "      <td>0.023391</td>\n",
       "      <td>0.852888</td>\n",
       "      <td>0.060438</td>\n",
       "      <td>0.843185</td>\n",
       "      <td>0.119518</td>\n",
       "      <td>0.824052</td>\n",
       "      <td>0.233631</td>\n",
       "      <td>0.809876</td>\n",
       "      <td>0.344426</td>\n",
       "      <td>0.778632</td>\n",
       "      <td>0.551908</td>\n",
       "      <td>0.621575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>AB</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'algorithm': 'SAMME', 'n_estimators': 1}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.014172</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.028345</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.070862</td>\n",
       "      <td>0.663273</td>\n",
       "      <td>0.094017</td>\n",
       "      <td>0.707969</td>\n",
       "      <td>0.200719</td>\n",
       "      <td>0.805318</td>\n",
       "      <td>0.342487</td>\n",
       "      <td>0.883193</td>\n",
       "      <td>0.626023</td>\n",
       "      <td>0.547378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>AB</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'algorithm': 'SAMME', 'n_estimators': 10}</td>\n",
       "      <td>0.849544</td>\n",
       "      <td>0.012040</td>\n",
       "      <td>0.864742</td>\n",
       "      <td>0.024511</td>\n",
       "      <td>0.882371</td>\n",
       "      <td>0.062527</td>\n",
       "      <td>0.833156</td>\n",
       "      <td>0.118097</td>\n",
       "      <td>0.802401</td>\n",
       "      <td>0.227492</td>\n",
       "      <td>0.784806</td>\n",
       "      <td>0.333764</td>\n",
       "      <td>0.775988</td>\n",
       "      <td>0.550034</td>\n",
       "      <td>0.603155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>AB</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'algorithm': 'SAMME', 'n_estimators': 100}</td>\n",
       "      <td>0.779635</td>\n",
       "      <td>0.011049</td>\n",
       "      <td>0.826748</td>\n",
       "      <td>0.023434</td>\n",
       "      <td>0.861702</td>\n",
       "      <td>0.061062</td>\n",
       "      <td>0.822671</td>\n",
       "      <td>0.116611</td>\n",
       "      <td>0.810605</td>\n",
       "      <td>0.229818</td>\n",
       "      <td>0.783236</td>\n",
       "      <td>0.333096</td>\n",
       "      <td>0.772038</td>\n",
       "      <td>0.547234</td>\n",
       "      <td>0.605013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>AB</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'algorithm': 'SAMME.R', 'n_estimators': 1}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.014172</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.028345</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.070862</td>\n",
       "      <td>0.663273</td>\n",
       "      <td>0.094017</td>\n",
       "      <td>0.707969</td>\n",
       "      <td>0.200719</td>\n",
       "      <td>0.805318</td>\n",
       "      <td>0.342487</td>\n",
       "      <td>0.883193</td>\n",
       "      <td>0.626023</td>\n",
       "      <td>0.547378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>AB</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'algorithm': 'SAMME.R', 'n_estimators': 10}</td>\n",
       "      <td>0.775076</td>\n",
       "      <td>0.010985</td>\n",
       "      <td>0.813830</td>\n",
       "      <td>0.023068</td>\n",
       "      <td>0.837690</td>\n",
       "      <td>0.059361</td>\n",
       "      <td>0.823735</td>\n",
       "      <td>0.116761</td>\n",
       "      <td>0.821013</td>\n",
       "      <td>0.232769</td>\n",
       "      <td>0.800608</td>\n",
       "      <td>0.340484</td>\n",
       "      <td>0.804309</td>\n",
       "      <td>0.570109</td>\n",
       "      <td>0.611839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>AB</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'algorithm': 'SAMME.R', 'n_estimators': 100}</td>\n",
       "      <td>0.797872</td>\n",
       "      <td>0.011308</td>\n",
       "      <td>0.828267</td>\n",
       "      <td>0.023477</td>\n",
       "      <td>0.854407</td>\n",
       "      <td>0.060545</td>\n",
       "      <td>0.843945</td>\n",
       "      <td>0.119626</td>\n",
       "      <td>0.824508</td>\n",
       "      <td>0.233760</td>\n",
       "      <td>0.810889</td>\n",
       "      <td>0.344857</td>\n",
       "      <td>0.778541</td>\n",
       "      <td>0.551844</td>\n",
       "      <td>0.621480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 'sqrt', 'min_...</td>\n",
       "      <td>0.855623</td>\n",
       "      <td>0.012126</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.024296</td>\n",
       "      <td>0.858055</td>\n",
       "      <td>0.060804</td>\n",
       "      <td>0.841665</td>\n",
       "      <td>0.119303</td>\n",
       "      <td>0.822913</td>\n",
       "      <td>0.233307</td>\n",
       "      <td>0.795948</td>\n",
       "      <td>0.338503</td>\n",
       "      <td>0.770367</td>\n",
       "      <td>0.546050</td>\n",
       "      <td>0.610254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 'sqrt', 'min_...</td>\n",
       "      <td>0.907295</td>\n",
       "      <td>0.012859</td>\n",
       "      <td>0.884498</td>\n",
       "      <td>0.025071</td>\n",
       "      <td>0.874164</td>\n",
       "      <td>0.061945</td>\n",
       "      <td>0.848807</td>\n",
       "      <td>0.120315</td>\n",
       "      <td>0.821165</td>\n",
       "      <td>0.232812</td>\n",
       "      <td>0.807850</td>\n",
       "      <td>0.343564</td>\n",
       "      <td>0.775016</td>\n",
       "      <td>0.549345</td>\n",
       "      <td>0.619022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 'sqrt', 'min_...</td>\n",
       "      <td>0.884498</td>\n",
       "      <td>0.012536</td>\n",
       "      <td>0.869301</td>\n",
       "      <td>0.024640</td>\n",
       "      <td>0.857447</td>\n",
       "      <td>0.060761</td>\n",
       "      <td>0.844097</td>\n",
       "      <td>0.119648</td>\n",
       "      <td>0.818886</td>\n",
       "      <td>0.232166</td>\n",
       "      <td>0.792049</td>\n",
       "      <td>0.336844</td>\n",
       "      <td>0.768483</td>\n",
       "      <td>0.544714</td>\n",
       "      <td>0.608049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 'sqrt', 'min_...</td>\n",
       "      <td>0.910334</td>\n",
       "      <td>0.012902</td>\n",
       "      <td>0.882979</td>\n",
       "      <td>0.025028</td>\n",
       "      <td>0.873252</td>\n",
       "      <td>0.061881</td>\n",
       "      <td>0.850327</td>\n",
       "      <td>0.120531</td>\n",
       "      <td>0.820862</td>\n",
       "      <td>0.232726</td>\n",
       "      <td>0.806635</td>\n",
       "      <td>0.343047</td>\n",
       "      <td>0.774742</td>\n",
       "      <td>0.549151</td>\n",
       "      <td>0.618268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 'log2', 'min_...</td>\n",
       "      <td>0.882979</td>\n",
       "      <td>0.012514</td>\n",
       "      <td>0.869301</td>\n",
       "      <td>0.024640</td>\n",
       "      <td>0.847720</td>\n",
       "      <td>0.060072</td>\n",
       "      <td>0.843033</td>\n",
       "      <td>0.119497</td>\n",
       "      <td>0.819190</td>\n",
       "      <td>0.232252</td>\n",
       "      <td>0.804963</td>\n",
       "      <td>0.342337</td>\n",
       "      <td>0.774165</td>\n",
       "      <td>0.548742</td>\n",
       "      <td>0.614670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 'log2', 'min_...</td>\n",
       "      <td>0.898176</td>\n",
       "      <td>0.012729</td>\n",
       "      <td>0.886778</td>\n",
       "      <td>0.025136</td>\n",
       "      <td>0.875988</td>\n",
       "      <td>0.062075</td>\n",
       "      <td>0.848655</td>\n",
       "      <td>0.120294</td>\n",
       "      <td>0.824356</td>\n",
       "      <td>0.233717</td>\n",
       "      <td>0.810129</td>\n",
       "      <td>0.344533</td>\n",
       "      <td>0.776718</td>\n",
       "      <td>0.550551</td>\n",
       "      <td>0.620370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 'log2', 'min_...</td>\n",
       "      <td>0.895137</td>\n",
       "      <td>0.012686</td>\n",
       "      <td>0.876140</td>\n",
       "      <td>0.024834</td>\n",
       "      <td>0.861702</td>\n",
       "      <td>0.061062</td>\n",
       "      <td>0.844552</td>\n",
       "      <td>0.119712</td>\n",
       "      <td>0.820482</td>\n",
       "      <td>0.232618</td>\n",
       "      <td>0.806584</td>\n",
       "      <td>0.343026</td>\n",
       "      <td>0.775381</td>\n",
       "      <td>0.549604</td>\n",
       "      <td>0.616112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 'log2', 'min_...</td>\n",
       "      <td>0.904255</td>\n",
       "      <td>0.012816</td>\n",
       "      <td>0.887538</td>\n",
       "      <td>0.025157</td>\n",
       "      <td>0.875684</td>\n",
       "      <td>0.062053</td>\n",
       "      <td>0.849567</td>\n",
       "      <td>0.120423</td>\n",
       "      <td>0.825876</td>\n",
       "      <td>0.234147</td>\n",
       "      <td>0.810737</td>\n",
       "      <td>0.344792</td>\n",
       "      <td>0.776718</td>\n",
       "      <td>0.550551</td>\n",
       "      <td>0.621013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 50, 'max_features': 'sqrt', 'min...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.014172</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.028345</td>\n",
       "      <td>0.758055</td>\n",
       "      <td>0.053718</td>\n",
       "      <td>0.879046</td>\n",
       "      <td>0.124602</td>\n",
       "      <td>0.874421</td>\n",
       "      <td>0.247911</td>\n",
       "      <td>0.856774</td>\n",
       "      <td>0.364371</td>\n",
       "      <td>0.821234</td>\n",
       "      <td>0.582106</td>\n",
       "      <td>0.696353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 50, 'max_features': 'sqrt', 'min...</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.013160</td>\n",
       "      <td>0.917933</td>\n",
       "      <td>0.026019</td>\n",
       "      <td>0.920669</td>\n",
       "      <td>0.065241</td>\n",
       "      <td>0.902143</td>\n",
       "      <td>0.127875</td>\n",
       "      <td>0.882170</td>\n",
       "      <td>0.250108</td>\n",
       "      <td>0.862801</td>\n",
       "      <td>0.366934</td>\n",
       "      <td>0.828618</td>\n",
       "      <td>0.587340</td>\n",
       "      <td>0.708737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 50, 'max_features': 'sqrt', 'min...</td>\n",
       "      <td>0.917933</td>\n",
       "      <td>0.013009</td>\n",
       "      <td>0.910334</td>\n",
       "      <td>0.025803</td>\n",
       "      <td>0.908207</td>\n",
       "      <td>0.064358</td>\n",
       "      <td>0.890442</td>\n",
       "      <td>0.126217</td>\n",
       "      <td>0.864089</td>\n",
       "      <td>0.244981</td>\n",
       "      <td>0.847151</td>\n",
       "      <td>0.360278</td>\n",
       "      <td>0.813151</td>\n",
       "      <td>0.576376</td>\n",
       "      <td>0.680287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 50, 'max_features': 'sqrt', 'min...</td>\n",
       "      <td>0.931611</td>\n",
       "      <td>0.013203</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.026320</td>\n",
       "      <td>0.916109</td>\n",
       "      <td>0.064918</td>\n",
       "      <td>0.900015</td>\n",
       "      <td>0.127574</td>\n",
       "      <td>0.876396</td>\n",
       "      <td>0.248471</td>\n",
       "      <td>0.858192</td>\n",
       "      <td>0.364974</td>\n",
       "      <td>0.821660</td>\n",
       "      <td>0.582407</td>\n",
       "      <td>0.698212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 50, 'max_features': 'log2', 'min...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.014172</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.028345</td>\n",
       "      <td>0.770213</td>\n",
       "      <td>0.054579</td>\n",
       "      <td>0.885124</td>\n",
       "      <td>0.125463</td>\n",
       "      <td>0.870850</td>\n",
       "      <td>0.246898</td>\n",
       "      <td>0.853330</td>\n",
       "      <td>0.362906</td>\n",
       "      <td>0.818803</td>\n",
       "      <td>0.580383</td>\n",
       "      <td>0.693699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 50, 'max_features': 'log2', 'min...</td>\n",
       "      <td>0.934650</td>\n",
       "      <td>0.013246</td>\n",
       "      <td>0.916413</td>\n",
       "      <td>0.025976</td>\n",
       "      <td>0.916413</td>\n",
       "      <td>0.064939</td>\n",
       "      <td>0.902446</td>\n",
       "      <td>0.127918</td>\n",
       "      <td>0.880802</td>\n",
       "      <td>0.249720</td>\n",
       "      <td>0.865333</td>\n",
       "      <td>0.368011</td>\n",
       "      <td>0.826370</td>\n",
       "      <td>0.585746</td>\n",
       "      <td>0.708881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 50, 'max_features': 'log2', 'min...</td>\n",
       "      <td>0.916413</td>\n",
       "      <td>0.012988</td>\n",
       "      <td>0.920213</td>\n",
       "      <td>0.026083</td>\n",
       "      <td>0.905471</td>\n",
       "      <td>0.064164</td>\n",
       "      <td>0.891658</td>\n",
       "      <td>0.126389</td>\n",
       "      <td>0.866292</td>\n",
       "      <td>0.245606</td>\n",
       "      <td>0.850393</td>\n",
       "      <td>0.361657</td>\n",
       "      <td>0.815339</td>\n",
       "      <td>0.577927</td>\n",
       "      <td>0.683563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 50, 'max_features': 'log2', 'min...</td>\n",
       "      <td>0.934650</td>\n",
       "      <td>0.013246</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.026320</td>\n",
       "      <td>0.919757</td>\n",
       "      <td>0.065176</td>\n",
       "      <td>0.902446</td>\n",
       "      <td>0.127918</td>\n",
       "      <td>0.879207</td>\n",
       "      <td>0.249268</td>\n",
       "      <td>0.858850</td>\n",
       "      <td>0.365254</td>\n",
       "      <td>0.824395</td>\n",
       "      <td>0.584346</td>\n",
       "      <td>0.699476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>SVM</td>\n",
       "      <td>LinearSVC(C=10, class_weight=None, dual=True, ...</td>\n",
       "      <td>{'C': 0.001}</td>\n",
       "      <td>0.886018</td>\n",
       "      <td>0.012557</td>\n",
       "      <td>0.892097</td>\n",
       "      <td>0.025286</td>\n",
       "      <td>0.871125</td>\n",
       "      <td>0.061730</td>\n",
       "      <td>0.852150</td>\n",
       "      <td>0.120789</td>\n",
       "      <td>0.827319</td>\n",
       "      <td>0.234557</td>\n",
       "      <td>0.812965</td>\n",
       "      <td>0.345740</td>\n",
       "      <td>0.779483</td>\n",
       "      <td>0.552511</td>\n",
       "      <td>0.622657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>SVM</td>\n",
       "      <td>LinearSVC(C=10, class_weight=None, dual=True, ...</td>\n",
       "      <td>{'C': 0.01}</td>\n",
       "      <td>0.870821</td>\n",
       "      <td>0.012342</td>\n",
       "      <td>0.873860</td>\n",
       "      <td>0.024770</td>\n",
       "      <td>0.861094</td>\n",
       "      <td>0.061019</td>\n",
       "      <td>0.847288</td>\n",
       "      <td>0.120100</td>\n",
       "      <td>0.824128</td>\n",
       "      <td>0.233652</td>\n",
       "      <td>0.811750</td>\n",
       "      <td>0.345223</td>\n",
       "      <td>0.779057</td>\n",
       "      <td>0.552210</td>\n",
       "      <td>0.622564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>SVM</td>\n",
       "      <td>LinearSVC(C=10, class_weight=None, dual=True, ...</td>\n",
       "      <td>{'C': 0.1}</td>\n",
       "      <td>0.858663</td>\n",
       "      <td>0.012169</td>\n",
       "      <td>0.860182</td>\n",
       "      <td>0.024382</td>\n",
       "      <td>0.858663</td>\n",
       "      <td>0.060847</td>\n",
       "      <td>0.845312</td>\n",
       "      <td>0.119820</td>\n",
       "      <td>0.824584</td>\n",
       "      <td>0.233781</td>\n",
       "      <td>0.811800</td>\n",
       "      <td>0.345244</td>\n",
       "      <td>0.778936</td>\n",
       "      <td>0.552124</td>\n",
       "      <td>0.622345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>SVM</td>\n",
       "      <td>LinearSVC(C=10, class_weight=None, dual=True, ...</td>\n",
       "      <td>{'C': 1}</td>\n",
       "      <td>0.864742</td>\n",
       "      <td>0.012256</td>\n",
       "      <td>0.857903</td>\n",
       "      <td>0.024317</td>\n",
       "      <td>0.856535</td>\n",
       "      <td>0.060696</td>\n",
       "      <td>0.845616</td>\n",
       "      <td>0.119863</td>\n",
       "      <td>0.824356</td>\n",
       "      <td>0.233717</td>\n",
       "      <td>0.811750</td>\n",
       "      <td>0.345223</td>\n",
       "      <td>0.779027</td>\n",
       "      <td>0.552188</td>\n",
       "      <td>0.622329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>SVM</td>\n",
       "      <td>LinearSVC(C=10, class_weight=None, dual=True, ...</td>\n",
       "      <td>{'C': 10}</td>\n",
       "      <td>0.861702</td>\n",
       "      <td>0.012212</td>\n",
       "      <td>0.854103</td>\n",
       "      <td>0.024210</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.060739</td>\n",
       "      <td>0.843945</td>\n",
       "      <td>0.119626</td>\n",
       "      <td>0.823445</td>\n",
       "      <td>0.233458</td>\n",
       "      <td>0.811193</td>\n",
       "      <td>0.344986</td>\n",
       "      <td>0.778480</td>\n",
       "      <td>0.551801</td>\n",
       "      <td>0.621743</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63 rows  18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   model_name                                              model  \\\n",
       "0          LR  LogisticRegression(C=10, class_weight=None, du...   \n",
       "1          LR  LogisticRegression(C=10, class_weight=None, du...   \n",
       "2          LR  LogisticRegression(C=10, class_weight=None, du...   \n",
       "3          LR  LogisticRegression(C=10, class_weight=None, du...   \n",
       "4          LR  LogisticRegression(C=10, class_weight=None, du...   \n",
       "5          LR  LogisticRegression(C=10, class_weight=None, du...   \n",
       "6          LR  LogisticRegression(C=10, class_weight=None, du...   \n",
       "7          LR  LogisticRegression(C=10, class_weight=None, du...   \n",
       "8          DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "9          DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "10         DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "11         DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "12         DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "13         DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "14         DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "15         DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "16         DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "17         DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "18         DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "19         DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "20         DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "21         DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "22         DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "23         DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "24         DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "25         DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "26         DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "27         DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "28         LR  LogisticRegression(C=10, class_weight=None, du...   \n",
       "29         LR  LogisticRegression(C=10, class_weight=None, du...   \n",
       "..        ...                                                ...   \n",
       "33         LR  LogisticRegression(C=10, class_weight=None, du...   \n",
       "34         LR  LogisticRegression(C=10, class_weight=None, du...   \n",
       "35         LR  LogisticRegression(C=10, class_weight=None, du...   \n",
       "36         AB  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "37         AB  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "38         AB  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "39         AB  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "40         AB  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "41         AB  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "42         RF  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "43         RF  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "44         RF  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "45         RF  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "46         RF  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "47         RF  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "48         RF  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "49         RF  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "50         RF  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "51         RF  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "52         RF  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "53         RF  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "54         RF  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "55         RF  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "56         RF  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "57         RF  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "58        SVM  LinearSVC(C=10, class_weight=None, dual=True, ...   \n",
       "59        SVM  LinearSVC(C=10, class_weight=None, dual=True, ...   \n",
       "60        SVM  LinearSVC(C=10, class_weight=None, dual=True, ...   \n",
       "61        SVM  LinearSVC(C=10, class_weight=None, dual=True, ...   \n",
       "62        SVM  LinearSVC(C=10, class_weight=None, dual=True, ...   \n",
       "\n",
       "                                           parameters    p_at_1    r_at_1  \\\n",
       "0                       {'C': 0.001, 'penalty': 'l1'}  0.986322  0.013979   \n",
       "1                       {'C': 0.001, 'penalty': 'l2'}  0.881459  0.012492   \n",
       "2                         {'C': 0.1, 'penalty': 'l1'}  0.841945  0.011932   \n",
       "3                         {'C': 0.1, 'penalty': 'l2'}  0.860182  0.012191   \n",
       "4                           {'C': 1, 'penalty': 'l1'}  0.794833  0.011265   \n",
       "5                           {'C': 1, 'penalty': 'l2'}  0.802432  0.011372   \n",
       "6                          {'C': 10, 'penalty': 'l1'}  0.793313  0.011243   \n",
       "7                          {'C': 10, 'penalty': 'l2'}  0.791793  0.011222   \n",
       "8   {'criterion': 'gini', 'max_depth': 1, 'min_sam...  1.000000  0.014172   \n",
       "9   {'criterion': 'gini', 'max_depth': 1, 'min_sam...  1.000000  0.014172   \n",
       "10  {'criterion': 'gini', 'max_depth': 5, 'min_sam...  0.844985  0.011976   \n",
       "11  {'criterion': 'gini', 'max_depth': 5, 'min_sam...  0.844985  0.011976   \n",
       "12  {'criterion': 'gini', 'max_depth': 10, 'min_sa...  0.673252  0.009542   \n",
       "13  {'criterion': 'gini', 'max_depth': 10, 'min_sa...  0.685410  0.009714   \n",
       "14  {'criterion': 'gini', 'max_depth': 50, 'min_sa...  1.000000  0.014172   \n",
       "15  {'criterion': 'gini', 'max_depth': 50, 'min_sa...  1.000000  0.014172   \n",
       "16  {'criterion': 'gini', 'max_depth': 100, 'min_s...  1.000000  0.014172   \n",
       "17  {'criterion': 'gini', 'max_depth': 100, 'min_s...  1.000000  0.014172   \n",
       "18  {'criterion': 'entropy', 'max_depth': 1, 'min_...  1.000000  0.014172   \n",
       "19  {'criterion': 'entropy', 'max_depth': 1, 'min_...  1.000000  0.014172   \n",
       "20  {'criterion': 'entropy', 'max_depth': 5, 'min_...  0.831307  0.011782   \n",
       "21  {'criterion': 'entropy', 'max_depth': 5, 'min_...  0.832827  0.011803   \n",
       "22  {'criterion': 'entropy', 'max_depth': 10, 'min...  0.706687  0.010016   \n",
       "23  {'criterion': 'entropy', 'max_depth': 10, 'min...  0.705167  0.009994   \n",
       "24  {'criterion': 'entropy', 'max_depth': 50, 'min...  1.000000  0.014172   \n",
       "25  {'criterion': 'entropy', 'max_depth': 50, 'min...  1.000000  0.014172   \n",
       "26  {'criterion': 'entropy', 'max_depth': 100, 'mi...  1.000000  0.014172   \n",
       "27  {'criterion': 'entropy', 'max_depth': 100, 'mi...  1.000000  0.014172   \n",
       "28                      {'C': 0.001, 'penalty': 'l1'}  0.986322  0.013979   \n",
       "29                      {'C': 0.001, 'penalty': 'l2'}  0.881459  0.012492   \n",
       "..                                                ...       ...       ...   \n",
       "33                          {'C': 1, 'penalty': 'l2'}  0.802432  0.011372   \n",
       "34                         {'C': 10, 'penalty': 'l1'}  0.793313  0.011243   \n",
       "35                         {'C': 10, 'penalty': 'l2'}  0.791793  0.011222   \n",
       "36          {'algorithm': 'SAMME', 'n_estimators': 1}  1.000000  0.014172   \n",
       "37         {'algorithm': 'SAMME', 'n_estimators': 10}  0.849544  0.012040   \n",
       "38        {'algorithm': 'SAMME', 'n_estimators': 100}  0.779635  0.011049   \n",
       "39        {'algorithm': 'SAMME.R', 'n_estimators': 1}  1.000000  0.014172   \n",
       "40       {'algorithm': 'SAMME.R', 'n_estimators': 10}  0.775076  0.010985   \n",
       "41      {'algorithm': 'SAMME.R', 'n_estimators': 100}  0.797872  0.011308   \n",
       "42  {'max_depth': 5, 'max_features': 'sqrt', 'min_...  0.855623  0.012126   \n",
       "43  {'max_depth': 5, 'max_features': 'sqrt', 'min_...  0.907295  0.012859   \n",
       "44  {'max_depth': 5, 'max_features': 'sqrt', 'min_...  0.884498  0.012536   \n",
       "45  {'max_depth': 5, 'max_features': 'sqrt', 'min_...  0.910334  0.012902   \n",
       "46  {'max_depth': 5, 'max_features': 'log2', 'min_...  0.882979  0.012514   \n",
       "47  {'max_depth': 5, 'max_features': 'log2', 'min_...  0.898176  0.012729   \n",
       "48  {'max_depth': 5, 'max_features': 'log2', 'min_...  0.895137  0.012686   \n",
       "49  {'max_depth': 5, 'max_features': 'log2', 'min_...  0.904255  0.012816   \n",
       "50  {'max_depth': 50, 'max_features': 'sqrt', 'min...  1.000000  0.014172   \n",
       "51  {'max_depth': 50, 'max_features': 'sqrt', 'min...  0.928571  0.013160   \n",
       "52  {'max_depth': 50, 'max_features': 'sqrt', 'min...  0.917933  0.013009   \n",
       "53  {'max_depth': 50, 'max_features': 'sqrt', 'min...  0.931611  0.013203   \n",
       "54  {'max_depth': 50, 'max_features': 'log2', 'min...  1.000000  0.014172   \n",
       "55  {'max_depth': 50, 'max_features': 'log2', 'min...  0.934650  0.013246   \n",
       "56  {'max_depth': 50, 'max_features': 'log2', 'min...  0.916413  0.012988   \n",
       "57  {'max_depth': 50, 'max_features': 'log2', 'min...  0.934650  0.013246   \n",
       "58                                       {'C': 0.001}  0.886018  0.012557   \n",
       "59                                        {'C': 0.01}  0.870821  0.012342   \n",
       "60                                         {'C': 0.1}  0.858663  0.012169   \n",
       "61                                           {'C': 1}  0.864742  0.012256   \n",
       "62                                          {'C': 10}  0.861702  0.012212   \n",
       "\n",
       "      p_at_2    r_at_2    p_at_5    r_at_5   p_at_10   r_at_10   p_at_20  \\\n",
       "0   0.695289  0.019708  0.823100  0.058327  0.838474  0.118851  0.798830   \n",
       "1   0.876900  0.024856  0.871733  0.061773  0.845008  0.119777  0.823672   \n",
       "2   0.843465  0.023908  0.854407  0.060545  0.845160  0.119798  0.823520   \n",
       "3   0.851064  0.024123  0.856535  0.060696  0.845312  0.119820  0.824508   \n",
       "4   0.826748  0.023434  0.853495  0.060481  0.844097  0.119648  0.824128   \n",
       "5   0.826748  0.023434  0.853191  0.060459  0.843641  0.119583  0.823824   \n",
       "6   0.825228  0.023391  0.852888  0.060438  0.843185  0.119518  0.824052   \n",
       "7   0.825228  0.023391  0.852888  0.060438  0.843185  0.119518  0.824052   \n",
       "8   1.000000  0.028345  1.000000  0.070862  0.663273  0.094017  0.707969   \n",
       "9   1.000000  0.028345  1.000000  0.070862  0.663273  0.094017  0.707969   \n",
       "10  0.780395  0.022120  0.827356  0.058628  0.781188  0.110731  0.806731   \n",
       "11  0.780395  0.022120  0.827356  0.058628  0.781188  0.110731  0.806731   \n",
       "12  0.818389  0.023197  0.842553  0.059705  0.828749  0.117472  0.821393   \n",
       "13  0.820669  0.023262  0.843465  0.059770  0.828901  0.117494  0.821393   \n",
       "14  1.000000  0.028345  1.000000  0.070862  1.000000  0.141746  0.649548   \n",
       "15  1.000000  0.028345  1.000000  0.070862  0.918401  0.130180  0.677049   \n",
       "16  1.000000  0.028345  1.000000  0.070862  1.000000  0.141746  0.669452   \n",
       "17  1.000000  0.028345  1.000000  0.070862  0.973256  0.137956  0.653802   \n",
       "18  1.000000  0.028345  1.000000  0.070862  0.663273  0.094017  0.707969   \n",
       "19  1.000000  0.028345  1.000000  0.070862  0.663273  0.094017  0.707969   \n",
       "20  0.832067  0.023585  0.857143  0.060739  0.796080  0.112841  0.802097   \n",
       "21  0.830547  0.023542  0.857447  0.060761  0.796232  0.112863  0.802173   \n",
       "22  0.819149  0.023219  0.850152  0.060244  0.835587  0.118441  0.831497   \n",
       "23  0.816869  0.023154  0.849240  0.060179  0.835283  0.118398  0.831497   \n",
       "24  1.000000  0.028345  1.000000  0.070862  0.981158  0.139076  0.653574   \n",
       "25  1.000000  0.028345  1.000000  0.070862  0.906245  0.128457  0.685482   \n",
       "26  1.000000  0.028345  1.000000  0.070862  1.000000  0.141746  0.664134   \n",
       "27  1.000000  0.028345  1.000000  0.070862  0.976295  0.138386  0.656309   \n",
       "28  0.695289  0.019708  0.823100  0.058327  0.838474  0.118851  0.798830   \n",
       "29  0.876900  0.024856  0.871733  0.061773  0.845008  0.119777  0.823672   \n",
       "..       ...       ...       ...       ...       ...       ...       ...   \n",
       "33  0.826748  0.023434  0.853191  0.060459  0.843641  0.119583  0.823824   \n",
       "34  0.825228  0.023391  0.852888  0.060438  0.843185  0.119518  0.824052   \n",
       "35  0.825228  0.023391  0.852888  0.060438  0.843185  0.119518  0.824052   \n",
       "36  1.000000  0.028345  1.000000  0.070862  0.663273  0.094017  0.707969   \n",
       "37  0.864742  0.024511  0.882371  0.062527  0.833156  0.118097  0.802401   \n",
       "38  0.826748  0.023434  0.861702  0.061062  0.822671  0.116611  0.810605   \n",
       "39  1.000000  0.028345  1.000000  0.070862  0.663273  0.094017  0.707969   \n",
       "40  0.813830  0.023068  0.837690  0.059361  0.823735  0.116761  0.821013   \n",
       "41  0.828267  0.023477  0.854407  0.060545  0.843945  0.119626  0.824508   \n",
       "42  0.857143  0.024296  0.858055  0.060804  0.841665  0.119303  0.822913   \n",
       "43  0.884498  0.025071  0.874164  0.061945  0.848807  0.120315  0.821165   \n",
       "44  0.869301  0.024640  0.857447  0.060761  0.844097  0.119648  0.818886   \n",
       "45  0.882979  0.025028  0.873252  0.061881  0.850327  0.120531  0.820862   \n",
       "46  0.869301  0.024640  0.847720  0.060072  0.843033  0.119497  0.819190   \n",
       "47  0.886778  0.025136  0.875988  0.062075  0.848655  0.120294  0.824356   \n",
       "48  0.876140  0.024834  0.861702  0.061062  0.844552  0.119712  0.820482   \n",
       "49  0.887538  0.025157  0.875684  0.062053  0.849567  0.120423  0.825876   \n",
       "50  1.000000  0.028345  0.758055  0.053718  0.879046  0.124602  0.874421   \n",
       "51  0.917933  0.026019  0.920669  0.065241  0.902143  0.127875  0.882170   \n",
       "52  0.910334  0.025803  0.908207  0.064358  0.890442  0.126217  0.864089   \n",
       "53  0.928571  0.026320  0.916109  0.064918  0.900015  0.127574  0.876396   \n",
       "54  1.000000  0.028345  0.770213  0.054579  0.885124  0.125463  0.870850   \n",
       "55  0.916413  0.025976  0.916413  0.064939  0.902446  0.127918  0.880802   \n",
       "56  0.920213  0.026083  0.905471  0.064164  0.891658  0.126389  0.866292   \n",
       "57  0.928571  0.026320  0.919757  0.065176  0.902446  0.127918  0.879207   \n",
       "58  0.892097  0.025286  0.871125  0.061730  0.852150  0.120789  0.827319   \n",
       "59  0.873860  0.024770  0.861094  0.061019  0.847288  0.120100  0.824128   \n",
       "60  0.860182  0.024382  0.858663  0.060847  0.845312  0.119820  0.824584   \n",
       "61  0.857903  0.024317  0.856535  0.060696  0.845616  0.119863  0.824356   \n",
       "62  0.854103  0.024210  0.857143  0.060739  0.843945  0.119626  0.823445   \n",
       "\n",
       "     r_at_20   p_at_30   r_at_30   p_at_50   r_at_50   auc-roc  \n",
       "0   0.226480  0.753102  0.320281  0.783494  0.555355  0.589707  \n",
       "1   0.233523  0.809268  0.344167  0.775016  0.549345  0.616552  \n",
       "2   0.233480  0.812459  0.345524  0.779088  0.552231  0.621434  \n",
       "3   0.233760  0.810382  0.344641  0.778693  0.551951  0.621850  \n",
       "4   0.233652  0.810332  0.344620  0.778571  0.551865  0.621629  \n",
       "5   0.233566  0.809927  0.344447  0.778632  0.551908  0.621587  \n",
       "6   0.233631  0.809977  0.344469  0.778693  0.551951  0.621588  \n",
       "7   0.233631  0.809876  0.344426  0.778632  0.551908  0.621575  \n",
       "8   0.200719  0.805318  0.342487  0.883193  0.626023  0.547378  \n",
       "9   0.200719  0.805318  0.342487  0.883193  0.626023  0.547378  \n",
       "10  0.228720  0.774424  0.329349  0.784102  0.555785  0.609611  \n",
       "11  0.228720  0.774424  0.329349  0.784102  0.555785  0.609611  \n",
       "12  0.232877  0.805622  0.342617  0.775715  0.549841  0.615923  \n",
       "13  0.232877  0.805622  0.342617  0.775563  0.549733  0.615698  \n",
       "14  0.184156  0.761712  0.323942  0.817223  0.579263  0.671708  \n",
       "15  0.191953  0.784705  0.333721  0.816646  0.578853  0.665784  \n",
       "16  0.189799  0.744340  0.316555  0.820870  0.581847  0.673102  \n",
       "17  0.185362  0.769207  0.327130  0.816616  0.578832  0.666648  \n",
       "18  0.200719  0.805318  0.342487  0.883193  0.626023  0.547378  \n",
       "19  0.200719  0.805318  0.342487  0.883193  0.626023  0.547378  \n",
       "20  0.227406  0.771486  0.328099  0.781245  0.553761  0.609104  \n",
       "21  0.227427  0.771537  0.328121  0.781276  0.553782  0.609113  \n",
       "22  0.235741  0.807242  0.343306  0.782248  0.554471  0.618732  \n",
       "23  0.235741  0.807242  0.343306  0.782370  0.554558  0.618663  \n",
       "24  0.185298  0.769055  0.327066  0.815977  0.578379  0.669600  \n",
       "25  0.194344  0.790327  0.336112  0.825610  0.585207  0.665806  \n",
       "26  0.188292  0.747784  0.318019  0.823240  0.583527  0.673119  \n",
       "27  0.186073  0.770879  0.327841  0.818044  0.579844  0.668566  \n",
       "28  0.226480  0.753102  0.320281  0.783494  0.555355  0.589707  \n",
       "29  0.233523  0.809268  0.344167  0.775016  0.549345  0.616552  \n",
       "..       ...       ...       ...       ...       ...       ...  \n",
       "33  0.233566  0.809927  0.344447  0.778632  0.551908  0.621587  \n",
       "34  0.233631  0.809977  0.344469  0.778693  0.551951  0.621592  \n",
       "35  0.233631  0.809876  0.344426  0.778632  0.551908  0.621575  \n",
       "36  0.200719  0.805318  0.342487  0.883193  0.626023  0.547378  \n",
       "37  0.227492  0.784806  0.333764  0.775988  0.550034  0.603155  \n",
       "38  0.229818  0.783236  0.333096  0.772038  0.547234  0.605013  \n",
       "39  0.200719  0.805318  0.342487  0.883193  0.626023  0.547378  \n",
       "40  0.232769  0.800608  0.340484  0.804309  0.570109  0.611839  \n",
       "41  0.233760  0.810889  0.344857  0.778541  0.551844  0.621480  \n",
       "42  0.233307  0.795948  0.338503  0.770367  0.546050  0.610254  \n",
       "43  0.232812  0.807850  0.343564  0.775016  0.549345  0.619022  \n",
       "44  0.232166  0.792049  0.336844  0.768483  0.544714  0.608049  \n",
       "45  0.232726  0.806635  0.343047  0.774742  0.549151  0.618268  \n",
       "46  0.232252  0.804963  0.342337  0.774165  0.548742  0.614670  \n",
       "47  0.233717  0.810129  0.344533  0.776718  0.550551  0.620370  \n",
       "48  0.232618  0.806584  0.343026  0.775381  0.549604  0.616112  \n",
       "49  0.234147  0.810737  0.344792  0.776718  0.550551  0.621013  \n",
       "50  0.247911  0.856774  0.364371  0.821234  0.582106  0.696353  \n",
       "51  0.250108  0.862801  0.366934  0.828618  0.587340  0.708737  \n",
       "52  0.244981  0.847151  0.360278  0.813151  0.576376  0.680287  \n",
       "53  0.248471  0.858192  0.364974  0.821660  0.582407  0.698212  \n",
       "54  0.246898  0.853330  0.362906  0.818803  0.580383  0.693699  \n",
       "55  0.249720  0.865333  0.368011  0.826370  0.585746  0.708881  \n",
       "56  0.245606  0.850393  0.361657  0.815339  0.577927  0.683563  \n",
       "57  0.249268  0.858850  0.365254  0.824395  0.584346  0.699476  \n",
       "58  0.234557  0.812965  0.345740  0.779483  0.552511  0.622657  \n",
       "59  0.233652  0.811750  0.345223  0.779057  0.552210  0.622564  \n",
       "60  0.233781  0.811800  0.345244  0.778936  0.552124  0.622345  \n",
       "61  0.233717  0.811750  0.345223  0.779027  0.552188  0.622329  \n",
       "62  0.233458  0.811193  0.344986  0.778480  0.551801  0.621743  \n",
       "\n",
       "[63 rows x 18 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"With second train set:\")\n",
    "pipeline.iterate_over_models(models_to_run, models, parameters_grid, x_train_2, x_test_2, y_train_2, y_test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With third train set (smalles one):\n",
      "Running LR...\n",
      "Running DT...\n",
      "Running LR...\n",
      "Running AB...\n",
      "Running RF...\n",
      "Running SVM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/felipe/.local/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>model</th>\n",
       "      <th>parameters</th>\n",
       "      <th>p_at_1</th>\n",
       "      <th>r_at_1</th>\n",
       "      <th>p_at_2</th>\n",
       "      <th>r_at_2</th>\n",
       "      <th>p_at_5</th>\n",
       "      <th>r_at_5</th>\n",
       "      <th>p_at_10</th>\n",
       "      <th>r_at_10</th>\n",
       "      <th>p_at_20</th>\n",
       "      <th>r_at_20</th>\n",
       "      <th>p_at_30</th>\n",
       "      <th>r_at_30</th>\n",
       "      <th>p_at_50</th>\n",
       "      <th>r_at_50</th>\n",
       "      <th>auc-roc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>{'C': 0.001, 'penalty': 'l1'}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013917</td>\n",
       "      <td>0.694881</td>\n",
       "      <td>0.019352</td>\n",
       "      <td>0.877989</td>\n",
       "      <td>0.061146</td>\n",
       "      <td>0.833401</td>\n",
       "      <td>0.116081</td>\n",
       "      <td>0.815211</td>\n",
       "      <td>0.227095</td>\n",
       "      <td>0.800939</td>\n",
       "      <td>0.334679</td>\n",
       "      <td>0.782331</td>\n",
       "      <td>0.544850</td>\n",
       "      <td>0.592306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>{'C': 0.001, 'penalty': 'l2'}</td>\n",
       "      <td>0.872211</td>\n",
       "      <td>0.012139</td>\n",
       "      <td>0.880892</td>\n",
       "      <td>0.024532</td>\n",
       "      <td>0.875963</td>\n",
       "      <td>0.061005</td>\n",
       "      <td>0.857925</td>\n",
       "      <td>0.119497</td>\n",
       "      <td>0.832489</td>\n",
       "      <td>0.231908</td>\n",
       "      <td>0.819247</td>\n",
       "      <td>0.342329</td>\n",
       "      <td>0.788553</td>\n",
       "      <td>0.549183</td>\n",
       "      <td>0.618635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'l1'}</td>\n",
       "      <td>0.864097</td>\n",
       "      <td>0.012026</td>\n",
       "      <td>0.866700</td>\n",
       "      <td>0.024137</td>\n",
       "      <td>0.872112</td>\n",
       "      <td>0.060737</td>\n",
       "      <td>0.858533</td>\n",
       "      <td>0.119582</td>\n",
       "      <td>0.837606</td>\n",
       "      <td>0.233334</td>\n",
       "      <td>0.823368</td>\n",
       "      <td>0.344051</td>\n",
       "      <td>0.791573</td>\n",
       "      <td>0.551287</td>\n",
       "      <td>0.624384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'l2'}</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.012280</td>\n",
       "      <td>0.872783</td>\n",
       "      <td>0.024306</td>\n",
       "      <td>0.871301</td>\n",
       "      <td>0.060680</td>\n",
       "      <td>0.859141</td>\n",
       "      <td>0.119666</td>\n",
       "      <td>0.838316</td>\n",
       "      <td>0.233531</td>\n",
       "      <td>0.823706</td>\n",
       "      <td>0.344192</td>\n",
       "      <td>0.791999</td>\n",
       "      <td>0.551583</td>\n",
       "      <td>0.625046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>{'C': 1, 'penalty': 'l1'}</td>\n",
       "      <td>0.834686</td>\n",
       "      <td>0.011617</td>\n",
       "      <td>0.855043</td>\n",
       "      <td>0.023812</td>\n",
       "      <td>0.869274</td>\n",
       "      <td>0.060539</td>\n",
       "      <td>0.858330</td>\n",
       "      <td>0.119553</td>\n",
       "      <td>0.838164</td>\n",
       "      <td>0.233489</td>\n",
       "      <td>0.823368</td>\n",
       "      <td>0.344051</td>\n",
       "      <td>0.791695</td>\n",
       "      <td>0.551371</td>\n",
       "      <td>0.624894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>{'C': 1, 'penalty': 'l2'}</td>\n",
       "      <td>0.839757</td>\n",
       "      <td>0.011687</td>\n",
       "      <td>0.856057</td>\n",
       "      <td>0.023840</td>\n",
       "      <td>0.868869</td>\n",
       "      <td>0.060511</td>\n",
       "      <td>0.857925</td>\n",
       "      <td>0.119497</td>\n",
       "      <td>0.837809</td>\n",
       "      <td>0.233390</td>\n",
       "      <td>0.823402</td>\n",
       "      <td>0.344065</td>\n",
       "      <td>0.791289</td>\n",
       "      <td>0.551089</td>\n",
       "      <td>0.624866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>{'C': 10, 'penalty': 'l1'}</td>\n",
       "      <td>0.830629</td>\n",
       "      <td>0.011560</td>\n",
       "      <td>0.854536</td>\n",
       "      <td>0.023798</td>\n",
       "      <td>0.869072</td>\n",
       "      <td>0.060525</td>\n",
       "      <td>0.858026</td>\n",
       "      <td>0.119511</td>\n",
       "      <td>0.838062</td>\n",
       "      <td>0.233461</td>\n",
       "      <td>0.823335</td>\n",
       "      <td>0.344037</td>\n",
       "      <td>0.791451</td>\n",
       "      <td>0.551202</td>\n",
       "      <td>0.624867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>{'C': 10, 'penalty': 'l2'}</td>\n",
       "      <td>0.833671</td>\n",
       "      <td>0.011602</td>\n",
       "      <td>0.855043</td>\n",
       "      <td>0.023812</td>\n",
       "      <td>0.868869</td>\n",
       "      <td>0.060511</td>\n",
       "      <td>0.857722</td>\n",
       "      <td>0.119469</td>\n",
       "      <td>0.837961</td>\n",
       "      <td>0.233433</td>\n",
       "      <td>0.823368</td>\n",
       "      <td>0.344051</td>\n",
       "      <td>0.791411</td>\n",
       "      <td>0.551174</td>\n",
       "      <td>0.624857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 1, 'min_sam...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013917</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.027849</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.069643</td>\n",
       "      <td>0.711796</td>\n",
       "      <td>0.099143</td>\n",
       "      <td>0.701409</td>\n",
       "      <td>0.195393</td>\n",
       "      <td>0.800939</td>\n",
       "      <td>0.334679</td>\n",
       "      <td>0.880566</td>\n",
       "      <td>0.613265</td>\n",
       "      <td>0.550781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 1, 'min_sam...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013917</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.027849</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.069643</td>\n",
       "      <td>0.711796</td>\n",
       "      <td>0.099143</td>\n",
       "      <td>0.701409</td>\n",
       "      <td>0.195393</td>\n",
       "      <td>0.800939</td>\n",
       "      <td>0.334679</td>\n",
       "      <td>0.880566</td>\n",
       "      <td>0.613265</td>\n",
       "      <td>0.550781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'min_sam...</td>\n",
       "      <td>0.887424</td>\n",
       "      <td>0.012351</td>\n",
       "      <td>0.811455</td>\n",
       "      <td>0.022598</td>\n",
       "      <td>0.837657</td>\n",
       "      <td>0.058337</td>\n",
       "      <td>0.787191</td>\n",
       "      <td>0.109645</td>\n",
       "      <td>0.799301</td>\n",
       "      <td>0.222663</td>\n",
       "      <td>0.769524</td>\n",
       "      <td>0.321552</td>\n",
       "      <td>0.783993</td>\n",
       "      <td>0.546008</td>\n",
       "      <td>0.610375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'min_sam...</td>\n",
       "      <td>0.887424</td>\n",
       "      <td>0.012351</td>\n",
       "      <td>0.811455</td>\n",
       "      <td>0.022598</td>\n",
       "      <td>0.837657</td>\n",
       "      <td>0.058337</td>\n",
       "      <td>0.787191</td>\n",
       "      <td>0.109645</td>\n",
       "      <td>0.799301</td>\n",
       "      <td>0.222663</td>\n",
       "      <td>0.769524</td>\n",
       "      <td>0.321552</td>\n",
       "      <td>0.783993</td>\n",
       "      <td>0.546008</td>\n",
       "      <td>0.610375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 10, 'min_sa...</td>\n",
       "      <td>0.781947</td>\n",
       "      <td>0.010883</td>\n",
       "      <td>0.871769</td>\n",
       "      <td>0.024278</td>\n",
       "      <td>0.877989</td>\n",
       "      <td>0.061146</td>\n",
       "      <td>0.847994</td>\n",
       "      <td>0.118114</td>\n",
       "      <td>0.830563</td>\n",
       "      <td>0.231372</td>\n",
       "      <td>0.823808</td>\n",
       "      <td>0.344235</td>\n",
       "      <td>0.792546</td>\n",
       "      <td>0.551964</td>\n",
       "      <td>0.626015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 10, 'min_sa...</td>\n",
       "      <td>0.790061</td>\n",
       "      <td>0.010996</td>\n",
       "      <td>0.872276</td>\n",
       "      <td>0.024292</td>\n",
       "      <td>0.875557</td>\n",
       "      <td>0.060976</td>\n",
       "      <td>0.847791</td>\n",
       "      <td>0.118085</td>\n",
       "      <td>0.829905</td>\n",
       "      <td>0.231188</td>\n",
       "      <td>0.823639</td>\n",
       "      <td>0.344164</td>\n",
       "      <td>0.792323</td>\n",
       "      <td>0.551809</td>\n",
       "      <td>0.625719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 50, 'min_sa...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013917</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.027849</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.069643</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.139286</td>\n",
       "      <td>0.761603</td>\n",
       "      <td>0.212161</td>\n",
       "      <td>0.841069</td>\n",
       "      <td>0.351447</td>\n",
       "      <td>0.869277</td>\n",
       "      <td>0.605403</td>\n",
       "      <td>0.745723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 50, 'min_sa...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013917</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.027849</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.069643</td>\n",
       "      <td>0.910113</td>\n",
       "      <td>0.126766</td>\n",
       "      <td>0.784607</td>\n",
       "      <td>0.218570</td>\n",
       "      <td>0.856405</td>\n",
       "      <td>0.357856</td>\n",
       "      <td>0.863319</td>\n",
       "      <td>0.601253</td>\n",
       "      <td>0.734040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 100, 'min_s...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013917</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.027849</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.069643</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.139286</td>\n",
       "      <td>0.744224</td>\n",
       "      <td>0.207320</td>\n",
       "      <td>0.829483</td>\n",
       "      <td>0.346606</td>\n",
       "      <td>0.874040</td>\n",
       "      <td>0.608720</td>\n",
       "      <td>0.748978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 100, 'min_s...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013917</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.027849</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.069643</td>\n",
       "      <td>0.962910</td>\n",
       "      <td>0.134120</td>\n",
       "      <td>0.769102</td>\n",
       "      <td>0.214250</td>\n",
       "      <td>0.846068</td>\n",
       "      <td>0.353536</td>\n",
       "      <td>0.865224</td>\n",
       "      <td>0.602580</td>\n",
       "      <td>0.736847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 1, 'min_...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013917</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.027849</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.069643</td>\n",
       "      <td>0.711796</td>\n",
       "      <td>0.099143</td>\n",
       "      <td>0.701409</td>\n",
       "      <td>0.195393</td>\n",
       "      <td>0.800939</td>\n",
       "      <td>0.334679</td>\n",
       "      <td>0.880566</td>\n",
       "      <td>0.613265</td>\n",
       "      <td>0.550781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 1, 'min_...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013917</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.027849</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.069643</td>\n",
       "      <td>0.711796</td>\n",
       "      <td>0.099143</td>\n",
       "      <td>0.701409</td>\n",
       "      <td>0.195393</td>\n",
       "      <td>0.800939</td>\n",
       "      <td>0.334679</td>\n",
       "      <td>0.880566</td>\n",
       "      <td>0.613265</td>\n",
       "      <td>0.550781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'min_...</td>\n",
       "      <td>0.834686</td>\n",
       "      <td>0.011617</td>\n",
       "      <td>0.783578</td>\n",
       "      <td>0.021822</td>\n",
       "      <td>0.878192</td>\n",
       "      <td>0.061160</td>\n",
       "      <td>0.807458</td>\n",
       "      <td>0.112468</td>\n",
       "      <td>0.810752</td>\n",
       "      <td>0.225853</td>\n",
       "      <td>0.767261</td>\n",
       "      <td>0.320606</td>\n",
       "      <td>0.782027</td>\n",
       "      <td>0.544638</td>\n",
       "      <td>0.609640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'min_...</td>\n",
       "      <td>0.834686</td>\n",
       "      <td>0.011617</td>\n",
       "      <td>0.782565</td>\n",
       "      <td>0.021793</td>\n",
       "      <td>0.878395</td>\n",
       "      <td>0.061174</td>\n",
       "      <td>0.807560</td>\n",
       "      <td>0.112482</td>\n",
       "      <td>0.810651</td>\n",
       "      <td>0.225825</td>\n",
       "      <td>0.767295</td>\n",
       "      <td>0.320620</td>\n",
       "      <td>0.781987</td>\n",
       "      <td>0.544610</td>\n",
       "      <td>0.609648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 10, 'min...</td>\n",
       "      <td>0.758621</td>\n",
       "      <td>0.010558</td>\n",
       "      <td>0.879372</td>\n",
       "      <td>0.024489</td>\n",
       "      <td>0.884070</td>\n",
       "      <td>0.061569</td>\n",
       "      <td>0.858127</td>\n",
       "      <td>0.119525</td>\n",
       "      <td>0.842623</td>\n",
       "      <td>0.234731</td>\n",
       "      <td>0.823166</td>\n",
       "      <td>0.343967</td>\n",
       "      <td>0.794917</td>\n",
       "      <td>0.553616</td>\n",
       "      <td>0.625778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 10, 'min...</td>\n",
       "      <td>0.755578</td>\n",
       "      <td>0.010516</td>\n",
       "      <td>0.877851</td>\n",
       "      <td>0.024447</td>\n",
       "      <td>0.883462</td>\n",
       "      <td>0.061527</td>\n",
       "      <td>0.857823</td>\n",
       "      <td>0.119483</td>\n",
       "      <td>0.842673</td>\n",
       "      <td>0.234745</td>\n",
       "      <td>0.822828</td>\n",
       "      <td>0.343825</td>\n",
       "      <td>0.794795</td>\n",
       "      <td>0.553531</td>\n",
       "      <td>0.625747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 50, 'min...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013917</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.027849</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.069643</td>\n",
       "      <td>0.976794</td>\n",
       "      <td>0.136054</td>\n",
       "      <td>0.768950</td>\n",
       "      <td>0.214208</td>\n",
       "      <td>0.845967</td>\n",
       "      <td>0.353494</td>\n",
       "      <td>0.867777</td>\n",
       "      <td>0.604359</td>\n",
       "      <td>0.742237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 50, 'min...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013917</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.027849</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.069643</td>\n",
       "      <td>0.900385</td>\n",
       "      <td>0.125411</td>\n",
       "      <td>0.790231</td>\n",
       "      <td>0.220136</td>\n",
       "      <td>0.860154</td>\n",
       "      <td>0.359422</td>\n",
       "      <td>0.870067</td>\n",
       "      <td>0.605954</td>\n",
       "      <td>0.733306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 100, 'mi...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013917</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.027849</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.069643</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.139286</td>\n",
       "      <td>0.747669</td>\n",
       "      <td>0.208280</td>\n",
       "      <td>0.831779</td>\n",
       "      <td>0.347566</td>\n",
       "      <td>0.875621</td>\n",
       "      <td>0.609821</td>\n",
       "      <td>0.749111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 100, 'mi...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013917</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.027849</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.069643</td>\n",
       "      <td>0.969193</td>\n",
       "      <td>0.134995</td>\n",
       "      <td>0.770774</td>\n",
       "      <td>0.214716</td>\n",
       "      <td>0.847183</td>\n",
       "      <td>0.354002</td>\n",
       "      <td>0.866825</td>\n",
       "      <td>0.603695</td>\n",
       "      <td>0.739574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>{'C': 0.001, 'penalty': 'l1'}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013917</td>\n",
       "      <td>0.694881</td>\n",
       "      <td>0.019352</td>\n",
       "      <td>0.877989</td>\n",
       "      <td>0.061146</td>\n",
       "      <td>0.833401</td>\n",
       "      <td>0.116081</td>\n",
       "      <td>0.815211</td>\n",
       "      <td>0.227095</td>\n",
       "      <td>0.800939</td>\n",
       "      <td>0.334679</td>\n",
       "      <td>0.782331</td>\n",
       "      <td>0.544850</td>\n",
       "      <td>0.592306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>{'C': 0.001, 'penalty': 'l2'}</td>\n",
       "      <td>0.872211</td>\n",
       "      <td>0.012139</td>\n",
       "      <td>0.880892</td>\n",
       "      <td>0.024532</td>\n",
       "      <td>0.875963</td>\n",
       "      <td>0.061005</td>\n",
       "      <td>0.857925</td>\n",
       "      <td>0.119497</td>\n",
       "      <td>0.832489</td>\n",
       "      <td>0.231908</td>\n",
       "      <td>0.819247</td>\n",
       "      <td>0.342329</td>\n",
       "      <td>0.788553</td>\n",
       "      <td>0.549183</td>\n",
       "      <td>0.618635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>{'C': 1, 'penalty': 'l2'}</td>\n",
       "      <td>0.839757</td>\n",
       "      <td>0.011687</td>\n",
       "      <td>0.856057</td>\n",
       "      <td>0.023840</td>\n",
       "      <td>0.868869</td>\n",
       "      <td>0.060511</td>\n",
       "      <td>0.857925</td>\n",
       "      <td>0.119497</td>\n",
       "      <td>0.837809</td>\n",
       "      <td>0.233390</td>\n",
       "      <td>0.823402</td>\n",
       "      <td>0.344065</td>\n",
       "      <td>0.791289</td>\n",
       "      <td>0.551089</td>\n",
       "      <td>0.624866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>{'C': 10, 'penalty': 'l1'}</td>\n",
       "      <td>0.830629</td>\n",
       "      <td>0.011560</td>\n",
       "      <td>0.854536</td>\n",
       "      <td>0.023798</td>\n",
       "      <td>0.869072</td>\n",
       "      <td>0.060525</td>\n",
       "      <td>0.858026</td>\n",
       "      <td>0.119511</td>\n",
       "      <td>0.838012</td>\n",
       "      <td>0.233447</td>\n",
       "      <td>0.823301</td>\n",
       "      <td>0.344023</td>\n",
       "      <td>0.791431</td>\n",
       "      <td>0.551188</td>\n",
       "      <td>0.624868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>{'C': 10, 'penalty': 'l2'}</td>\n",
       "      <td>0.833671</td>\n",
       "      <td>0.011602</td>\n",
       "      <td>0.855043</td>\n",
       "      <td>0.023812</td>\n",
       "      <td>0.868869</td>\n",
       "      <td>0.060511</td>\n",
       "      <td>0.857722</td>\n",
       "      <td>0.119469</td>\n",
       "      <td>0.837961</td>\n",
       "      <td>0.233433</td>\n",
       "      <td>0.823368</td>\n",
       "      <td>0.344051</td>\n",
       "      <td>0.791411</td>\n",
       "      <td>0.551174</td>\n",
       "      <td>0.624857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>AB</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'algorithm': 'SAMME', 'n_estimators': 1}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013917</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.027849</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.069643</td>\n",
       "      <td>0.711796</td>\n",
       "      <td>0.099143</td>\n",
       "      <td>0.701409</td>\n",
       "      <td>0.195393</td>\n",
       "      <td>0.800939</td>\n",
       "      <td>0.334679</td>\n",
       "      <td>0.880566</td>\n",
       "      <td>0.613265</td>\n",
       "      <td>0.550781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>AB</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'algorithm': 'SAMME', 'n_estimators': 10}</td>\n",
       "      <td>0.808316</td>\n",
       "      <td>0.011250</td>\n",
       "      <td>0.874303</td>\n",
       "      <td>0.024348</td>\n",
       "      <td>0.897244</td>\n",
       "      <td>0.062487</td>\n",
       "      <td>0.826915</td>\n",
       "      <td>0.115178</td>\n",
       "      <td>0.817896</td>\n",
       "      <td>0.227843</td>\n",
       "      <td>0.793812</td>\n",
       "      <td>0.331701</td>\n",
       "      <td>0.797937</td>\n",
       "      <td>0.555719</td>\n",
       "      <td>0.603653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>AB</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'algorithm': 'SAMME', 'n_estimators': 100}</td>\n",
       "      <td>0.826572</td>\n",
       "      <td>0.011504</td>\n",
       "      <td>0.842879</td>\n",
       "      <td>0.023473</td>\n",
       "      <td>0.866234</td>\n",
       "      <td>0.060327</td>\n",
       "      <td>0.847385</td>\n",
       "      <td>0.118029</td>\n",
       "      <td>0.820582</td>\n",
       "      <td>0.228591</td>\n",
       "      <td>0.791177</td>\n",
       "      <td>0.330600</td>\n",
       "      <td>0.784783</td>\n",
       "      <td>0.546558</td>\n",
       "      <td>0.606189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>AB</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'algorithm': 'SAMME.R', 'n_estimators': 1}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013917</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.027849</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.069643</td>\n",
       "      <td>0.711796</td>\n",
       "      <td>0.099143</td>\n",
       "      <td>0.701409</td>\n",
       "      <td>0.195393</td>\n",
       "      <td>0.800939</td>\n",
       "      <td>0.334679</td>\n",
       "      <td>0.880566</td>\n",
       "      <td>0.613265</td>\n",
       "      <td>0.550781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>AB</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'algorithm': 'SAMME.R', 'n_estimators': 10}</td>\n",
       "      <td>0.824544</td>\n",
       "      <td>0.011475</td>\n",
       "      <td>0.829194</td>\n",
       "      <td>0.023092</td>\n",
       "      <td>0.847588</td>\n",
       "      <td>0.059029</td>\n",
       "      <td>0.835124</td>\n",
       "      <td>0.116321</td>\n",
       "      <td>0.825750</td>\n",
       "      <td>0.230031</td>\n",
       "      <td>0.812492</td>\n",
       "      <td>0.339506</td>\n",
       "      <td>0.803976</td>\n",
       "      <td>0.559925</td>\n",
       "      <td>0.612352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>AB</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'algorithm': 'SAMME.R', 'n_estimators': 100}</td>\n",
       "      <td>0.831643</td>\n",
       "      <td>0.011574</td>\n",
       "      <td>0.855550</td>\n",
       "      <td>0.023826</td>\n",
       "      <td>0.870288</td>\n",
       "      <td>0.060609</td>\n",
       "      <td>0.859141</td>\n",
       "      <td>0.119666</td>\n",
       "      <td>0.838265</td>\n",
       "      <td>0.233517</td>\n",
       "      <td>0.823706</td>\n",
       "      <td>0.344192</td>\n",
       "      <td>0.792080</td>\n",
       "      <td>0.551639</td>\n",
       "      <td>0.624863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 'sqrt', 'min_...</td>\n",
       "      <td>0.892495</td>\n",
       "      <td>0.012421</td>\n",
       "      <td>0.884440</td>\n",
       "      <td>0.024631</td>\n",
       "      <td>0.867653</td>\n",
       "      <td>0.060426</td>\n",
       "      <td>0.857013</td>\n",
       "      <td>0.119370</td>\n",
       "      <td>0.831982</td>\n",
       "      <td>0.231767</td>\n",
       "      <td>0.807898</td>\n",
       "      <td>0.337587</td>\n",
       "      <td>0.782392</td>\n",
       "      <td>0.544893</td>\n",
       "      <td>0.611993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 'sqrt', 'min_...</td>\n",
       "      <td>0.909736</td>\n",
       "      <td>0.012661</td>\n",
       "      <td>0.888495</td>\n",
       "      <td>0.024743</td>\n",
       "      <td>0.884272</td>\n",
       "      <td>0.061583</td>\n",
       "      <td>0.864613</td>\n",
       "      <td>0.120429</td>\n",
       "      <td>0.832286</td>\n",
       "      <td>0.231852</td>\n",
       "      <td>0.820801</td>\n",
       "      <td>0.342979</td>\n",
       "      <td>0.787945</td>\n",
       "      <td>0.548760</td>\n",
       "      <td>0.621082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 'sqrt', 'min_...</td>\n",
       "      <td>0.911765</td>\n",
       "      <td>0.012689</td>\n",
       "      <td>0.895590</td>\n",
       "      <td>0.024941</td>\n",
       "      <td>0.872923</td>\n",
       "      <td>0.060793</td>\n",
       "      <td>0.859242</td>\n",
       "      <td>0.119680</td>\n",
       "      <td>0.828739</td>\n",
       "      <td>0.230864</td>\n",
       "      <td>0.804114</td>\n",
       "      <td>0.336006</td>\n",
       "      <td>0.781541</td>\n",
       "      <td>0.544300</td>\n",
       "      <td>0.610145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 'sqrt', 'min_...</td>\n",
       "      <td>0.905680</td>\n",
       "      <td>0.012605</td>\n",
       "      <td>0.889002</td>\n",
       "      <td>0.024758</td>\n",
       "      <td>0.886299</td>\n",
       "      <td>0.061725</td>\n",
       "      <td>0.864208</td>\n",
       "      <td>0.120372</td>\n",
       "      <td>0.831779</td>\n",
       "      <td>0.231711</td>\n",
       "      <td>0.819112</td>\n",
       "      <td>0.342273</td>\n",
       "      <td>0.787520</td>\n",
       "      <td>0.548464</td>\n",
       "      <td>0.620299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 'log2', 'min_...</td>\n",
       "      <td>0.889452</td>\n",
       "      <td>0.012379</td>\n",
       "      <td>0.878865</td>\n",
       "      <td>0.024475</td>\n",
       "      <td>0.867248</td>\n",
       "      <td>0.060398</td>\n",
       "      <td>0.856810</td>\n",
       "      <td>0.119342</td>\n",
       "      <td>0.830310</td>\n",
       "      <td>0.231301</td>\n",
       "      <td>0.818200</td>\n",
       "      <td>0.341892</td>\n",
       "      <td>0.786324</td>\n",
       "      <td>0.547631</td>\n",
       "      <td>0.616561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 'log2', 'min_...</td>\n",
       "      <td>0.894523</td>\n",
       "      <td>0.012449</td>\n",
       "      <td>0.894577</td>\n",
       "      <td>0.024913</td>\n",
       "      <td>0.883259</td>\n",
       "      <td>0.061513</td>\n",
       "      <td>0.861674</td>\n",
       "      <td>0.120019</td>\n",
       "      <td>0.836137</td>\n",
       "      <td>0.232924</td>\n",
       "      <td>0.822524</td>\n",
       "      <td>0.343698</td>\n",
       "      <td>0.789019</td>\n",
       "      <td>0.549508</td>\n",
       "      <td>0.622608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 'log2', 'min_...</td>\n",
       "      <td>0.895538</td>\n",
       "      <td>0.012463</td>\n",
       "      <td>0.881399</td>\n",
       "      <td>0.024546</td>\n",
       "      <td>0.875557</td>\n",
       "      <td>0.060976</td>\n",
       "      <td>0.855188</td>\n",
       "      <td>0.119116</td>\n",
       "      <td>0.830006</td>\n",
       "      <td>0.231217</td>\n",
       "      <td>0.819112</td>\n",
       "      <td>0.342273</td>\n",
       "      <td>0.787418</td>\n",
       "      <td>0.548393</td>\n",
       "      <td>0.617727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 'log2', 'min_...</td>\n",
       "      <td>0.897566</td>\n",
       "      <td>0.012492</td>\n",
       "      <td>0.891536</td>\n",
       "      <td>0.024828</td>\n",
       "      <td>0.881638</td>\n",
       "      <td>0.061400</td>\n",
       "      <td>0.863498</td>\n",
       "      <td>0.120273</td>\n",
       "      <td>0.836796</td>\n",
       "      <td>0.233108</td>\n",
       "      <td>0.823909</td>\n",
       "      <td>0.344277</td>\n",
       "      <td>0.789810</td>\n",
       "      <td>0.550059</td>\n",
       "      <td>0.623095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 50, 'max_features': 'sqrt', 'min...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013917</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.027849</td>\n",
       "      <td>0.838670</td>\n",
       "      <td>0.058408</td>\n",
       "      <td>0.919335</td>\n",
       "      <td>0.128051</td>\n",
       "      <td>0.925618</td>\n",
       "      <td>0.257851</td>\n",
       "      <td>0.911127</td>\n",
       "      <td>0.380722</td>\n",
       "      <td>0.871770</td>\n",
       "      <td>0.607139</td>\n",
       "      <td>0.764817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 50, 'max_features': 'sqrt', 'min...</td>\n",
       "      <td>0.952333</td>\n",
       "      <td>0.013254</td>\n",
       "      <td>0.954384</td>\n",
       "      <td>0.026578</td>\n",
       "      <td>0.954601</td>\n",
       "      <td>0.066481</td>\n",
       "      <td>0.949027</td>\n",
       "      <td>0.132186</td>\n",
       "      <td>0.933877</td>\n",
       "      <td>0.260152</td>\n",
       "      <td>0.918322</td>\n",
       "      <td>0.383728</td>\n",
       "      <td>0.880627</td>\n",
       "      <td>0.613308</td>\n",
       "      <td>0.779924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 50, 'max_features': 'sqrt', 'min...</td>\n",
       "      <td>0.953347</td>\n",
       "      <td>0.013268</td>\n",
       "      <td>0.945261</td>\n",
       "      <td>0.026324</td>\n",
       "      <td>0.943859</td>\n",
       "      <td>0.065733</td>\n",
       "      <td>0.932509</td>\n",
       "      <td>0.129886</td>\n",
       "      <td>0.911532</td>\n",
       "      <td>0.253927</td>\n",
       "      <td>0.894643</td>\n",
       "      <td>0.373834</td>\n",
       "      <td>0.854219</td>\n",
       "      <td>0.594916</td>\n",
       "      <td>0.733735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 50, 'max_features': 'sqrt', 'min...</td>\n",
       "      <td>0.959432</td>\n",
       "      <td>0.013353</td>\n",
       "      <td>0.955398</td>\n",
       "      <td>0.026607</td>\n",
       "      <td>0.949737</td>\n",
       "      <td>0.066143</td>\n",
       "      <td>0.940717</td>\n",
       "      <td>0.131029</td>\n",
       "      <td>0.919437</td>\n",
       "      <td>0.256129</td>\n",
       "      <td>0.903831</td>\n",
       "      <td>0.377673</td>\n",
       "      <td>0.866602</td>\n",
       "      <td>0.603540</td>\n",
       "      <td>0.754929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 50, 'max_features': 'log2', 'min...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013917</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.027849</td>\n",
       "      <td>0.846777</td>\n",
       "      <td>0.058972</td>\n",
       "      <td>0.923389</td>\n",
       "      <td>0.128615</td>\n",
       "      <td>0.925517</td>\n",
       "      <td>0.257823</td>\n",
       "      <td>0.910147</td>\n",
       "      <td>0.380313</td>\n",
       "      <td>0.870898</td>\n",
       "      <td>0.606532</td>\n",
       "      <td>0.763718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 50, 'max_features': 'log2', 'min...</td>\n",
       "      <td>0.968560</td>\n",
       "      <td>0.013480</td>\n",
       "      <td>0.953371</td>\n",
       "      <td>0.026550</td>\n",
       "      <td>0.952979</td>\n",
       "      <td>0.066368</td>\n",
       "      <td>0.947102</td>\n",
       "      <td>0.131918</td>\n",
       "      <td>0.936056</td>\n",
       "      <td>0.260759</td>\n",
       "      <td>0.920754</td>\n",
       "      <td>0.384745</td>\n",
       "      <td>0.879654</td>\n",
       "      <td>0.612630</td>\n",
       "      <td>0.780529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 50, 'max_features': 'log2', 'min...</td>\n",
       "      <td>0.954361</td>\n",
       "      <td>0.013282</td>\n",
       "      <td>0.953877</td>\n",
       "      <td>0.026564</td>\n",
       "      <td>0.942440</td>\n",
       "      <td>0.065634</td>\n",
       "      <td>0.931901</td>\n",
       "      <td>0.129801</td>\n",
       "      <td>0.911735</td>\n",
       "      <td>0.253984</td>\n",
       "      <td>0.894541</td>\n",
       "      <td>0.373791</td>\n",
       "      <td>0.855191</td>\n",
       "      <td>0.595593</td>\n",
       "      <td>0.734312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 50, 'max_features': 'log2', 'min...</td>\n",
       "      <td>0.958418</td>\n",
       "      <td>0.013339</td>\n",
       "      <td>0.956918</td>\n",
       "      <td>0.026649</td>\n",
       "      <td>0.951155</td>\n",
       "      <td>0.066241</td>\n",
       "      <td>0.940312</td>\n",
       "      <td>0.130972</td>\n",
       "      <td>0.922173</td>\n",
       "      <td>0.256892</td>\n",
       "      <td>0.903223</td>\n",
       "      <td>0.377419</td>\n",
       "      <td>0.867473</td>\n",
       "      <td>0.604147</td>\n",
       "      <td>0.755189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>SVM</td>\n",
       "      <td>LinearSVC(C=10, class_weight=None, dual=True, ...</td>\n",
       "      <td>{'C': 0.001}</td>\n",
       "      <td>0.891481</td>\n",
       "      <td>0.012407</td>\n",
       "      <td>0.892043</td>\n",
       "      <td>0.024842</td>\n",
       "      <td>0.880219</td>\n",
       "      <td>0.061301</td>\n",
       "      <td>0.863296</td>\n",
       "      <td>0.120245</td>\n",
       "      <td>0.839380</td>\n",
       "      <td>0.233828</td>\n",
       "      <td>0.823571</td>\n",
       "      <td>0.344136</td>\n",
       "      <td>0.791999</td>\n",
       "      <td>0.551583</td>\n",
       "      <td>0.625333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>SVM</td>\n",
       "      <td>LinearSVC(C=10, class_weight=None, dual=True, ...</td>\n",
       "      <td>{'C': 0.01}</td>\n",
       "      <td>0.885396</td>\n",
       "      <td>0.012322</td>\n",
       "      <td>0.887988</td>\n",
       "      <td>0.024729</td>\n",
       "      <td>0.876571</td>\n",
       "      <td>0.061047</td>\n",
       "      <td>0.860053</td>\n",
       "      <td>0.119793</td>\n",
       "      <td>0.838670</td>\n",
       "      <td>0.233630</td>\n",
       "      <td>0.824078</td>\n",
       "      <td>0.344348</td>\n",
       "      <td>0.791897</td>\n",
       "      <td>0.551512</td>\n",
       "      <td>0.625729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>SVM</td>\n",
       "      <td>LinearSVC(C=10, class_weight=None, dual=True, ...</td>\n",
       "      <td>{'C': 0.1}</td>\n",
       "      <td>0.880325</td>\n",
       "      <td>0.012252</td>\n",
       "      <td>0.880385</td>\n",
       "      <td>0.024518</td>\n",
       "      <td>0.872720</td>\n",
       "      <td>0.060779</td>\n",
       "      <td>0.858938</td>\n",
       "      <td>0.119638</td>\n",
       "      <td>0.837708</td>\n",
       "      <td>0.233362</td>\n",
       "      <td>0.823639</td>\n",
       "      <td>0.344164</td>\n",
       "      <td>0.792140</td>\n",
       "      <td>0.551682</td>\n",
       "      <td>0.625592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>SVM</td>\n",
       "      <td>LinearSVC(C=10, class_weight=None, dual=True, ...</td>\n",
       "      <td>{'C': 1}</td>\n",
       "      <td>0.884381</td>\n",
       "      <td>0.012308</td>\n",
       "      <td>0.877851</td>\n",
       "      <td>0.024447</td>\n",
       "      <td>0.872112</td>\n",
       "      <td>0.060737</td>\n",
       "      <td>0.859141</td>\n",
       "      <td>0.119666</td>\n",
       "      <td>0.837708</td>\n",
       "      <td>0.233362</td>\n",
       "      <td>0.823706</td>\n",
       "      <td>0.344192</td>\n",
       "      <td>0.791978</td>\n",
       "      <td>0.551569</td>\n",
       "      <td>0.625581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>SVM</td>\n",
       "      <td>LinearSVC(C=10, class_weight=None, dual=True, ...</td>\n",
       "      <td>{'C': 10}</td>\n",
       "      <td>0.884381</td>\n",
       "      <td>0.012308</td>\n",
       "      <td>0.875824</td>\n",
       "      <td>0.024391</td>\n",
       "      <td>0.875557</td>\n",
       "      <td>0.060976</td>\n",
       "      <td>0.857722</td>\n",
       "      <td>0.119469</td>\n",
       "      <td>0.837404</td>\n",
       "      <td>0.233277</td>\n",
       "      <td>0.823672</td>\n",
       "      <td>0.344178</td>\n",
       "      <td>0.791613</td>\n",
       "      <td>0.551315</td>\n",
       "      <td>0.625121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63 rows  18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   model_name                                              model  \\\n",
       "0          LR  LogisticRegression(C=10, class_weight=None, du...   \n",
       "1          LR  LogisticRegression(C=10, class_weight=None, du...   \n",
       "2          LR  LogisticRegression(C=10, class_weight=None, du...   \n",
       "3          LR  LogisticRegression(C=10, class_weight=None, du...   \n",
       "4          LR  LogisticRegression(C=10, class_weight=None, du...   \n",
       "5          LR  LogisticRegression(C=10, class_weight=None, du...   \n",
       "6          LR  LogisticRegression(C=10, class_weight=None, du...   \n",
       "7          LR  LogisticRegression(C=10, class_weight=None, du...   \n",
       "8          DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "9          DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "10         DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "11         DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "12         DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "13         DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "14         DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "15         DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "16         DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "17         DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "18         DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "19         DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "20         DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "21         DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "22         DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "23         DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "24         DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "25         DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "26         DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "27         DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "28         LR  LogisticRegression(C=10, class_weight=None, du...   \n",
       "29         LR  LogisticRegression(C=10, class_weight=None, du...   \n",
       "..        ...                                                ...   \n",
       "33         LR  LogisticRegression(C=10, class_weight=None, du...   \n",
       "34         LR  LogisticRegression(C=10, class_weight=None, du...   \n",
       "35         LR  LogisticRegression(C=10, class_weight=None, du...   \n",
       "36         AB  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "37         AB  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "38         AB  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "39         AB  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "40         AB  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "41         AB  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "42         RF  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "43         RF  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "44         RF  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "45         RF  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "46         RF  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "47         RF  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "48         RF  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "49         RF  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "50         RF  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "51         RF  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "52         RF  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "53         RF  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "54         RF  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "55         RF  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "56         RF  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "57         RF  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "58        SVM  LinearSVC(C=10, class_weight=None, dual=True, ...   \n",
       "59        SVM  LinearSVC(C=10, class_weight=None, dual=True, ...   \n",
       "60        SVM  LinearSVC(C=10, class_weight=None, dual=True, ...   \n",
       "61        SVM  LinearSVC(C=10, class_weight=None, dual=True, ...   \n",
       "62        SVM  LinearSVC(C=10, class_weight=None, dual=True, ...   \n",
       "\n",
       "                                           parameters    p_at_1    r_at_1  \\\n",
       "0                       {'C': 0.001, 'penalty': 'l1'}  1.000000  0.013917   \n",
       "1                       {'C': 0.001, 'penalty': 'l2'}  0.872211  0.012139   \n",
       "2                         {'C': 0.1, 'penalty': 'l1'}  0.864097  0.012026   \n",
       "3                         {'C': 0.1, 'penalty': 'l2'}  0.882353  0.012280   \n",
       "4                           {'C': 1, 'penalty': 'l1'}  0.834686  0.011617   \n",
       "5                           {'C': 1, 'penalty': 'l2'}  0.839757  0.011687   \n",
       "6                          {'C': 10, 'penalty': 'l1'}  0.830629  0.011560   \n",
       "7                          {'C': 10, 'penalty': 'l2'}  0.833671  0.011602   \n",
       "8   {'criterion': 'gini', 'max_depth': 1, 'min_sam...  1.000000  0.013917   \n",
       "9   {'criterion': 'gini', 'max_depth': 1, 'min_sam...  1.000000  0.013917   \n",
       "10  {'criterion': 'gini', 'max_depth': 5, 'min_sam...  0.887424  0.012351   \n",
       "11  {'criterion': 'gini', 'max_depth': 5, 'min_sam...  0.887424  0.012351   \n",
       "12  {'criterion': 'gini', 'max_depth': 10, 'min_sa...  0.781947  0.010883   \n",
       "13  {'criterion': 'gini', 'max_depth': 10, 'min_sa...  0.790061  0.010996   \n",
       "14  {'criterion': 'gini', 'max_depth': 50, 'min_sa...  1.000000  0.013917   \n",
       "15  {'criterion': 'gini', 'max_depth': 50, 'min_sa...  1.000000  0.013917   \n",
       "16  {'criterion': 'gini', 'max_depth': 100, 'min_s...  1.000000  0.013917   \n",
       "17  {'criterion': 'gini', 'max_depth': 100, 'min_s...  1.000000  0.013917   \n",
       "18  {'criterion': 'entropy', 'max_depth': 1, 'min_...  1.000000  0.013917   \n",
       "19  {'criterion': 'entropy', 'max_depth': 1, 'min_...  1.000000  0.013917   \n",
       "20  {'criterion': 'entropy', 'max_depth': 5, 'min_...  0.834686  0.011617   \n",
       "21  {'criterion': 'entropy', 'max_depth': 5, 'min_...  0.834686  0.011617   \n",
       "22  {'criterion': 'entropy', 'max_depth': 10, 'min...  0.758621  0.010558   \n",
       "23  {'criterion': 'entropy', 'max_depth': 10, 'min...  0.755578  0.010516   \n",
       "24  {'criterion': 'entropy', 'max_depth': 50, 'min...  1.000000  0.013917   \n",
       "25  {'criterion': 'entropy', 'max_depth': 50, 'min...  1.000000  0.013917   \n",
       "26  {'criterion': 'entropy', 'max_depth': 100, 'mi...  1.000000  0.013917   \n",
       "27  {'criterion': 'entropy', 'max_depth': 100, 'mi...  1.000000  0.013917   \n",
       "28                      {'C': 0.001, 'penalty': 'l1'}  1.000000  0.013917   \n",
       "29                      {'C': 0.001, 'penalty': 'l2'}  0.872211  0.012139   \n",
       "..                                                ...       ...       ...   \n",
       "33                          {'C': 1, 'penalty': 'l2'}  0.839757  0.011687   \n",
       "34                         {'C': 10, 'penalty': 'l1'}  0.830629  0.011560   \n",
       "35                         {'C': 10, 'penalty': 'l2'}  0.833671  0.011602   \n",
       "36          {'algorithm': 'SAMME', 'n_estimators': 1}  1.000000  0.013917   \n",
       "37         {'algorithm': 'SAMME', 'n_estimators': 10}  0.808316  0.011250   \n",
       "38        {'algorithm': 'SAMME', 'n_estimators': 100}  0.826572  0.011504   \n",
       "39        {'algorithm': 'SAMME.R', 'n_estimators': 1}  1.000000  0.013917   \n",
       "40       {'algorithm': 'SAMME.R', 'n_estimators': 10}  0.824544  0.011475   \n",
       "41      {'algorithm': 'SAMME.R', 'n_estimators': 100}  0.831643  0.011574   \n",
       "42  {'max_depth': 5, 'max_features': 'sqrt', 'min_...  0.892495  0.012421   \n",
       "43  {'max_depth': 5, 'max_features': 'sqrt', 'min_...  0.909736  0.012661   \n",
       "44  {'max_depth': 5, 'max_features': 'sqrt', 'min_...  0.911765  0.012689   \n",
       "45  {'max_depth': 5, 'max_features': 'sqrt', 'min_...  0.905680  0.012605   \n",
       "46  {'max_depth': 5, 'max_features': 'log2', 'min_...  0.889452  0.012379   \n",
       "47  {'max_depth': 5, 'max_features': 'log2', 'min_...  0.894523  0.012449   \n",
       "48  {'max_depth': 5, 'max_features': 'log2', 'min_...  0.895538  0.012463   \n",
       "49  {'max_depth': 5, 'max_features': 'log2', 'min_...  0.897566  0.012492   \n",
       "50  {'max_depth': 50, 'max_features': 'sqrt', 'min...  1.000000  0.013917   \n",
       "51  {'max_depth': 50, 'max_features': 'sqrt', 'min...  0.952333  0.013254   \n",
       "52  {'max_depth': 50, 'max_features': 'sqrt', 'min...  0.953347  0.013268   \n",
       "53  {'max_depth': 50, 'max_features': 'sqrt', 'min...  0.959432  0.013353   \n",
       "54  {'max_depth': 50, 'max_features': 'log2', 'min...  1.000000  0.013917   \n",
       "55  {'max_depth': 50, 'max_features': 'log2', 'min...  0.968560  0.013480   \n",
       "56  {'max_depth': 50, 'max_features': 'log2', 'min...  0.954361  0.013282   \n",
       "57  {'max_depth': 50, 'max_features': 'log2', 'min...  0.958418  0.013339   \n",
       "58                                       {'C': 0.001}  0.891481  0.012407   \n",
       "59                                        {'C': 0.01}  0.885396  0.012322   \n",
       "60                                         {'C': 0.1}  0.880325  0.012252   \n",
       "61                                           {'C': 1}  0.884381  0.012308   \n",
       "62                                          {'C': 10}  0.884381  0.012308   \n",
       "\n",
       "      p_at_2    r_at_2    p_at_5    r_at_5   p_at_10   r_at_10   p_at_20  \\\n",
       "0   0.694881  0.019352  0.877989  0.061146  0.833401  0.116081  0.815211   \n",
       "1   0.880892  0.024532  0.875963  0.061005  0.857925  0.119497  0.832489   \n",
       "2   0.866700  0.024137  0.872112  0.060737  0.858533  0.119582  0.837606   \n",
       "3   0.872783  0.024306  0.871301  0.060680  0.859141  0.119666  0.838316   \n",
       "4   0.855043  0.023812  0.869274  0.060539  0.858330  0.119553  0.838164   \n",
       "5   0.856057  0.023840  0.868869  0.060511  0.857925  0.119497  0.837809   \n",
       "6   0.854536  0.023798  0.869072  0.060525  0.858026  0.119511  0.838062   \n",
       "7   0.855043  0.023812  0.868869  0.060511  0.857722  0.119469  0.837961   \n",
       "8   1.000000  0.027849  1.000000  0.069643  0.711796  0.099143  0.701409   \n",
       "9   1.000000  0.027849  1.000000  0.069643  0.711796  0.099143  0.701409   \n",
       "10  0.811455  0.022598  0.837657  0.058337  0.787191  0.109645  0.799301   \n",
       "11  0.811455  0.022598  0.837657  0.058337  0.787191  0.109645  0.799301   \n",
       "12  0.871769  0.024278  0.877989  0.061146  0.847994  0.118114  0.830563   \n",
       "13  0.872276  0.024292  0.875557  0.060976  0.847791  0.118085  0.829905   \n",
       "14  1.000000  0.027849  1.000000  0.069643  1.000000  0.139286  0.761603   \n",
       "15  1.000000  0.027849  1.000000  0.069643  0.910113  0.126766  0.784607   \n",
       "16  1.000000  0.027849  1.000000  0.069643  1.000000  0.139286  0.744224   \n",
       "17  1.000000  0.027849  1.000000  0.069643  0.962910  0.134120  0.769102   \n",
       "18  1.000000  0.027849  1.000000  0.069643  0.711796  0.099143  0.701409   \n",
       "19  1.000000  0.027849  1.000000  0.069643  0.711796  0.099143  0.701409   \n",
       "20  0.783578  0.021822  0.878192  0.061160  0.807458  0.112468  0.810752   \n",
       "21  0.782565  0.021793  0.878395  0.061174  0.807560  0.112482  0.810651   \n",
       "22  0.879372  0.024489  0.884070  0.061569  0.858127  0.119525  0.842623   \n",
       "23  0.877851  0.024447  0.883462  0.061527  0.857823  0.119483  0.842673   \n",
       "24  1.000000  0.027849  1.000000  0.069643  0.976794  0.136054  0.768950   \n",
       "25  1.000000  0.027849  1.000000  0.069643  0.900385  0.125411  0.790231   \n",
       "26  1.000000  0.027849  1.000000  0.069643  1.000000  0.139286  0.747669   \n",
       "27  1.000000  0.027849  1.000000  0.069643  0.969193  0.134995  0.770774   \n",
       "28  0.694881  0.019352  0.877989  0.061146  0.833401  0.116081  0.815211   \n",
       "29  0.880892  0.024532  0.875963  0.061005  0.857925  0.119497  0.832489   \n",
       "..       ...       ...       ...       ...       ...       ...       ...   \n",
       "33  0.856057  0.023840  0.868869  0.060511  0.857925  0.119497  0.837809   \n",
       "34  0.854536  0.023798  0.869072  0.060525  0.858026  0.119511  0.838012   \n",
       "35  0.855043  0.023812  0.868869  0.060511  0.857722  0.119469  0.837961   \n",
       "36  1.000000  0.027849  1.000000  0.069643  0.711796  0.099143  0.701409   \n",
       "37  0.874303  0.024348  0.897244  0.062487  0.826915  0.115178  0.817896   \n",
       "38  0.842879  0.023473  0.866234  0.060327  0.847385  0.118029  0.820582   \n",
       "39  1.000000  0.027849  1.000000  0.069643  0.711796  0.099143  0.701409   \n",
       "40  0.829194  0.023092  0.847588  0.059029  0.835124  0.116321  0.825750   \n",
       "41  0.855550  0.023826  0.870288  0.060609  0.859141  0.119666  0.838265   \n",
       "42  0.884440  0.024631  0.867653  0.060426  0.857013  0.119370  0.831982   \n",
       "43  0.888495  0.024743  0.884272  0.061583  0.864613  0.120429  0.832286   \n",
       "44  0.895590  0.024941  0.872923  0.060793  0.859242  0.119680  0.828739   \n",
       "45  0.889002  0.024758  0.886299  0.061725  0.864208  0.120372  0.831779   \n",
       "46  0.878865  0.024475  0.867248  0.060398  0.856810  0.119342  0.830310   \n",
       "47  0.894577  0.024913  0.883259  0.061513  0.861674  0.120019  0.836137   \n",
       "48  0.881399  0.024546  0.875557  0.060976  0.855188  0.119116  0.830006   \n",
       "49  0.891536  0.024828  0.881638  0.061400  0.863498  0.120273  0.836796   \n",
       "50  1.000000  0.027849  0.838670  0.058408  0.919335  0.128051  0.925618   \n",
       "51  0.954384  0.026578  0.954601  0.066481  0.949027  0.132186  0.933877   \n",
       "52  0.945261  0.026324  0.943859  0.065733  0.932509  0.129886  0.911532   \n",
       "53  0.955398  0.026607  0.949737  0.066143  0.940717  0.131029  0.919437   \n",
       "54  1.000000  0.027849  0.846777  0.058972  0.923389  0.128615  0.925517   \n",
       "55  0.953371  0.026550  0.952979  0.066368  0.947102  0.131918  0.936056   \n",
       "56  0.953877  0.026564  0.942440  0.065634  0.931901  0.129801  0.911735   \n",
       "57  0.956918  0.026649  0.951155  0.066241  0.940312  0.130972  0.922173   \n",
       "58  0.892043  0.024842  0.880219  0.061301  0.863296  0.120245  0.839380   \n",
       "59  0.887988  0.024729  0.876571  0.061047  0.860053  0.119793  0.838670   \n",
       "60  0.880385  0.024518  0.872720  0.060779  0.858938  0.119638  0.837708   \n",
       "61  0.877851  0.024447  0.872112  0.060737  0.859141  0.119666  0.837708   \n",
       "62  0.875824  0.024391  0.875557  0.060976  0.857722  0.119469  0.837404   \n",
       "\n",
       "     r_at_20   p_at_30   r_at_30   p_at_50   r_at_50   auc-roc  \n",
       "0   0.227095  0.800939  0.334679  0.782331  0.544850  0.592306  \n",
       "1   0.231908  0.819247  0.342329  0.788553  0.549183  0.618635  \n",
       "2   0.233334  0.823368  0.344051  0.791573  0.551287  0.624384  \n",
       "3   0.233531  0.823706  0.344192  0.791999  0.551583  0.625046  \n",
       "4   0.233489  0.823368  0.344051  0.791695  0.551371  0.624894  \n",
       "5   0.233390  0.823402  0.344065  0.791289  0.551089  0.624866  \n",
       "6   0.233461  0.823335  0.344037  0.791451  0.551202  0.624867  \n",
       "7   0.233433  0.823368  0.344051  0.791411  0.551174  0.624857  \n",
       "8   0.195393  0.800939  0.334679  0.880566  0.613265  0.550781  \n",
       "9   0.195393  0.800939  0.334679  0.880566  0.613265  0.550781  \n",
       "10  0.222663  0.769524  0.321552  0.783993  0.546008  0.610375  \n",
       "11  0.222663  0.769524  0.321552  0.783993  0.546008  0.610375  \n",
       "12  0.231372  0.823808  0.344235  0.792546  0.551964  0.626015  \n",
       "13  0.231188  0.823639  0.344164  0.792323  0.551809  0.625719  \n",
       "14  0.212161  0.841069  0.351447  0.869277  0.605403  0.745723  \n",
       "15  0.218570  0.856405  0.357856  0.863319  0.601253  0.734040  \n",
       "16  0.207320  0.829483  0.346606  0.874040  0.608720  0.748978  \n",
       "17  0.214250  0.846068  0.353536  0.865224  0.602580  0.736847  \n",
       "18  0.195393  0.800939  0.334679  0.880566  0.613265  0.550781  \n",
       "19  0.195393  0.800939  0.334679  0.880566  0.613265  0.550781  \n",
       "20  0.225853  0.767261  0.320606  0.782027  0.544638  0.609640  \n",
       "21  0.225825  0.767295  0.320620  0.781987  0.544610  0.609648  \n",
       "22  0.234731  0.823166  0.343967  0.794917  0.553616  0.625778  \n",
       "23  0.234745  0.822828  0.343825  0.794795  0.553531  0.625747  \n",
       "24  0.214208  0.845967  0.353494  0.867777  0.604359  0.742237  \n",
       "25  0.220136  0.860154  0.359422  0.870067  0.605954  0.733306  \n",
       "26  0.208280  0.831779  0.347566  0.875621  0.609821  0.749111  \n",
       "27  0.214716  0.847183  0.354002  0.866825  0.603695  0.739574  \n",
       "28  0.227095  0.800939  0.334679  0.782331  0.544850  0.592306  \n",
       "29  0.231908  0.819247  0.342329  0.788553  0.549183  0.618635  \n",
       "..       ...       ...       ...       ...       ...       ...  \n",
       "33  0.233390  0.823402  0.344065  0.791289  0.551089  0.624866  \n",
       "34  0.233447  0.823301  0.344023  0.791431  0.551188  0.624868  \n",
       "35  0.233433  0.823368  0.344051  0.791411  0.551174  0.624857  \n",
       "36  0.195393  0.800939  0.334679  0.880566  0.613265  0.550781  \n",
       "37  0.227843  0.793812  0.331701  0.797937  0.555719  0.603653  \n",
       "38  0.228591  0.791177  0.330600  0.784783  0.546558  0.606189  \n",
       "39  0.195393  0.800939  0.334679  0.880566  0.613265  0.550781  \n",
       "40  0.230031  0.812492  0.339506  0.803976  0.559925  0.612352  \n",
       "41  0.233517  0.823706  0.344192  0.792080  0.551639  0.624863  \n",
       "42  0.231767  0.807898  0.337587  0.782392  0.544893  0.611993  \n",
       "43  0.231852  0.820801  0.342979  0.787945  0.548760  0.621082  \n",
       "44  0.230864  0.804114  0.336006  0.781541  0.544300  0.610145  \n",
       "45  0.231711  0.819112  0.342273  0.787520  0.548464  0.620299  \n",
       "46  0.231301  0.818200  0.341892  0.786324  0.547631  0.616561  \n",
       "47  0.232924  0.822524  0.343698  0.789019  0.549508  0.622608  \n",
       "48  0.231217  0.819112  0.342273  0.787418  0.548393  0.617727  \n",
       "49  0.233108  0.823909  0.344277  0.789810  0.550059  0.623095  \n",
       "50  0.257851  0.911127  0.380722  0.871770  0.607139  0.764817  \n",
       "51  0.260152  0.918322  0.383728  0.880627  0.613308  0.779924  \n",
       "52  0.253927  0.894643  0.373834  0.854219  0.594916  0.733735  \n",
       "53  0.256129  0.903831  0.377673  0.866602  0.603540  0.754929  \n",
       "54  0.257823  0.910147  0.380313  0.870898  0.606532  0.763718  \n",
       "55  0.260759  0.920754  0.384745  0.879654  0.612630  0.780529  \n",
       "56  0.253984  0.894541  0.373791  0.855191  0.595593  0.734312  \n",
       "57  0.256892  0.903223  0.377419  0.867473  0.604147  0.755189  \n",
       "58  0.233828  0.823571  0.344136  0.791999  0.551583  0.625333  \n",
       "59  0.233630  0.824078  0.344348  0.791897  0.551512  0.625729  \n",
       "60  0.233362  0.823639  0.344164  0.792140  0.551682  0.625592  \n",
       "61  0.233362  0.823706  0.344192  0.791978  0.551569  0.625581  \n",
       "62  0.233277  0.823672  0.344178  0.791613  0.551315  0.625121  \n",
       "\n",
       "[63 rows x 18 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"With third train set (smallest one):\")\n",
    "pipeline.iterate_over_models(models_to_run, models, parameters_grid, x_train_3, x_test_3, y_train_3, y_test_3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
