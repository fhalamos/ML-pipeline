{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspired/based on https://github.com/rayidghani/magicloops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pipeline_v2 as pipeline\n",
    "import importlib\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(pipeline)\n",
    "\n",
    "data = pipeline.read_csv('projects_2012_2013.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data exploration...\n",
      "\n",
      "Number of rows: 124976\n",
      "\n",
      "Columns and types of data:\n",
      "projectid                                  object\n",
      "teacher_acctid                             object\n",
      "schoolid                                   object\n",
      "school_ncesid                             float64\n",
      "school_latitude                           float64\n",
      "school_longitude                          float64\n",
      "school_city                                object\n",
      "school_state                               object\n",
      "school_metro                               object\n",
      "school_district                            object\n",
      "school_county                              object\n",
      "school_charter                             object\n",
      "school_magnet                              object\n",
      "teacher_prefix                             object\n",
      "primary_focus_subject                      object\n",
      "primary_focus_area                         object\n",
      "secondary_focus_subject                    object\n",
      "secondary_focus_area                       object\n",
      "resource_type                              object\n",
      "poverty_level                              object\n",
      "grade_level                                object\n",
      "total_price_including_optional_support    float64\n",
      "students_reached                          float64\n",
      "eligible_double_your_impact_match          object\n",
      "date_posted                                object\n",
      "datefullyfunded                            object\n",
      "dtype: object\n",
      "\n",
      "\n",
      "Statistics for selected variables:\n",
      "count    124976.000000\n",
      "mean        654.011811\n",
      "std        1098.015854\n",
      "min          92.000000\n",
      "25%         345.810000\n",
      "50%         510.500000\n",
      "75%         752.960000\n",
      "max      164382.840000\n",
      "Name: total_price_including_optional_support, dtype: float64\n",
      "Number of outliers (>4 standard dev):521\n",
      "\n",
      "\n",
      "count    124917.000000\n",
      "mean         95.445760\n",
      "std         163.481912\n",
      "min           1.000000\n",
      "25%          23.000000\n",
      "50%          30.000000\n",
      "75%         100.000000\n",
      "max       12143.000000\n",
      "Name: students_reached, dtype: float64\n",
      "Number of outliers (>4 standard dev):2063\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Correlation between ['total_price_including_optional_support', 'students_reached']\n",
      "0.1766274350291622\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "importlib.reload(pipeline)\n",
    "\n",
    "stats_for_variables = [\n",
    "  'total_price_including_optional_support',\n",
    "  'students_reached'\n",
    "]\n",
    "\n",
    "variables_for_correlation = [\n",
    "  'total_price_including_optional_support',\n",
    "  'students_reached'\n",
    "]\n",
    "\n",
    "pipeline.explore_data(data, stats_for_variables, variables_for_correlation)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can clearly see in the histograms that DebtRadio MontlyIncome have very big outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre processing data...\n",
      "Done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(pipeline)\n",
    "\n",
    "columns_to_process = [\n",
    "  'total_price_including_optional_support',\n",
    "  'students_reached'\n",
    "]\n",
    "\n",
    "data = pipeline.pre_process_data(data, columns_to_process)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create discrete features and select predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(pipeline)\n",
    "\n",
    "cols_to_transform = [\n",
    "'school_state',\n",
    "'school_metro',\n",
    "'school_charter',\n",
    "'school_magnet',\n",
    "'primary_focus_subject',\n",
    "'primary_focus_area',\n",
    "'resource_type',\n",
    "'poverty_level',\n",
    "'grade_level',\n",
    "'eligible_double_your_impact_match']\n",
    "\n",
    "\n",
    "data = pipeline.create_dummies(data, cols_to_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = ['school_state_AK','school_state_AL','school_state_AR','school_state_AZ','school_state_CA','school_state_CO','school_state_CT','school_state_DC','school_state_DE','school_state_FL','school_state_GA','school_state_HI','school_state_IA','school_state_ID','school_state_IL','school_state_IN','school_state_KS','school_state_KY','school_state_LA','school_state_MA','school_state_MD','school_state_ME','school_state_MI','school_state_MN','school_state_MO','school_state_MS','school_state_MT','school_state_NC','school_state_ND','school_state_NE','school_state_NH','school_state_NJ','school_state_NM','school_state_NV','school_state_NY','school_state_OH','school_state_OK','school_state_OR','school_state_PA','school_state_RI','school_state_SC','school_state_SD','school_state_TN','school_state_TX','school_state_UT','school_state_VA','school_state_VT','school_state_WA','school_state_WI','school_state_WV','school_state_WY','school_state_nan','school_metro_rural','school_metro_suburban','school_metro_urban','school_metro_nan','school_charter_f','school_charter_t','school_charter_nan','school_magnet_f','school_magnet_t','school_magnet_nan','primary_focus_subject_Applied Sciences','primary_focus_subject_Character Education','primary_focus_subject_Civics & Government','primary_focus_subject_College & Career Prep','primary_focus_subject_Community Service','primary_focus_subject_ESL','primary_focus_subject_Early Development','primary_focus_subject_Economics','primary_focus_subject_Environmental Science','primary_focus_subject_Extracurricular','primary_focus_subject_Foreign Languages','primary_focus_subject_Gym & Fitness','primary_focus_subject_Health & Life Science','primary_focus_subject_Health & Wellness','primary_focus_subject_History & Geography','primary_focus_subject_Literacy','primary_focus_subject_Literature & Writing','primary_focus_subject_Mathematics','primary_focus_subject_Music','primary_focus_subject_Nutrition','primary_focus_subject_Other','primary_focus_subject_Parent Involvement','primary_focus_subject_Performing Arts','primary_focus_subject_Social Sciences','primary_focus_subject_Special Needs','primary_focus_subject_Sports','primary_focus_subject_Visual Arts','primary_focus_subject_nan','primary_focus_area_Applied Learning','primary_focus_area_Health & Sports','primary_focus_area_History & Civics','primary_focus_area_Literacy & Language','primary_focus_area_Math & Science','primary_focus_area_Music & The Arts','primary_focus_area_Special Needs','primary_focus_area_nan','resource_type_Books','resource_type_Other','resource_type_Supplies','resource_type_Technology','resource_type_Trips','resource_type_Visitors','resource_type_nan','poverty_level_high poverty','poverty_level_highest poverty','poverty_level_low poverty','poverty_level_moderate poverty','poverty_level_nan','grade_level_Grades 3-5','grade_level_Grades 6-8','grade_level_Grades 9-12','grade_level_Grades PreK-2','grade_level_nan','eligible_double_your_impact_match_f','eligible_double_your_impact_match_t','eligible_double_your_impact_match_nan']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create binary variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(pipeline)\n",
    "\n",
    "# The task is to predict if a project on donorschoose will not get fully funded within 60 days of posting.\n",
    "\n",
    "# Change dates to date format\n",
    "data['datefullyfunded_formated'] = pd.to_datetime(data['datefullyfunded'])\n",
    "data['date_posted_formated'] = pd.to_datetime(data['date_posted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(pipeline)\n",
    "\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "#Calculate difference between two dates\n",
    "data['time_to_fund'] = data['datefullyfunded_formated'].sub(data['date_posted_formated'], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(pipeline)\n",
    "\n",
    "data['time_to_fund'] = pd.to_numeric(data['time_to_fund'] / np.timedelta64(1, 'D'))\n",
    "data['funded_in_60'] = np.where(data['time_to_fund']<61, 1, 0)\n",
    "\n",
    "outcome ='funded_in_60'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count                  124976\n",
       "unique                    731\n",
       "top       2012-09-30 00:00:00\n",
       "freq                      728\n",
       "first     2012-01-01 00:00:00\n",
       "last      2013-12-31 00:00:00\n",
       "Name: date_posted_formated, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['date_posted_formated'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80800, 118)\n",
      "(80800,)\n",
      "(44176, 118)\n",
      "(44176,)\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(pipeline)\n",
    "\n",
    "start_time = str(data['date_posted_formated'].describe()['first']).split(\" \")[0]\n",
    "end_time = str(data['date_posted_formated'].describe()['last']).split(\" \")[0]\n",
    "prediction_window = 6\n",
    "date_column='date_posted_formated'\n",
    "\n",
    "\n",
    "sets = pipeline.create_temp_validation_train_and_testing_sets(data, \n",
    "                                                                   selected_features,\n",
    "                                                                   outcome,\n",
    "                                                                   start_time,\n",
    "                                                                   end_time,\n",
    "                                                                   prediction_window,\n",
    "                                                                   date_column)\n",
    "x_train = sets[0]\n",
    "x_test = sets[1]\n",
    "y_train = sets[2]\n",
    "y_test = sets[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Clasifiers and parameters generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(pipeline)\n",
    "\n",
    "#We define the specific models we want to run\n",
    "\n",
    "#Not running BA and KNN because they are taking ages\n",
    "models_to_run=['LR','DT','LR','AB','RF','SVM']#,'BA','KNN']\n",
    "\n",
    "#Get all posible models and their different sets of parameters\n",
    "models, parameters_grid = pipeline.get_models_and_parameters()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loop over models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running LR...\n",
      "Running DT...\n",
      "Running LR...\n",
      "Running AB...\n",
      "Running RF...\n",
      "Running SVM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/felipe/.local/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>model</th>\n",
       "      <th>parameters</th>\n",
       "      <th>p_at_1</th>\n",
       "      <th>r_at_1</th>\n",
       "      <th>p_at_2</th>\n",
       "      <th>r_at_2</th>\n",
       "      <th>p_at_5</th>\n",
       "      <th>r_at_5</th>\n",
       "      <th>p_at_10</th>\n",
       "      <th>r_at_10</th>\n",
       "      <th>p_at_20</th>\n",
       "      <th>r_at_20</th>\n",
       "      <th>p_at_30</th>\n",
       "      <th>r_at_30</th>\n",
       "      <th>p_at_50</th>\n",
       "      <th>r_at_50</th>\n",
       "      <th>auc-roc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>{'C': 0.001, 'penalty': 'l1'}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013956</td>\n",
       "      <td>0.710079</td>\n",
       "      <td>0.019842</td>\n",
       "      <td>0.867301</td>\n",
       "      <td>0.060601</td>\n",
       "      <td>0.837220</td>\n",
       "      <td>0.117025</td>\n",
       "      <td>0.799095</td>\n",
       "      <td>0.223418</td>\n",
       "      <td>0.781467</td>\n",
       "      <td>0.327722</td>\n",
       "      <td>0.785313</td>\n",
       "      <td>0.548924</td>\n",
       "      <td>0.590088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>{'C': 0.001, 'penalty': 'l2'}</td>\n",
       "      <td>0.877551</td>\n",
       "      <td>0.012247</td>\n",
       "      <td>0.883352</td>\n",
       "      <td>0.024684</td>\n",
       "      <td>0.871830</td>\n",
       "      <td>0.060918</td>\n",
       "      <td>0.854426</td>\n",
       "      <td>0.119430</td>\n",
       "      <td>0.828862</td>\n",
       "      <td>0.231741</td>\n",
       "      <td>0.817386</td>\n",
       "      <td>0.342785</td>\n",
       "      <td>0.783412</td>\n",
       "      <td>0.547595</td>\n",
       "      <td>0.617331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'l1'}</td>\n",
       "      <td>0.825397</td>\n",
       "      <td>0.011519</td>\n",
       "      <td>0.828992</td>\n",
       "      <td>0.023165</td>\n",
       "      <td>0.850091</td>\n",
       "      <td>0.059399</td>\n",
       "      <td>0.843559</td>\n",
       "      <td>0.117911</td>\n",
       "      <td>0.827731</td>\n",
       "      <td>0.231424</td>\n",
       "      <td>0.817235</td>\n",
       "      <td>0.342722</td>\n",
       "      <td>0.787577</td>\n",
       "      <td>0.550506</td>\n",
       "      <td>0.619977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'l2'}</td>\n",
       "      <td>0.845805</td>\n",
       "      <td>0.011804</td>\n",
       "      <td>0.843715</td>\n",
       "      <td>0.023576</td>\n",
       "      <td>0.852808</td>\n",
       "      <td>0.059589</td>\n",
       "      <td>0.845370</td>\n",
       "      <td>0.118165</td>\n",
       "      <td>0.828976</td>\n",
       "      <td>0.231772</td>\n",
       "      <td>0.817235</td>\n",
       "      <td>0.342722</td>\n",
       "      <td>0.786490</td>\n",
       "      <td>0.549747</td>\n",
       "      <td>0.620281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>{'C': 1, 'penalty': 'l1'}</td>\n",
       "      <td>0.775510</td>\n",
       "      <td>0.010823</td>\n",
       "      <td>0.796149</td>\n",
       "      <td>0.022247</td>\n",
       "      <td>0.843297</td>\n",
       "      <td>0.058924</td>\n",
       "      <td>0.844691</td>\n",
       "      <td>0.118070</td>\n",
       "      <td>0.828297</td>\n",
       "      <td>0.231582</td>\n",
       "      <td>0.816933</td>\n",
       "      <td>0.342595</td>\n",
       "      <td>0.786626</td>\n",
       "      <td>0.549842</td>\n",
       "      <td>0.619914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>{'C': 1, 'penalty': 'l2'}</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.010854</td>\n",
       "      <td>0.800680</td>\n",
       "      <td>0.022373</td>\n",
       "      <td>0.843750</td>\n",
       "      <td>0.058956</td>\n",
       "      <td>0.844238</td>\n",
       "      <td>0.118006</td>\n",
       "      <td>0.827391</td>\n",
       "      <td>0.231329</td>\n",
       "      <td>0.816707</td>\n",
       "      <td>0.342500</td>\n",
       "      <td>0.786671</td>\n",
       "      <td>0.549873</td>\n",
       "      <td>0.619810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>{'C': 10, 'penalty': 'l1'}</td>\n",
       "      <td>0.773243</td>\n",
       "      <td>0.010791</td>\n",
       "      <td>0.793884</td>\n",
       "      <td>0.022184</td>\n",
       "      <td>0.844203</td>\n",
       "      <td>0.058987</td>\n",
       "      <td>0.844917</td>\n",
       "      <td>0.118101</td>\n",
       "      <td>0.827278</td>\n",
       "      <td>0.231297</td>\n",
       "      <td>0.816556</td>\n",
       "      <td>0.342437</td>\n",
       "      <td>0.786762</td>\n",
       "      <td>0.549937</td>\n",
       "      <td>0.619782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>{'C': 10, 'penalty': 'l2'}</td>\n",
       "      <td>0.770975</td>\n",
       "      <td>0.010759</td>\n",
       "      <td>0.793884</td>\n",
       "      <td>0.022184</td>\n",
       "      <td>0.844203</td>\n",
       "      <td>0.058987</td>\n",
       "      <td>0.844917</td>\n",
       "      <td>0.118101</td>\n",
       "      <td>0.827617</td>\n",
       "      <td>0.231392</td>\n",
       "      <td>0.816556</td>\n",
       "      <td>0.342437</td>\n",
       "      <td>0.786762</td>\n",
       "      <td>0.549937</td>\n",
       "      <td>0.619771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 1, 'min_sam...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013956</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.027943</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.069873</td>\n",
       "      <td>0.744623</td>\n",
       "      <td>0.104082</td>\n",
       "      <td>0.672213</td>\n",
       "      <td>0.187943</td>\n",
       "      <td>0.781467</td>\n",
       "      <td>0.327722</td>\n",
       "      <td>0.868843</td>\n",
       "      <td>0.607310</td>\n",
       "      <td>0.547044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 1, 'min_sam...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013956</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.027943</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.069873</td>\n",
       "      <td>0.744623</td>\n",
       "      <td>0.104082</td>\n",
       "      <td>0.672213</td>\n",
       "      <td>0.187943</td>\n",
       "      <td>0.781467</td>\n",
       "      <td>0.327722</td>\n",
       "      <td>0.868843</td>\n",
       "      <td>0.607310</td>\n",
       "      <td>0.547044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'min_sam...</td>\n",
       "      <td>0.775510</td>\n",
       "      <td>0.010823</td>\n",
       "      <td>0.705549</td>\n",
       "      <td>0.019715</td>\n",
       "      <td>0.788496</td>\n",
       "      <td>0.055095</td>\n",
       "      <td>0.749830</td>\n",
       "      <td>0.104810</td>\n",
       "      <td>0.805999</td>\n",
       "      <td>0.225348</td>\n",
       "      <td>0.780486</td>\n",
       "      <td>0.327310</td>\n",
       "      <td>0.784227</td>\n",
       "      <td>0.548165</td>\n",
       "      <td>0.609405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'min_sam...</td>\n",
       "      <td>0.775510</td>\n",
       "      <td>0.010823</td>\n",
       "      <td>0.705549</td>\n",
       "      <td>0.019715</td>\n",
       "      <td>0.788496</td>\n",
       "      <td>0.055095</td>\n",
       "      <td>0.749830</td>\n",
       "      <td>0.104810</td>\n",
       "      <td>0.805999</td>\n",
       "      <td>0.225348</td>\n",
       "      <td>0.780486</td>\n",
       "      <td>0.327310</td>\n",
       "      <td>0.784227</td>\n",
       "      <td>0.548165</td>\n",
       "      <td>0.609405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 10, 'min_sa...</td>\n",
       "      <td>0.512472</td>\n",
       "      <td>0.007152</td>\n",
       "      <td>0.749717</td>\n",
       "      <td>0.020949</td>\n",
       "      <td>0.802989</td>\n",
       "      <td>0.056108</td>\n",
       "      <td>0.803939</td>\n",
       "      <td>0.112373</td>\n",
       "      <td>0.804188</td>\n",
       "      <td>0.224842</td>\n",
       "      <td>0.801011</td>\n",
       "      <td>0.335918</td>\n",
       "      <td>0.781375</td>\n",
       "      <td>0.546171</td>\n",
       "      <td>0.603402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 10, 'min_sa...</td>\n",
       "      <td>0.530612</td>\n",
       "      <td>0.007405</td>\n",
       "      <td>0.747452</td>\n",
       "      <td>0.020886</td>\n",
       "      <td>0.803895</td>\n",
       "      <td>0.056171</td>\n",
       "      <td>0.800091</td>\n",
       "      <td>0.111835</td>\n",
       "      <td>0.804188</td>\n",
       "      <td>0.224842</td>\n",
       "      <td>0.800936</td>\n",
       "      <td>0.335886</td>\n",
       "      <td>0.781239</td>\n",
       "      <td>0.546076</td>\n",
       "      <td>0.603347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 50, 'min_sa...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013956</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.027943</td>\n",
       "      <td>0.993207</td>\n",
       "      <td>0.069399</td>\n",
       "      <td>0.996378</td>\n",
       "      <td>0.139272</td>\n",
       "      <td>0.528919</td>\n",
       "      <td>0.147880</td>\n",
       "      <td>0.644959</td>\n",
       "      <td>0.270475</td>\n",
       "      <td>0.756836</td>\n",
       "      <td>0.529019</td>\n",
       "      <td>0.553882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 50, 'min_sa...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013956</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.027943</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.069873</td>\n",
       "      <td>0.970342</td>\n",
       "      <td>0.135633</td>\n",
       "      <td>0.518846</td>\n",
       "      <td>0.145063</td>\n",
       "      <td>0.679218</td>\n",
       "      <td>0.284842</td>\n",
       "      <td>0.755433</td>\n",
       "      <td>0.528038</td>\n",
       "      <td>0.556310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 100, 'min_s...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013956</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.027943</td>\n",
       "      <td>0.967844</td>\n",
       "      <td>0.067627</td>\n",
       "      <td>0.983926</td>\n",
       "      <td>0.137532</td>\n",
       "      <td>0.555178</td>\n",
       "      <td>0.155222</td>\n",
       "      <td>0.619076</td>\n",
       "      <td>0.259620</td>\n",
       "      <td>0.753577</td>\n",
       "      <td>0.526741</td>\n",
       "      <td>0.550751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 100, 'min_s...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013956</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.027943</td>\n",
       "      <td>0.987319</td>\n",
       "      <td>0.068987</td>\n",
       "      <td>0.993661</td>\n",
       "      <td>0.138892</td>\n",
       "      <td>0.509338</td>\n",
       "      <td>0.142405</td>\n",
       "      <td>0.656127</td>\n",
       "      <td>0.275158</td>\n",
       "      <td>0.753079</td>\n",
       "      <td>0.526392</td>\n",
       "      <td>0.552637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 1, 'min_...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013956</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.027943</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.069873</td>\n",
       "      <td>0.744623</td>\n",
       "      <td>0.104082</td>\n",
       "      <td>0.672213</td>\n",
       "      <td>0.187943</td>\n",
       "      <td>0.781467</td>\n",
       "      <td>0.327722</td>\n",
       "      <td>0.868843</td>\n",
       "      <td>0.607310</td>\n",
       "      <td>0.547044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 1, 'min_...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013956</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.027943</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.069873</td>\n",
       "      <td>0.744623</td>\n",
       "      <td>0.104082</td>\n",
       "      <td>0.672213</td>\n",
       "      <td>0.187943</td>\n",
       "      <td>0.781467</td>\n",
       "      <td>0.327722</td>\n",
       "      <td>0.868843</td>\n",
       "      <td>0.607310</td>\n",
       "      <td>0.547044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'min_...</td>\n",
       "      <td>0.773243</td>\n",
       "      <td>0.010791</td>\n",
       "      <td>0.795017</td>\n",
       "      <td>0.022215</td>\n",
       "      <td>0.810236</td>\n",
       "      <td>0.056614</td>\n",
       "      <td>0.760697</td>\n",
       "      <td>0.106329</td>\n",
       "      <td>0.821279</td>\n",
       "      <td>0.229620</td>\n",
       "      <td>0.776411</td>\n",
       "      <td>0.325601</td>\n",
       "      <td>0.780695</td>\n",
       "      <td>0.545696</td>\n",
       "      <td>0.608205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'min_...</td>\n",
       "      <td>0.775510</td>\n",
       "      <td>0.010823</td>\n",
       "      <td>0.796149</td>\n",
       "      <td>0.022247</td>\n",
       "      <td>0.810688</td>\n",
       "      <td>0.056646</td>\n",
       "      <td>0.760924</td>\n",
       "      <td>0.106361</td>\n",
       "      <td>0.821166</td>\n",
       "      <td>0.229589</td>\n",
       "      <td>0.776487</td>\n",
       "      <td>0.325633</td>\n",
       "      <td>0.780741</td>\n",
       "      <td>0.545728</td>\n",
       "      <td>0.608252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 10, 'min...</td>\n",
       "      <td>0.646259</td>\n",
       "      <td>0.009019</td>\n",
       "      <td>0.730464</td>\n",
       "      <td>0.020411</td>\n",
       "      <td>0.795743</td>\n",
       "      <td>0.055601</td>\n",
       "      <td>0.827258</td>\n",
       "      <td>0.115633</td>\n",
       "      <td>0.818789</td>\n",
       "      <td>0.228924</td>\n",
       "      <td>0.801087</td>\n",
       "      <td>0.335949</td>\n",
       "      <td>0.786264</td>\n",
       "      <td>0.549589</td>\n",
       "      <td>0.608688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 10, 'min...</td>\n",
       "      <td>0.637188</td>\n",
       "      <td>0.008892</td>\n",
       "      <td>0.727067</td>\n",
       "      <td>0.020316</td>\n",
       "      <td>0.794384</td>\n",
       "      <td>0.055506</td>\n",
       "      <td>0.826806</td>\n",
       "      <td>0.115570</td>\n",
       "      <td>0.818789</td>\n",
       "      <td>0.228924</td>\n",
       "      <td>0.800634</td>\n",
       "      <td>0.335759</td>\n",
       "      <td>0.786309</td>\n",
       "      <td>0.549620</td>\n",
       "      <td>0.608738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 50, 'min...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013956</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.027943</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.069873</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.139778</td>\n",
       "      <td>0.517148</td>\n",
       "      <td>0.144589</td>\n",
       "      <td>0.655901</td>\n",
       "      <td>0.275063</td>\n",
       "      <td>0.754573</td>\n",
       "      <td>0.527437</td>\n",
       "      <td>0.554204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 50, 'min...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013956</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.027943</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.069873</td>\n",
       "      <td>0.953362</td>\n",
       "      <td>0.133259</td>\n",
       "      <td>0.531409</td>\n",
       "      <td>0.148576</td>\n",
       "      <td>0.687594</td>\n",
       "      <td>0.288354</td>\n",
       "      <td>0.763944</td>\n",
       "      <td>0.533987</td>\n",
       "      <td>0.557241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 100, 'mi...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013956</td>\n",
       "      <td>0.998867</td>\n",
       "      <td>0.027911</td>\n",
       "      <td>0.971014</td>\n",
       "      <td>0.067848</td>\n",
       "      <td>0.985511</td>\n",
       "      <td>0.137753</td>\n",
       "      <td>0.549179</td>\n",
       "      <td>0.153544</td>\n",
       "      <td>0.624208</td>\n",
       "      <td>0.261772</td>\n",
       "      <td>0.751630</td>\n",
       "      <td>0.525380</td>\n",
       "      <td>0.550796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 100, 'mi...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013956</td>\n",
       "      <td>0.998867</td>\n",
       "      <td>0.027911</td>\n",
       "      <td>0.992754</td>\n",
       "      <td>0.069367</td>\n",
       "      <td>0.996378</td>\n",
       "      <td>0.139272</td>\n",
       "      <td>0.508432</td>\n",
       "      <td>0.142152</td>\n",
       "      <td>0.658618</td>\n",
       "      <td>0.276203</td>\n",
       "      <td>0.753984</td>\n",
       "      <td>0.527025</td>\n",
       "      <td>0.552605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>{'C': 0.001, 'penalty': 'l1'}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013956</td>\n",
       "      <td>0.710079</td>\n",
       "      <td>0.019842</td>\n",
       "      <td>0.867301</td>\n",
       "      <td>0.060601</td>\n",
       "      <td>0.837220</td>\n",
       "      <td>0.117025</td>\n",
       "      <td>0.803396</td>\n",
       "      <td>0.224620</td>\n",
       "      <td>0.781467</td>\n",
       "      <td>0.327722</td>\n",
       "      <td>0.785313</td>\n",
       "      <td>0.548924</td>\n",
       "      <td>0.593102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>{'C': 0.001, 'penalty': 'l2'}</td>\n",
       "      <td>0.877551</td>\n",
       "      <td>0.012247</td>\n",
       "      <td>0.883352</td>\n",
       "      <td>0.024684</td>\n",
       "      <td>0.871830</td>\n",
       "      <td>0.060918</td>\n",
       "      <td>0.854426</td>\n",
       "      <td>0.119430</td>\n",
       "      <td>0.828862</td>\n",
       "      <td>0.231741</td>\n",
       "      <td>0.817386</td>\n",
       "      <td>0.342785</td>\n",
       "      <td>0.783412</td>\n",
       "      <td>0.547595</td>\n",
       "      <td>0.617331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>{'C': 1, 'penalty': 'l2'}</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.010854</td>\n",
       "      <td>0.800680</td>\n",
       "      <td>0.022373</td>\n",
       "      <td>0.843750</td>\n",
       "      <td>0.058956</td>\n",
       "      <td>0.844238</td>\n",
       "      <td>0.118006</td>\n",
       "      <td>0.827391</td>\n",
       "      <td>0.231329</td>\n",
       "      <td>0.816707</td>\n",
       "      <td>0.342500</td>\n",
       "      <td>0.786671</td>\n",
       "      <td>0.549873</td>\n",
       "      <td>0.619810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>{'C': 10, 'penalty': 'l1'}</td>\n",
       "      <td>0.773243</td>\n",
       "      <td>0.010791</td>\n",
       "      <td>0.793884</td>\n",
       "      <td>0.022184</td>\n",
       "      <td>0.844203</td>\n",
       "      <td>0.058987</td>\n",
       "      <td>0.844917</td>\n",
       "      <td>0.118101</td>\n",
       "      <td>0.827504</td>\n",
       "      <td>0.231361</td>\n",
       "      <td>0.816556</td>\n",
       "      <td>0.342437</td>\n",
       "      <td>0.786762</td>\n",
       "      <td>0.549937</td>\n",
       "      <td>0.619793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>{'C': 10, 'penalty': 'l2'}</td>\n",
       "      <td>0.770975</td>\n",
       "      <td>0.010759</td>\n",
       "      <td>0.793884</td>\n",
       "      <td>0.022184</td>\n",
       "      <td>0.844203</td>\n",
       "      <td>0.058987</td>\n",
       "      <td>0.844917</td>\n",
       "      <td>0.118101</td>\n",
       "      <td>0.827617</td>\n",
       "      <td>0.231392</td>\n",
       "      <td>0.816556</td>\n",
       "      <td>0.342437</td>\n",
       "      <td>0.786762</td>\n",
       "      <td>0.549937</td>\n",
       "      <td>0.619771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>AB</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'algorithm': 'SAMME', 'n_estimators': 1}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013956</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.027943</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.069873</td>\n",
       "      <td>0.744623</td>\n",
       "      <td>0.104082</td>\n",
       "      <td>0.672213</td>\n",
       "      <td>0.187943</td>\n",
       "      <td>0.781467</td>\n",
       "      <td>0.327722</td>\n",
       "      <td>0.868843</td>\n",
       "      <td>0.607310</td>\n",
       "      <td>0.547044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>AB</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'algorithm': 'SAMME', 'n_estimators': 10}</td>\n",
       "      <td>0.836735</td>\n",
       "      <td>0.011677</td>\n",
       "      <td>0.898075</td>\n",
       "      <td>0.025095</td>\n",
       "      <td>0.902174</td>\n",
       "      <td>0.063038</td>\n",
       "      <td>0.823862</td>\n",
       "      <td>0.115158</td>\n",
       "      <td>0.822524</td>\n",
       "      <td>0.229968</td>\n",
       "      <td>0.779882</td>\n",
       "      <td>0.327057</td>\n",
       "      <td>0.783140</td>\n",
       "      <td>0.547405</td>\n",
       "      <td>0.601875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>AB</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'algorithm': 'SAMME', 'n_estimators': 100}</td>\n",
       "      <td>0.739229</td>\n",
       "      <td>0.010316</td>\n",
       "      <td>0.781427</td>\n",
       "      <td>0.021835</td>\n",
       "      <td>0.838315</td>\n",
       "      <td>0.058576</td>\n",
       "      <td>0.830428</td>\n",
       "      <td>0.116076</td>\n",
       "      <td>0.819581</td>\n",
       "      <td>0.229146</td>\n",
       "      <td>0.774374</td>\n",
       "      <td>0.324747</td>\n",
       "      <td>0.782280</td>\n",
       "      <td>0.546804</td>\n",
       "      <td>0.602678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>AB</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'algorithm': 'SAMME.R', 'n_estimators': 1}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013956</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.027943</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.069873</td>\n",
       "      <td>0.744623</td>\n",
       "      <td>0.104082</td>\n",
       "      <td>0.672213</td>\n",
       "      <td>0.187943</td>\n",
       "      <td>0.781467</td>\n",
       "      <td>0.327722</td>\n",
       "      <td>0.868843</td>\n",
       "      <td>0.607310</td>\n",
       "      <td>0.547044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>AB</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'algorithm': 'SAMME.R', 'n_estimators': 10}</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.010633</td>\n",
       "      <td>0.784824</td>\n",
       "      <td>0.021930</td>\n",
       "      <td>0.821105</td>\n",
       "      <td>0.057373</td>\n",
       "      <td>0.815033</td>\n",
       "      <td>0.113924</td>\n",
       "      <td>0.820147</td>\n",
       "      <td>0.229304</td>\n",
       "      <td>0.809010</td>\n",
       "      <td>0.339272</td>\n",
       "      <td>0.802562</td>\n",
       "      <td>0.560981</td>\n",
       "      <td>0.610830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>AB</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'algorithm': 'SAMME.R', 'n_estimators': 100}</td>\n",
       "      <td>0.775510</td>\n",
       "      <td>0.010823</td>\n",
       "      <td>0.790487</td>\n",
       "      <td>0.022089</td>\n",
       "      <td>0.843750</td>\n",
       "      <td>0.058956</td>\n",
       "      <td>0.845144</td>\n",
       "      <td>0.118133</td>\n",
       "      <td>0.827165</td>\n",
       "      <td>0.231266</td>\n",
       "      <td>0.817160</td>\n",
       "      <td>0.342690</td>\n",
       "      <td>0.786807</td>\n",
       "      <td>0.549968</td>\n",
       "      <td>0.619644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 'sqrt', 'min_...</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.011962</td>\n",
       "      <td>0.862967</td>\n",
       "      <td>0.024114</td>\n",
       "      <td>0.857790</td>\n",
       "      <td>0.059937</td>\n",
       "      <td>0.844691</td>\n",
       "      <td>0.118070</td>\n",
       "      <td>0.826712</td>\n",
       "      <td>0.231139</td>\n",
       "      <td>0.795804</td>\n",
       "      <td>0.333734</td>\n",
       "      <td>0.775715</td>\n",
       "      <td>0.542215</td>\n",
       "      <td>0.606076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 'sqrt', 'min_...</td>\n",
       "      <td>0.902494</td>\n",
       "      <td>0.012595</td>\n",
       "      <td>0.876557</td>\n",
       "      <td>0.024494</td>\n",
       "      <td>0.874547</td>\n",
       "      <td>0.061108</td>\n",
       "      <td>0.856237</td>\n",
       "      <td>0.119684</td>\n",
       "      <td>0.826712</td>\n",
       "      <td>0.231139</td>\n",
       "      <td>0.814066</td>\n",
       "      <td>0.341392</td>\n",
       "      <td>0.780650</td>\n",
       "      <td>0.545665</td>\n",
       "      <td>0.616676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 'sqrt', 'min_...</td>\n",
       "      <td>0.877551</td>\n",
       "      <td>0.012247</td>\n",
       "      <td>0.866365</td>\n",
       "      <td>0.024209</td>\n",
       "      <td>0.855525</td>\n",
       "      <td>0.059778</td>\n",
       "      <td>0.844012</td>\n",
       "      <td>0.117975</td>\n",
       "      <td>0.819468</td>\n",
       "      <td>0.229114</td>\n",
       "      <td>0.792409</td>\n",
       "      <td>0.332310</td>\n",
       "      <td>0.772365</td>\n",
       "      <td>0.539873</td>\n",
       "      <td>0.603239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 'sqrt', 'min_...</td>\n",
       "      <td>0.895692</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>0.875425</td>\n",
       "      <td>0.024462</td>\n",
       "      <td>0.873641</td>\n",
       "      <td>0.061044</td>\n",
       "      <td>0.855558</td>\n",
       "      <td>0.119589</td>\n",
       "      <td>0.826486</td>\n",
       "      <td>0.231076</td>\n",
       "      <td>0.811877</td>\n",
       "      <td>0.340475</td>\n",
       "      <td>0.780560</td>\n",
       "      <td>0.545601</td>\n",
       "      <td>0.615912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 'log2', 'min_...</td>\n",
       "      <td>0.868481</td>\n",
       "      <td>0.012120</td>\n",
       "      <td>0.859570</td>\n",
       "      <td>0.024019</td>\n",
       "      <td>0.846467</td>\n",
       "      <td>0.059146</td>\n",
       "      <td>0.846955</td>\n",
       "      <td>0.118386</td>\n",
       "      <td>0.826938</td>\n",
       "      <td>0.231203</td>\n",
       "      <td>0.812708</td>\n",
       "      <td>0.340823</td>\n",
       "      <td>0.781963</td>\n",
       "      <td>0.546582</td>\n",
       "      <td>0.614701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 'log2', 'min_...</td>\n",
       "      <td>0.886621</td>\n",
       "      <td>0.012373</td>\n",
       "      <td>0.877690</td>\n",
       "      <td>0.024525</td>\n",
       "      <td>0.876359</td>\n",
       "      <td>0.061234</td>\n",
       "      <td>0.855105</td>\n",
       "      <td>0.119525</td>\n",
       "      <td>0.831239</td>\n",
       "      <td>0.232405</td>\n",
       "      <td>0.816254</td>\n",
       "      <td>0.342310</td>\n",
       "      <td>0.783910</td>\n",
       "      <td>0.547943</td>\n",
       "      <td>0.618690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 'log2', 'min_...</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.012405</td>\n",
       "      <td>0.859570</td>\n",
       "      <td>0.024019</td>\n",
       "      <td>0.855525</td>\n",
       "      <td>0.059778</td>\n",
       "      <td>0.847861</td>\n",
       "      <td>0.118513</td>\n",
       "      <td>0.827504</td>\n",
       "      <td>0.231361</td>\n",
       "      <td>0.815952</td>\n",
       "      <td>0.342184</td>\n",
       "      <td>0.784634</td>\n",
       "      <td>0.548449</td>\n",
       "      <td>0.616462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 'log2', 'min_...</td>\n",
       "      <td>0.886621</td>\n",
       "      <td>0.012373</td>\n",
       "      <td>0.882220</td>\n",
       "      <td>0.024652</td>\n",
       "      <td>0.876359</td>\n",
       "      <td>0.061234</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.119810</td>\n",
       "      <td>0.831579</td>\n",
       "      <td>0.232500</td>\n",
       "      <td>0.816933</td>\n",
       "      <td>0.342595</td>\n",
       "      <td>0.784996</td>\n",
       "      <td>0.548703</td>\n",
       "      <td>0.619532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 50, 'max_features': 'sqrt', 'min...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013956</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.027943</td>\n",
       "      <td>0.639493</td>\n",
       "      <td>0.044684</td>\n",
       "      <td>0.808467</td>\n",
       "      <td>0.113006</td>\n",
       "      <td>0.794114</td>\n",
       "      <td>0.222025</td>\n",
       "      <td>0.780486</td>\n",
       "      <td>0.327310</td>\n",
       "      <td>0.762586</td>\n",
       "      <td>0.533038</td>\n",
       "      <td>0.577122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 50, 'max_features': 'sqrt', 'min...</td>\n",
       "      <td>0.841270</td>\n",
       "      <td>0.011741</td>\n",
       "      <td>0.847112</td>\n",
       "      <td>0.023671</td>\n",
       "      <td>0.850543</td>\n",
       "      <td>0.059430</td>\n",
       "      <td>0.816844</td>\n",
       "      <td>0.114177</td>\n",
       "      <td>0.790492</td>\n",
       "      <td>0.221013</td>\n",
       "      <td>0.781920</td>\n",
       "      <td>0.327911</td>\n",
       "      <td>0.766570</td>\n",
       "      <td>0.535823</td>\n",
       "      <td>0.583090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 50, 'max_features': 'sqrt', 'min...</td>\n",
       "      <td>0.850340</td>\n",
       "      <td>0.011867</td>\n",
       "      <td>0.845980</td>\n",
       "      <td>0.023639</td>\n",
       "      <td>0.850091</td>\n",
       "      <td>0.059399</td>\n",
       "      <td>0.829975</td>\n",
       "      <td>0.116013</td>\n",
       "      <td>0.805433</td>\n",
       "      <td>0.225190</td>\n",
       "      <td>0.793390</td>\n",
       "      <td>0.332722</td>\n",
       "      <td>0.768607</td>\n",
       "      <td>0.537247</td>\n",
       "      <td>0.589409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 50, 'max_features': 'sqrt', 'min...</td>\n",
       "      <td>0.879819</td>\n",
       "      <td>0.012278</td>\n",
       "      <td>0.879955</td>\n",
       "      <td>0.024589</td>\n",
       "      <td>0.859149</td>\n",
       "      <td>0.060032</td>\n",
       "      <td>0.839937</td>\n",
       "      <td>0.117405</td>\n",
       "      <td>0.819015</td>\n",
       "      <td>0.228987</td>\n",
       "      <td>0.800634</td>\n",
       "      <td>0.335759</td>\n",
       "      <td>0.773044</td>\n",
       "      <td>0.540348</td>\n",
       "      <td>0.601300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 50, 'max_features': 'log2', 'min...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013956</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.027943</td>\n",
       "      <td>0.657609</td>\n",
       "      <td>0.045949</td>\n",
       "      <td>0.802355</td>\n",
       "      <td>0.112152</td>\n",
       "      <td>0.793775</td>\n",
       "      <td>0.221930</td>\n",
       "      <td>0.774374</td>\n",
       "      <td>0.324747</td>\n",
       "      <td>0.758783</td>\n",
       "      <td>0.530380</td>\n",
       "      <td>0.572475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 50, 'max_features': 'log2', 'min...</td>\n",
       "      <td>0.829932</td>\n",
       "      <td>0.011582</td>\n",
       "      <td>0.830125</td>\n",
       "      <td>0.023196</td>\n",
       "      <td>0.837409</td>\n",
       "      <td>0.058513</td>\n",
       "      <td>0.817976</td>\n",
       "      <td>0.114335</td>\n",
       "      <td>0.790606</td>\n",
       "      <td>0.221044</td>\n",
       "      <td>0.784410</td>\n",
       "      <td>0.328956</td>\n",
       "      <td>0.763627</td>\n",
       "      <td>0.533766</td>\n",
       "      <td>0.582335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 50, 'max_features': 'log2', 'min...</td>\n",
       "      <td>0.861678</td>\n",
       "      <td>0.012025</td>\n",
       "      <td>0.860702</td>\n",
       "      <td>0.024051</td>\n",
       "      <td>0.848279</td>\n",
       "      <td>0.059272</td>\n",
       "      <td>0.831560</td>\n",
       "      <td>0.116234</td>\n",
       "      <td>0.810300</td>\n",
       "      <td>0.226551</td>\n",
       "      <td>0.796106</td>\n",
       "      <td>0.333861</td>\n",
       "      <td>0.773814</td>\n",
       "      <td>0.540886</td>\n",
       "      <td>0.596438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 50, 'max_features': 'log2', 'min...</td>\n",
       "      <td>0.882086</td>\n",
       "      <td>0.012310</td>\n",
       "      <td>0.876557</td>\n",
       "      <td>0.024494</td>\n",
       "      <td>0.866848</td>\n",
       "      <td>0.060570</td>\n",
       "      <td>0.843333</td>\n",
       "      <td>0.117880</td>\n",
       "      <td>0.823090</td>\n",
       "      <td>0.230127</td>\n",
       "      <td>0.802294</td>\n",
       "      <td>0.336456</td>\n",
       "      <td>0.777390</td>\n",
       "      <td>0.543386</td>\n",
       "      <td>0.604583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>SVM</td>\n",
       "      <td>LinearSVC(C=10, class_weight=None, dual=True, ...</td>\n",
       "      <td>{'C': 0.001}</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.012405</td>\n",
       "      <td>0.899207</td>\n",
       "      <td>0.025127</td>\n",
       "      <td>0.876359</td>\n",
       "      <td>0.061234</td>\n",
       "      <td>0.858275</td>\n",
       "      <td>0.119968</td>\n",
       "      <td>0.833164</td>\n",
       "      <td>0.232943</td>\n",
       "      <td>0.819423</td>\n",
       "      <td>0.343639</td>\n",
       "      <td>0.788482</td>\n",
       "      <td>0.551139</td>\n",
       "      <td>0.622892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>SVM</td>\n",
       "      <td>LinearSVC(C=10, class_weight=None, dual=True, ...</td>\n",
       "      <td>{'C': 0.01}</td>\n",
       "      <td>0.868481</td>\n",
       "      <td>0.012120</td>\n",
       "      <td>0.867497</td>\n",
       "      <td>0.024241</td>\n",
       "      <td>0.865036</td>\n",
       "      <td>0.060443</td>\n",
       "      <td>0.851030</td>\n",
       "      <td>0.118956</td>\n",
       "      <td>0.828636</td>\n",
       "      <td>0.231677</td>\n",
       "      <td>0.817839</td>\n",
       "      <td>0.342975</td>\n",
       "      <td>0.787984</td>\n",
       "      <td>0.550791</td>\n",
       "      <td>0.621633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>SVM</td>\n",
       "      <td>LinearSVC(C=10, class_weight=None, dual=True, ...</td>\n",
       "      <td>{'C': 0.1}</td>\n",
       "      <td>0.848073</td>\n",
       "      <td>0.011835</td>\n",
       "      <td>0.857305</td>\n",
       "      <td>0.023956</td>\n",
       "      <td>0.853714</td>\n",
       "      <td>0.059652</td>\n",
       "      <td>0.846729</td>\n",
       "      <td>0.118354</td>\n",
       "      <td>0.827278</td>\n",
       "      <td>0.231297</td>\n",
       "      <td>0.817084</td>\n",
       "      <td>0.342658</td>\n",
       "      <td>0.788030</td>\n",
       "      <td>0.550823</td>\n",
       "      <td>0.621200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>SVM</td>\n",
       "      <td>LinearSVC(C=10, class_weight=None, dual=True, ...</td>\n",
       "      <td>{'C': 1}</td>\n",
       "      <td>0.850340</td>\n",
       "      <td>0.011867</td>\n",
       "      <td>0.850510</td>\n",
       "      <td>0.023766</td>\n",
       "      <td>0.854620</td>\n",
       "      <td>0.059715</td>\n",
       "      <td>0.846729</td>\n",
       "      <td>0.118354</td>\n",
       "      <td>0.826825</td>\n",
       "      <td>0.231171</td>\n",
       "      <td>0.816933</td>\n",
       "      <td>0.342595</td>\n",
       "      <td>0.788211</td>\n",
       "      <td>0.550949</td>\n",
       "      <td>0.621155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>SVM</td>\n",
       "      <td>LinearSVC(C=10, class_weight=None, dual=True, ...</td>\n",
       "      <td>{'C': 10}</td>\n",
       "      <td>0.841270</td>\n",
       "      <td>0.011741</td>\n",
       "      <td>0.843715</td>\n",
       "      <td>0.023576</td>\n",
       "      <td>0.857337</td>\n",
       "      <td>0.059905</td>\n",
       "      <td>0.845370</td>\n",
       "      <td>0.118165</td>\n",
       "      <td>0.827051</td>\n",
       "      <td>0.231234</td>\n",
       "      <td>0.817537</td>\n",
       "      <td>0.342848</td>\n",
       "      <td>0.788120</td>\n",
       "      <td>0.550886</td>\n",
       "      <td>0.620483</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63 rows  18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   model_name                                              model  \\\n",
       "0          LR  LogisticRegression(C=10, class_weight=None, du...   \n",
       "1          LR  LogisticRegression(C=10, class_weight=None, du...   \n",
       "2          LR  LogisticRegression(C=10, class_weight=None, du...   \n",
       "3          LR  LogisticRegression(C=10, class_weight=None, du...   \n",
       "4          LR  LogisticRegression(C=10, class_weight=None, du...   \n",
       "5          LR  LogisticRegression(C=10, class_weight=None, du...   \n",
       "6          LR  LogisticRegression(C=10, class_weight=None, du...   \n",
       "7          LR  LogisticRegression(C=10, class_weight=None, du...   \n",
       "8          DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "9          DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "10         DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "11         DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "12         DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "13         DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "14         DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "15         DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "16         DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "17         DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "18         DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "19         DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "20         DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "21         DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "22         DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "23         DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "24         DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "25         DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "26         DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "27         DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "28         LR  LogisticRegression(C=10, class_weight=None, du...   \n",
       "29         LR  LogisticRegression(C=10, class_weight=None, du...   \n",
       "..        ...                                                ...   \n",
       "33         LR  LogisticRegression(C=10, class_weight=None, du...   \n",
       "34         LR  LogisticRegression(C=10, class_weight=None, du...   \n",
       "35         LR  LogisticRegression(C=10, class_weight=None, du...   \n",
       "36         AB  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "37         AB  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "38         AB  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "39         AB  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "40         AB  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "41         AB  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "42         RF  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "43         RF  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "44         RF  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "45         RF  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "46         RF  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "47         RF  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "48         RF  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "49         RF  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "50         RF  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "51         RF  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "52         RF  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "53         RF  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "54         RF  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "55         RF  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "56         RF  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "57         RF  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "58        SVM  LinearSVC(C=10, class_weight=None, dual=True, ...   \n",
       "59        SVM  LinearSVC(C=10, class_weight=None, dual=True, ...   \n",
       "60        SVM  LinearSVC(C=10, class_weight=None, dual=True, ...   \n",
       "61        SVM  LinearSVC(C=10, class_weight=None, dual=True, ...   \n",
       "62        SVM  LinearSVC(C=10, class_weight=None, dual=True, ...   \n",
       "\n",
       "                                           parameters    p_at_1    r_at_1  \\\n",
       "0                       {'C': 0.001, 'penalty': 'l1'}  1.000000  0.013956   \n",
       "1                       {'C': 0.001, 'penalty': 'l2'}  0.877551  0.012247   \n",
       "2                         {'C': 0.1, 'penalty': 'l1'}  0.825397  0.011519   \n",
       "3                         {'C': 0.1, 'penalty': 'l2'}  0.845805  0.011804   \n",
       "4                           {'C': 1, 'penalty': 'l1'}  0.775510  0.010823   \n",
       "5                           {'C': 1, 'penalty': 'l2'}  0.777778  0.010854   \n",
       "6                          {'C': 10, 'penalty': 'l1'}  0.773243  0.010791   \n",
       "7                          {'C': 10, 'penalty': 'l2'}  0.770975  0.010759   \n",
       "8   {'criterion': 'gini', 'max_depth': 1, 'min_sam...  1.000000  0.013956   \n",
       "9   {'criterion': 'gini', 'max_depth': 1, 'min_sam...  1.000000  0.013956   \n",
       "10  {'criterion': 'gini', 'max_depth': 5, 'min_sam...  0.775510  0.010823   \n",
       "11  {'criterion': 'gini', 'max_depth': 5, 'min_sam...  0.775510  0.010823   \n",
       "12  {'criterion': 'gini', 'max_depth': 10, 'min_sa...  0.512472  0.007152   \n",
       "13  {'criterion': 'gini', 'max_depth': 10, 'min_sa...  0.530612  0.007405   \n",
       "14  {'criterion': 'gini', 'max_depth': 50, 'min_sa...  1.000000  0.013956   \n",
       "15  {'criterion': 'gini', 'max_depth': 50, 'min_sa...  1.000000  0.013956   \n",
       "16  {'criterion': 'gini', 'max_depth': 100, 'min_s...  1.000000  0.013956   \n",
       "17  {'criterion': 'gini', 'max_depth': 100, 'min_s...  1.000000  0.013956   \n",
       "18  {'criterion': 'entropy', 'max_depth': 1, 'min_...  1.000000  0.013956   \n",
       "19  {'criterion': 'entropy', 'max_depth': 1, 'min_...  1.000000  0.013956   \n",
       "20  {'criterion': 'entropy', 'max_depth': 5, 'min_...  0.773243  0.010791   \n",
       "21  {'criterion': 'entropy', 'max_depth': 5, 'min_...  0.775510  0.010823   \n",
       "22  {'criterion': 'entropy', 'max_depth': 10, 'min...  0.646259  0.009019   \n",
       "23  {'criterion': 'entropy', 'max_depth': 10, 'min...  0.637188  0.008892   \n",
       "24  {'criterion': 'entropy', 'max_depth': 50, 'min...  1.000000  0.013956   \n",
       "25  {'criterion': 'entropy', 'max_depth': 50, 'min...  1.000000  0.013956   \n",
       "26  {'criterion': 'entropy', 'max_depth': 100, 'mi...  1.000000  0.013956   \n",
       "27  {'criterion': 'entropy', 'max_depth': 100, 'mi...  1.000000  0.013956   \n",
       "28                      {'C': 0.001, 'penalty': 'l1'}  1.000000  0.013956   \n",
       "29                      {'C': 0.001, 'penalty': 'l2'}  0.877551  0.012247   \n",
       "..                                                ...       ...       ...   \n",
       "33                          {'C': 1, 'penalty': 'l2'}  0.777778  0.010854   \n",
       "34                         {'C': 10, 'penalty': 'l1'}  0.773243  0.010791   \n",
       "35                         {'C': 10, 'penalty': 'l2'}  0.770975  0.010759   \n",
       "36          {'algorithm': 'SAMME', 'n_estimators': 1}  1.000000  0.013956   \n",
       "37         {'algorithm': 'SAMME', 'n_estimators': 10}  0.836735  0.011677   \n",
       "38        {'algorithm': 'SAMME', 'n_estimators': 100}  0.739229  0.010316   \n",
       "39        {'algorithm': 'SAMME.R', 'n_estimators': 1}  1.000000  0.013956   \n",
       "40       {'algorithm': 'SAMME.R', 'n_estimators': 10}  0.761905  0.010633   \n",
       "41      {'algorithm': 'SAMME.R', 'n_estimators': 100}  0.775510  0.010823   \n",
       "42  {'max_depth': 5, 'max_features': 'sqrt', 'min_...  0.857143  0.011962   \n",
       "43  {'max_depth': 5, 'max_features': 'sqrt', 'min_...  0.902494  0.012595   \n",
       "44  {'max_depth': 5, 'max_features': 'sqrt', 'min_...  0.877551  0.012247   \n",
       "45  {'max_depth': 5, 'max_features': 'sqrt', 'min_...  0.895692  0.012500   \n",
       "46  {'max_depth': 5, 'max_features': 'log2', 'min_...  0.868481  0.012120   \n",
       "47  {'max_depth': 5, 'max_features': 'log2', 'min_...  0.886621  0.012373   \n",
       "48  {'max_depth': 5, 'max_features': 'log2', 'min_...  0.888889  0.012405   \n",
       "49  {'max_depth': 5, 'max_features': 'log2', 'min_...  0.886621  0.012373   \n",
       "50  {'max_depth': 50, 'max_features': 'sqrt', 'min...  1.000000  0.013956   \n",
       "51  {'max_depth': 50, 'max_features': 'sqrt', 'min...  0.841270  0.011741   \n",
       "52  {'max_depth': 50, 'max_features': 'sqrt', 'min...  0.850340  0.011867   \n",
       "53  {'max_depth': 50, 'max_features': 'sqrt', 'min...  0.879819  0.012278   \n",
       "54  {'max_depth': 50, 'max_features': 'log2', 'min...  1.000000  0.013956   \n",
       "55  {'max_depth': 50, 'max_features': 'log2', 'min...  0.829932  0.011582   \n",
       "56  {'max_depth': 50, 'max_features': 'log2', 'min...  0.861678  0.012025   \n",
       "57  {'max_depth': 50, 'max_features': 'log2', 'min...  0.882086  0.012310   \n",
       "58                                       {'C': 0.001}  0.888889  0.012405   \n",
       "59                                        {'C': 0.01}  0.868481  0.012120   \n",
       "60                                         {'C': 0.1}  0.848073  0.011835   \n",
       "61                                           {'C': 1}  0.850340  0.011867   \n",
       "62                                          {'C': 10}  0.841270  0.011741   \n",
       "\n",
       "      p_at_2    r_at_2    p_at_5    r_at_5   p_at_10   r_at_10   p_at_20  \\\n",
       "0   0.710079  0.019842  0.867301  0.060601  0.837220  0.117025  0.799095   \n",
       "1   0.883352  0.024684  0.871830  0.060918  0.854426  0.119430  0.828862   \n",
       "2   0.828992  0.023165  0.850091  0.059399  0.843559  0.117911  0.827731   \n",
       "3   0.843715  0.023576  0.852808  0.059589  0.845370  0.118165  0.828976   \n",
       "4   0.796149  0.022247  0.843297  0.058924  0.844691  0.118070  0.828297   \n",
       "5   0.800680  0.022373  0.843750  0.058956  0.844238  0.118006  0.827391   \n",
       "6   0.793884  0.022184  0.844203  0.058987  0.844917  0.118101  0.827278   \n",
       "7   0.793884  0.022184  0.844203  0.058987  0.844917  0.118101  0.827617   \n",
       "8   1.000000  0.027943  1.000000  0.069873  0.744623  0.104082  0.672213   \n",
       "9   1.000000  0.027943  1.000000  0.069873  0.744623  0.104082  0.672213   \n",
       "10  0.705549  0.019715  0.788496  0.055095  0.749830  0.104810  0.805999   \n",
       "11  0.705549  0.019715  0.788496  0.055095  0.749830  0.104810  0.805999   \n",
       "12  0.749717  0.020949  0.802989  0.056108  0.803939  0.112373  0.804188   \n",
       "13  0.747452  0.020886  0.803895  0.056171  0.800091  0.111835  0.804188   \n",
       "14  1.000000  0.027943  0.993207  0.069399  0.996378  0.139272  0.528919   \n",
       "15  1.000000  0.027943  1.000000  0.069873  0.970342  0.135633  0.518846   \n",
       "16  1.000000  0.027943  0.967844  0.067627  0.983926  0.137532  0.555178   \n",
       "17  1.000000  0.027943  0.987319  0.068987  0.993661  0.138892  0.509338   \n",
       "18  1.000000  0.027943  1.000000  0.069873  0.744623  0.104082  0.672213   \n",
       "19  1.000000  0.027943  1.000000  0.069873  0.744623  0.104082  0.672213   \n",
       "20  0.795017  0.022215  0.810236  0.056614  0.760697  0.106329  0.821279   \n",
       "21  0.796149  0.022247  0.810688  0.056646  0.760924  0.106361  0.821166   \n",
       "22  0.730464  0.020411  0.795743  0.055601  0.827258  0.115633  0.818789   \n",
       "23  0.727067  0.020316  0.794384  0.055506  0.826806  0.115570  0.818789   \n",
       "24  1.000000  0.027943  1.000000  0.069873  1.000000  0.139778  0.517148   \n",
       "25  1.000000  0.027943  1.000000  0.069873  0.953362  0.133259  0.531409   \n",
       "26  0.998867  0.027911  0.971014  0.067848  0.985511  0.137753  0.549179   \n",
       "27  0.998867  0.027911  0.992754  0.069367  0.996378  0.139272  0.508432   \n",
       "28  0.710079  0.019842  0.867301  0.060601  0.837220  0.117025  0.803396   \n",
       "29  0.883352  0.024684  0.871830  0.060918  0.854426  0.119430  0.828862   \n",
       "..       ...       ...       ...       ...       ...       ...       ...   \n",
       "33  0.800680  0.022373  0.843750  0.058956  0.844238  0.118006  0.827391   \n",
       "34  0.793884  0.022184  0.844203  0.058987  0.844917  0.118101  0.827504   \n",
       "35  0.793884  0.022184  0.844203  0.058987  0.844917  0.118101  0.827617   \n",
       "36  1.000000  0.027943  1.000000  0.069873  0.744623  0.104082  0.672213   \n",
       "37  0.898075  0.025095  0.902174  0.063038  0.823862  0.115158  0.822524   \n",
       "38  0.781427  0.021835  0.838315  0.058576  0.830428  0.116076  0.819581   \n",
       "39  1.000000  0.027943  1.000000  0.069873  0.744623  0.104082  0.672213   \n",
       "40  0.784824  0.021930  0.821105  0.057373  0.815033  0.113924  0.820147   \n",
       "41  0.790487  0.022089  0.843750  0.058956  0.845144  0.118133  0.827165   \n",
       "42  0.862967  0.024114  0.857790  0.059937  0.844691  0.118070  0.826712   \n",
       "43  0.876557  0.024494  0.874547  0.061108  0.856237  0.119684  0.826712   \n",
       "44  0.866365  0.024209  0.855525  0.059778  0.844012  0.117975  0.819468   \n",
       "45  0.875425  0.024462  0.873641  0.061044  0.855558  0.119589  0.826486   \n",
       "46  0.859570  0.024019  0.846467  0.059146  0.846955  0.118386  0.826938   \n",
       "47  0.877690  0.024525  0.876359  0.061234  0.855105  0.119525  0.831239   \n",
       "48  0.859570  0.024019  0.855525  0.059778  0.847861  0.118513  0.827504   \n",
       "49  0.882220  0.024652  0.876359  0.061234  0.857143  0.119810  0.831579   \n",
       "50  1.000000  0.027943  0.639493  0.044684  0.808467  0.113006  0.794114   \n",
       "51  0.847112  0.023671  0.850543  0.059430  0.816844  0.114177  0.790492   \n",
       "52  0.845980  0.023639  0.850091  0.059399  0.829975  0.116013  0.805433   \n",
       "53  0.879955  0.024589  0.859149  0.060032  0.839937  0.117405  0.819015   \n",
       "54  1.000000  0.027943  0.657609  0.045949  0.802355  0.112152  0.793775   \n",
       "55  0.830125  0.023196  0.837409  0.058513  0.817976  0.114335  0.790606   \n",
       "56  0.860702  0.024051  0.848279  0.059272  0.831560  0.116234  0.810300   \n",
       "57  0.876557  0.024494  0.866848  0.060570  0.843333  0.117880  0.823090   \n",
       "58  0.899207  0.025127  0.876359  0.061234  0.858275  0.119968  0.833164   \n",
       "59  0.867497  0.024241  0.865036  0.060443  0.851030  0.118956  0.828636   \n",
       "60  0.857305  0.023956  0.853714  0.059652  0.846729  0.118354  0.827278   \n",
       "61  0.850510  0.023766  0.854620  0.059715  0.846729  0.118354  0.826825   \n",
       "62  0.843715  0.023576  0.857337  0.059905  0.845370  0.118165  0.827051   \n",
       "\n",
       "     r_at_20   p_at_30   r_at_30   p_at_50   r_at_50   auc-roc  \n",
       "0   0.223418  0.781467  0.327722  0.785313  0.548924  0.590088  \n",
       "1   0.231741  0.817386  0.342785  0.783412  0.547595  0.617331  \n",
       "2   0.231424  0.817235  0.342722  0.787577  0.550506  0.619977  \n",
       "3   0.231772  0.817235  0.342722  0.786490  0.549747  0.620281  \n",
       "4   0.231582  0.816933  0.342595  0.786626  0.549842  0.619914  \n",
       "5   0.231329  0.816707  0.342500  0.786671  0.549873  0.619810  \n",
       "6   0.231297  0.816556  0.342437  0.786762  0.549937  0.619782  \n",
       "7   0.231392  0.816556  0.342437  0.786762  0.549937  0.619771  \n",
       "8   0.187943  0.781467  0.327722  0.868843  0.607310  0.547044  \n",
       "9   0.187943  0.781467  0.327722  0.868843  0.607310  0.547044  \n",
       "10  0.225348  0.780486  0.327310  0.784227  0.548165  0.609405  \n",
       "11  0.225348  0.780486  0.327310  0.784227  0.548165  0.609405  \n",
       "12  0.224842  0.801011  0.335918  0.781375  0.546171  0.603402  \n",
       "13  0.224842  0.800936  0.335886  0.781239  0.546076  0.603347  \n",
       "14  0.147880  0.644959  0.270475  0.756836  0.529019  0.553882  \n",
       "15  0.145063  0.679218  0.284842  0.755433  0.528038  0.556310  \n",
       "16  0.155222  0.619076  0.259620  0.753577  0.526741  0.550751  \n",
       "17  0.142405  0.656127  0.275158  0.753079  0.526392  0.552637  \n",
       "18  0.187943  0.781467  0.327722  0.868843  0.607310  0.547044  \n",
       "19  0.187943  0.781467  0.327722  0.868843  0.607310  0.547044  \n",
       "20  0.229620  0.776411  0.325601  0.780695  0.545696  0.608205  \n",
       "21  0.229589  0.776487  0.325633  0.780741  0.545728  0.608252  \n",
       "22  0.228924  0.801087  0.335949  0.786264  0.549589  0.608688  \n",
       "23  0.228924  0.800634  0.335759  0.786309  0.549620  0.608738  \n",
       "24  0.144589  0.655901  0.275063  0.754573  0.527437  0.554204  \n",
       "25  0.148576  0.687594  0.288354  0.763944  0.533987  0.557241  \n",
       "26  0.153544  0.624208  0.261772  0.751630  0.525380  0.550796  \n",
       "27  0.142152  0.658618  0.276203  0.753984  0.527025  0.552605  \n",
       "28  0.224620  0.781467  0.327722  0.785313  0.548924  0.593102  \n",
       "29  0.231741  0.817386  0.342785  0.783412  0.547595  0.617331  \n",
       "..       ...       ...       ...       ...       ...       ...  \n",
       "33  0.231329  0.816707  0.342500  0.786671  0.549873  0.619810  \n",
       "34  0.231361  0.816556  0.342437  0.786762  0.549937  0.619793  \n",
       "35  0.231392  0.816556  0.342437  0.786762  0.549937  0.619771  \n",
       "36  0.187943  0.781467  0.327722  0.868843  0.607310  0.547044  \n",
       "37  0.229968  0.779882  0.327057  0.783140  0.547405  0.601875  \n",
       "38  0.229146  0.774374  0.324747  0.782280  0.546804  0.602678  \n",
       "39  0.187943  0.781467  0.327722  0.868843  0.607310  0.547044  \n",
       "40  0.229304  0.809010  0.339272  0.802562  0.560981  0.610830  \n",
       "41  0.231266  0.817160  0.342690  0.786807  0.549968  0.619644  \n",
       "42  0.231139  0.795804  0.333734  0.775715  0.542215  0.606076  \n",
       "43  0.231139  0.814066  0.341392  0.780650  0.545665  0.616676  \n",
       "44  0.229114  0.792409  0.332310  0.772365  0.539873  0.603239  \n",
       "45  0.231076  0.811877  0.340475  0.780560  0.545601  0.615912  \n",
       "46  0.231203  0.812708  0.340823  0.781963  0.546582  0.614701  \n",
       "47  0.232405  0.816254  0.342310  0.783910  0.547943  0.618690  \n",
       "48  0.231361  0.815952  0.342184  0.784634  0.548449  0.616462  \n",
       "49  0.232500  0.816933  0.342595  0.784996  0.548703  0.619532  \n",
       "50  0.222025  0.780486  0.327310  0.762586  0.533038  0.577122  \n",
       "51  0.221013  0.781920  0.327911  0.766570  0.535823  0.583090  \n",
       "52  0.225190  0.793390  0.332722  0.768607  0.537247  0.589409  \n",
       "53  0.228987  0.800634  0.335759  0.773044  0.540348  0.601300  \n",
       "54  0.221930  0.774374  0.324747  0.758783  0.530380  0.572475  \n",
       "55  0.221044  0.784410  0.328956  0.763627  0.533766  0.582335  \n",
       "56  0.226551  0.796106  0.333861  0.773814  0.540886  0.596438  \n",
       "57  0.230127  0.802294  0.336456  0.777390  0.543386  0.604583  \n",
       "58  0.232943  0.819423  0.343639  0.788482  0.551139  0.622892  \n",
       "59  0.231677  0.817839  0.342975  0.787984  0.550791  0.621633  \n",
       "60  0.231297  0.817084  0.342658  0.788030  0.550823  0.621200  \n",
       "61  0.231171  0.816933  0.342595  0.788211  0.550949  0.621155  \n",
       "62  0.231234  0.817537  0.342848  0.788120  0.550886  0.620483  \n",
       "\n",
       "[63 rows x 18 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(pipeline)\n",
    "\n",
    "pipeline.iterate_over_models(models_to_run, models, parameters_grid, x_train, x_test, y_train, y_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
